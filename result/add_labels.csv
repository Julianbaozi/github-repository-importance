full_name,mirror_url,archived,disabled,if_fork,size,files,stars,watches,forks,recent_commits,recent_added,recent_deleted,recent_contributors,latest_commits,owner_type,description,formats,homepage,license,language,commits,branches,releases,contributors,topics,age,has_issues,open_issues,closed_issues,open_issues_recent,closed_issues_recent,open_prs,closed_prs,open_prs_recent,closed_prs_recent,labels,milestones,dependent_repositories,dependent_packages,repositories,people,followers,readme,info
bookshelf/bookshelf,,False,False,False,7240,102,5922,101,533,26,1883,782,8,"[34, 76, 88, 105, 111, 120, 127, 131, 134, 135]",Organization,"A simple Node.js ORM for PostgreSQL, MySQL and SQLite3 built on top of Knex.js","{'json': 5, 'md': 14, '': 7, 'yml': 4, 'js': 45, 'html': 21, 'svg': 1, 'ico': 1, 'txt': 1, 'css': 1, 'sh': 2}",http://bookshelfjs.org,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",JavaScript,1894,7,85,85,8,2676,True,203,1326,8,14,0,551,0,12,32,0,17621,404,11,5,,"# bookshelf.jsþþ[![NPM Version](https://img.shields.io/npm/v/bookshelf.svg?style=flat)](https://www.npmjs.com/package/bookshelf)þ[![Build Status](https://api.travis-ci.org/bookshelf/bookshelf.svg?branch=master)](https://travis-ci.org/bookshelf/bookshelf)þ[![Dependency Status](https://david-dm.org/bookshelf/bookshelf/status.svg)](https://david-dm.org/bookshelf/bookshelf)þ[![devDependency Status](https://david-dm.org/bookshelf/bookshelf/dev-status.svg)](https://david-dm.org/bookshelf/bookshelf?type=dev)þþBookshelf is a JavaScript ORM for Node.js, built on the [Knex](http://knexjs.org) SQL query builder. It features both Promise-based and traditional callback interfaces, transaction support, eager/nested-eager relation loading, polymorphic associations, and support for one-to-one, one-to-many, and many-to-many relations.þþIt is designed to work with PostgreSQL, MySQL, and SQLite3.þþ[Website and documentation](http://bookshelfjs.org). The project is [hosted on GitHub](http://github.com/bookshelf/bookshelf/), and has a comprehensive [test suite](https://travis-ci.org/bookshelf/bookshelf).þþ## IntroductionþþBookshelf aims to provide a simple library for common tasks when querying databases in JavaScript, and forming relations between these objects, taking a lot of ideas from the [Data Mapper Pattern](http://en.wikipedia.org/wiki/Data_mapper_pattern).þþWith a concise, literate codebase, Bookshelf is simple to read, understand, and extend. It doesn't force you to use any specific validation scheme, and provides flexible, efficient relation/nested-relation loading and first-class transaction support.þþIt's a lean object-relational mapper, allowing you to drop down to the raw Knex interface whenever you need a custom query that doesn't quite fit with the stock conventions.þþ## InstallationþþYou'll need to install a copy of [Knex](http://knexjs.org/), and either `mysql`, `pg`, or `sqlite3` from npm.þþ```jsþ$ npm install knexþ$ npm install bookshelfþþ# Then add one of the following:þ$ npm install pgþ$ npm install mysqlþ$ npm install sqlite3þ```þþThe Bookshelf library is initialized by passing an initialized [Knex](http://knexjs.org/) client instance. The [Knex documentation](http://knexjs.org/) provides a number of examples for different databases.þþ```jsþ// Setting up the database connectionþconst knex = require('knex')({þ  client: 'mysql',þ  connection: {þ    host     : '127.0.0.1',þ    user     : 'your_database_user',þ    password : 'your_database_password',þ    database : 'myapp_test',þ    charset  : 'utf8'þ  }þ})þconst bookshelf = require('bookshelf')(knex)þþ// Defining modelsþconst User = bookshelf.model('User', {þ  tableName: 'users'þ})þ```þþThis initialization should likely only ever happen once in your application. As it creates a connection pool for the current database, you should use the `bookshelf` instance returned throughout your library. You'll need to store this instance created by the initialize somewhere in the application so you can reference it. A common pattern to follow is to initialize the client in a module so you can easily reference it later:þþ```jsþ// In a file named, e.g. bookshelf.jsþconst knex = require('knex')(dbConfig)þmodule.exports = require('bookshelf')(knex)þþ// elsewhere, to use the bookshelf client:þconst bookshelf = require('./bookshelf')þþconst Post = bookshelf.model('Post', {þ  // ...þ})þ```þþ## ExamplesþþHere is an example to get you started:þþ```jsþconst knex = require('knex')({þ  client: 'mysql',þ  connection: process.env.MYSQL_DATABASE_CONNECTIONþ})þconst bookshelf = require('bookshelf')(knex)þþconst User = bookshelf.model('User', {þ  tableName: 'users',þ  posts() {þ    return this.hasMany(Posts)þ  }þ})þþconst Post = bookshelf.model('Post', {þ  tableName: 'posts',þ  tags() {þ    return this.belongsToMany(Tag)þ  }þ})þþconst Tag = bookshelf.model('Tag', {þ  tableName: 'tags'þ})þþnew User({id: 1}).fetch({withRelated: ['posts.tags']}).then((user) => {þ  console.log(user.related('posts').toJSON())þ}).catch((error) => {þ  console.error(error)þ})þ```þþ## Official Pluginsþþ* [Virtuals](https://github.com/bookshelf/virtuals-plugin): Define virtual properties on your model to compute new values.þ* [Case Converter](https://github.com/bookshelf/case-converter-plugin): Handles the conversion between the database's snake_cased and a model's camelCased properties automatically.þ* [Processor](https://github.com/bookshelf/processor-plugin): Allows defining custom processor functions that handle transformation of values whenever they are `.set()` on a model.þþ## Community pluginsþþ* [bookshelf-cascade-delete](https://github.com/seegno/bookshelf-cascade-delete) - Cascade delete related models on destroy.þ* [bookshelf-json-columns](https://github.com/seegno/bookshelf-json-columns) - Parse and stringify JSON columns on save and fetch instead of manually define hooks for each model (PostgreSQL and SQLite).þ* [bookshelf-mask](https://github.com/seegno/bookshelf-mask) - Similar to the functionality of the {@link Model#visible} attribute but supporting multiple scopes, masking models and collections using the [json-mask](https://github.com/nemtsov/json-mask) API.þ* [bookshelf-schema](https://github.com/bogus34/bookshelf-schema) - A plugin for handling fields, relations, scopes and more.þ* [bookshelf-signals](https://github.com/bogus34/bookshelf-signals) - A plugin that translates Bookshelf events to a central hub.þ* [bookshelf-paranoia](https://github.com/estate/bookshelf-paranoia) - Protect your database from data loss by soft deleting your rows.þ* [bookshelf-uuid](https://github.com/estate/bookshelf-uuid) - Automatically generates UUIDs for your models.þ* [bookshelf-modelbase](https://github.com/bsiddiqui/bookshelf-modelbase) - An alternative to extend `Model`, adding timestamps, attribute validation and some native CRUD methods.þ* [bookshelf-advanced-serialization](https://github.com/sequiturs/bookshelf-advanced-serialization) - A more powerful visibility plugin, supporting serializing models and collections according to access permissions, application context, and after ensuring relations have been loaded.þ* [bookshelf-plugin-mode](https://github.com/popodidi/bookshelf-plugin-mode) - Plugin inspired by the functionality of the {@link Model#visible} attribute, allowing to specify different modes with corresponding visible/hidden fields of model.þ* [bookshelf-secure-password](https://github.com/venables/bookshelf-secure-password) - A plugin for easily securing passwords using bcrypt.þ* [bookshelf-default-select](https://github.com/DJAndries/bookshelf-default-select) - Enables default column selection for models. Inspired by the functionality of the {@link Model#visible} attribute, but operates on the database level.þ* [bookshelf-ez-fetch](https://github.com/DJAndries/bookshelf-ez-fetch) - Convenient fetching methods which allow for compact filtering, relation selection and error handling.þ* [bookshelf-manager](https://github.com/ericclemmons/bookshelf-manager) - Model & Collection manager to make it easy to create & save deep, nested JSON structures from API requests.þþ## SupportþþHave questions about the library? Come join us in the [#bookshelf freenode IRC channel](http://webchat.freenode.net/?channels=bookshelf) for support on [knex.js](http://knexjs.org/) and bookshelf.js, or post an issue on [Stack Overflow](http://stackoverflow.com/questions/tagged/bookshelf.js).þþ## ContributingþþIf you want to contribute to Bookshelf you'll usually want to report an issue or submit aþpull-request. For this purpose the [online repository](https://github.com/bookshelf/bookshelf/) isþavailable on GitHub.þþFor further help setting up your local development environment or learning how you can contribute toþBookshelf you should read the [Contributing document](https://github.com/bookshelf/bookshelf/blob/master/.github/CONTRIBUTING.md)þavailable on GitHub.þþ## F.A.Q.þþ### Can I use standard node.js style callbacks?þþYes, you can call `.asCallback(function(err, resp) {` on any database operation method and use the standard `(err, result)` style callback interface if you prefer.þþ### My relations don't seem to be loading, what's up?þþMake sure to check that the type is correct for the initial parameters passed to the initial model being fetched. For example `new Model({id: '1'}).load([relations...])` will not return the same as `new Model({id: 1}).load([relations...])` - notice that the id is a string in one case and a number in the other. This can be a common mistake if retrieving the id from a url parameter.þþThis is only an issue if you're eager loading data with load without first fetching the original model. `new Model({id: '1'}).fetch({withRelated: [relations...]})` should work just fine.þþ### My process won't exit after my script is finished, why?þþThe issue here is that Knex, the database abstraction layer used by Bookshelf, uses connection pooling and thus keeps the database connection open. If you want your process to exit after your script has finished, you will have to call `.destroy(cb)` on the `knex` property of your `Bookshelf` instance or on the `Knex` instance passed during initialization. More information about connection pooling can be found over at the [Knex docs](http://knexjs.org/#Installation-pooling).þþ### How do I debug?þþIf you pass `debug: true` in the options object to your `knex` initialize call, you can see all of the query calls being made. You can also pass that same option to all methods that access the database, like `model.fetch()` or `model.destroy()`. Examples:þþ```jsþ// Turning on debug mode for all queriesþconst knex = require('knex')({þ  debug: true,þ  client: 'mysql',þ  connection: process.env.MYSQL_DATABASE_CONNECTIONþ})þconst bookshelf = require('bookshelf')(knex)þþ// Debugging a single queryþnew User({id: 1}).fetch({debug: true, withRelated: ['posts.tags']}).then(user => {þ  // ...þ})þ```þþSometimes you need to dive a bit further into the various calls and see what all is going on behind the scenes. You can use [node-inspector](https://github.com/dannycoates/node-inspector), which allows you to debug code with `debugger` statements like you would in the browser.þþBookshelf uses its own copy of the `bluebird` Promise library. You can read up [here](http://bluebirdjs.com/docs/api/promise.config.html) for more on debugging Promises.þþAdding the following block at the start of your application code will catch any errors not otherwise caught in the normal Promise chain handlers, which is very helpful in debugging:þþ```jsþprocess.stderr.on('data', (data) => {þ  console.log(data)þ})þ```þþ### How do I run the test suite?þþSee the [CONTRIBUTING](https://github.com/bookshelf/bookshelf/blob/master/.github/CONTRIBUTING.md#running-the-tests)þdocument on GitHub.þþ### Can I use Bookshelf outside of Node.js?þþWhile it primarily targets Node.js, all dependencies are browser compatible, and it could be adapted to work with other javascript environments supporting a sqlite3 database, by providing a custom [Knex adapter](http://knexjs.org/#Adapters). No such adapter exists though.þþ### Which open-source projects are using Bookshelf?þþWe found the following projects using Bookshelf, but there can be more:þþ* [Ghost](https://ghost.org/) (A blogging platform) uses bookshelf. [[Link](https://github.com/TryGhost/Ghost/tree/master/core/server/models)]þ* [Soapee](http://soapee.com/) (Soap Making Community and Resources) uses bookshelf. [[Link](https://github.com/nazar/soapee-api/tree/master/src/models)]þ* [NodeZA](http://nodeza.co.za/) (Node.js social platform for developers in South Africa) uses bookshelf. [[Link](https://github.com/qawemlilo/nodeza/tree/master/models)]þ* [Sunday Cook](https://github.com/sunday-cooks/sunday-cook) (A social cooking event platform) uses bookshelf. [[Link](https://github.com/sunday-cooks/sunday-cook/tree/master/server/bookshelf)]þ* [FlyptoX](http://www.flyptox.com/) (Open-source Node.js cryptocurrency exchange) uses bookshelf. [[Link](https://github.com/FlipSideHR/FlyptoX/tree/master/server/models)]þ* And of course, everything on [here](https://www.npmjs.com/browse/depended/bookshelf) use bookshelf too.",
Darkhax-Minecraft/Bookshelf,,False,False,False,2384,83,38,8,18,112,5277,5875,2,"[0, 1, 2, 47, 51, 53, 58, 63, 69, 71]",Organization,A library mod which adds additional code support beyond what is provided by Forge.,"{'': 3, 'md': 2, 'gradle': 1, 'properties': 2, 'jar': 1, 'bat': 1, 'java': 58, 'cfg': 1, 'toml': 1, 'json': 11, 'png': 1, 'mcmeta': 1}",,"{'key': 'lgpl-2.1', 'name': 'GNU Lesser General Public License v2.1', 'spdx_id': 'LGPL-2.1', 'url': 'https://api.github.com/licenses/lgpl-2.1', 'node_id': 'MDc6TGljZW5zZTEx'}",Java,1244,10,0,21,0,1840,True,0,92,0,10,0,51,0,2,7,0,0,0,90,1,,,
laurent22/joplin,,False,False,False,131366,2200,16828,387,1731,757,584419,488584,56,"[0, 1, 4, 5, 7, 8, 9, 11, 13, 14]",User,"Joplin - an open source note taking and to-do application with synchronization capabilities for Windows, macOS, Linux, Android and iOS. Forum: https://discourse.joplinapp.org/","{'': 25, 'js': 447, 'yml': 6, 'md': 136, 'png': 985, 'psd': 7, 'ico': 5, 'svg': 20, 'eps': 1, 'jpg': 8, 'icns': 1, 'sh': 6, 'json': 148, 'po': 38, 'pot': 1, 'enex': 5, 'html': 100, 'ts': 115, 'css': 9, 'xml': 9, 'yml-fortesting': 1, 'jsx': 32, 'tsx': 15, 'txt': 6, 'lock': 2, 'gradle': 3, 'keystore': 1, 'pro': 1, 'java': 4, 'properties': 2, 'jar': 1, 'bat': 2, 'plist': 4, 'pbxproj': 1, 'xcscheme': 1, 'xcworkspacedata': 1, 'h': 1, 'm': 2, 'xib': 1, 'entitlements': 1, 'woff2': 24, 'ini': 3, 'exe': 1, 'eot': 4, 'ttf': 4, 'woff': 4, 'code-workspace': 1, 'sublime-project': 1, 'patch': 2, 'gif': 2}",https://joplinapp.org,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",JavaScript,4447,93,478,478,14,1361,True,206,2263,156,556,23,973,23,442,37,0,7,1,,,801,"[![Donate](https://joplinapp.org/images/badges/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=E8JMYD2LQ8MMA&lc=GB&item_name=Joplin+Development&currency_code=EUR&bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted) [![Sponsor on GitHub](https://joplinapp.org/images/badges/GitHub-Badge.svg)](https://github.com/sponsors/laurent22/) [![Become a patron](https://joplinapp.org/images/badges/Patreon-Badge.svg)](https://www.patreon.com/joplin)þþ* * *þþ<img width=""64"" src=""https://raw.githubusercontent.com/laurent22/joplin/master/Assets/LinuxIcons/256x256.png"" align=""left"" /> **Joplin** is a free, open source note taking and to-do application, which can handle a large number of notes organised into notebooks. The notes are searchable, can be copied, tagged and modified either from the applications directly or from your own text editor. The notes are in [Markdown format](#markdown).þþNotes exported from Evernote via .enex files [can be imported](#importing) into Joplin, including the formatted content (which is converted to Markdown), resources (images, attachments, etc.) and complete metadata (geolocation, updated time, created time, etc.). Plain Markdown files can also be imported.þþThe notes can be [synchronised](#synchronisation) with various cloud services including [Nextcloud](https://nextcloud.com/), Dropbox, OneDrive, WebDAV or the file system (for example with a network directory). When synchronising the notes, notebooks, tags and other metadata are saved to plain text files which can be easily inspected, backed up and moved around.þþThe application is available for Windows, Linux, macOS, Android and iOS (the terminal app also works on FreeBSD). A [Web Clipper](https://github.com/laurent22/joplin/blob/master/readme/clipper.md), to save web pages and screenshots from your browser, is also available for [Firefox](https://addons.mozilla.org/firefox/addon/joplin-web-clipper/) and [Chrome](https://chrome.google.com/webstore/detail/joplin-web-clipper/alofnhikmmkdbbbgpnglcpdollgjjfek?hl=en-GB).þþ<div class=""top-screenshot""><img src=""https://joplinapp.org/images/AllClients.jpg"" style=""max-width: 100%; max-height: 35em;""></div>þþ# InstallationþþThree types of applications are available: for the **desktop** (Windows, macOS and Linux), for **mobile** (Android and iOS) and for **terminal** (Windows, macOS, Linux and FreeBSD). All applications have similar user interfaces and can synchronise with each other.þþ## Desktop applicationsþþOperating System | Download | Alternativeþ-----------------|--------|-------------------þWindows (32 and 64-bit)         | <a href='https://github.com/laurent22/joplin/releases/download/v1.0.220/Joplin-Setup-1.0.220.exe'><img alt='Get it on Windows' width=""134px"" src='https://joplinapp.org/images/BadgeWindows.png'/></a> | Or get the <a href='https://github.com/laurent22/joplin/releases/download/v1.0.220/JoplinPortable.exe'>Portable version</a><br><br>The [portable application](https://en.wikipedia.org/wiki/Portable_application) allows installing the software on a portable device such as a USB key. Simply copy the file JoplinPortable.exe in any directory on that USB key ; the application will then create a directory called ""JoplinProfile"" next to the executable file.þmacOS          | <a href='https://github.com/laurent22/joplin/releases/download/v1.0.220/Joplin-1.0.220.dmg'><img alt='Get it on macOS' width=""134px"" src='https://joplinapp.org/images/BadgeMacOS.png'/></a> | You can also use Homebrew (unsupported): `brew cask install joplin`þLinux          | <a href='https://github.com/laurent22/joplin/releases/download/v1.0.220/Joplin-1.0.220.AppImage'><img alt='Get it on Linux' width=""134px"" src='https://joplinapp.org/images/BadgeLinux.png'/></a> | An Arch Linux package (unsupported) [is also available](#terminal-application).<br><br>If it works with your distribution (it has been tested on Ubuntu, Fedora, and Mint; the desktop environments supported are GNOME, KDE, Xfce, MATE, LXQT, LXDE, Unity, Cinnamon, Deepin and Pantheon), the recommended way is to use this script as it will handle the desktop icon too:<br><br> `wget -O - https://raw.githubusercontent.com/laurent22/joplin/master/Joplin_install_and_update.sh \| bash`þþ## Mobile applicationsþþOperating System | Download | Alt. Downloadþ-----------------|----------|----------------þAndroid          | <a href='https://play.google.com/store/apps/details?id=net.cozic.joplin&utm_source=GitHub&utm_campaign=README&pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1'><img alt='Get it on Google Play' height=""40px"" src='https://joplinapp.org/images/BadgeAndroid.png'/></a> | or download the APK file: [64-bit](https://github.com/laurent22/joplin-android/releases/download/android-v1.0.333/joplin-v1.0.333.apk) [32-bit](https://github.com/laurent22/joplin-android/releases/download/android-v1.0.333/joplin-v1.0.333-32bit.apk)þiOS              | <a href='https://itunes.apple.com/us/app/joplin/id1315599797'><img alt='Get it on the App Store' height=""40px"" src='https://joplinapp.org/images/BadgeIOS.png'/></a> | -þþ## Terminal applicationþþOperating system | Methodþ-----------------|----------------þmacOS, Linux, or Windows (via [WSL](https://msdn.microsoft.com/en-us/commandline/wsl/faq?f=255&MSPPError=-2147217396)) | **Important:** First, [install Node 10+](https://nodejs.org/en/download/package-manager/).<br/><br/>`NPM_CONFIG_PREFIX=~/.joplin-bin npm install -g joplin`<br/>`sudo ln -s ~/.joplin-bin/bin/joplin /usr/bin/joplin`<br><br>By default, the application binary will be installed under `~/.joplin-bin`. You may change this directory if needed. Alternatively, if your npm permissions are setup as described [here](https://docs.npmjs.com/getting-started/fixing-npm-permissions#option-2-change-npms-default-directory-to-another-directory) (Option 2) then simply running `npm -g install joplin` would work.þþTo start it, type `joplin`.þþFor usage information, please refer to the full [Joplin Terminal Application Documentation](https://joplinapp.org/terminal/).þþ### Unsupported methodsþþThere are other ways to install the terminal application. However, they are not supported and problems must be reported to the upstream projects.þþOperating system | Methodþ-----------------|----------------þmacOS            | `brew install joplin`þArch Linux       | An Arch Linux package is available [here](https://aur.archlinux.org/packages/joplin/). To install it, use an AUR wrapper such as yay: `yay -S joplin`. Both the CLI tool (type `joplin`) and desktop app (type `joplin-desktop`) are packaged. You can also install a compiled version with the [chaotic-aur](https://wiki.archlinux.org/index.php/Unofficial_user_repositories#chaotic-aur) repository. For support, please go to the [GitHub repo](https://github.com/masterkorp/joplin-pkgbuild).þþ## Web ClipperþþThe Web Clipper is a browser extension that allows you to save web pages and screenshots from your browser. For more information on how to install and use it, see the [Web Clipper Help Page](https://github.com/laurent22/joplin/blob/master/readme/clipper.md).þþ# Sponsorsþþ<a href=""https://seirei.ne.jp""><img title=""Serei Network"" width=""256"" src=""https://joplinapp.org/images/sponsors/SeireiNetwork.png""/></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=""https://usrigging.com/""><img title=""U.S. Ringing Supply"" width=""256"" src=""https://joplinapp.org/images/sponsors/RingingSupply.svg""/></a>þþ* * *þþ|     |     |     |þ| :---: | :---: | :---: |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/6979755?s=96&v=4""/></br>[Devon Zuegel](https://github.com/devonzuegel) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/24908652?s=96&v=4""/></br>[小西　孝宗](https://github.com/konishi-t) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/215668?s=96&v=4""/></br>[Alexander van der Berg](https://github.com/avanderberg)þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/1168659?s=96&v=4""/></br>[Nicholas Head](https://github.com/nicholashead) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/1439535?s=96&v=4""/></br>[Frank Bloise](https://github.com/fbloise) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/15859362?s=96&v=4""/></br>[Thomas Broussard](https://github.com/thomasbroussard)þþ<!-- TOC -->þ# Table of contentsþþ- Applicationsþþ - [Desktop application](https://github.com/laurent22/joplin/blob/master/readme/desktop.md)þ - [Mobile applications](https://github.com/laurent22/joplin/blob/master/readme/mobile.md)þ - [Terminal application](https://github.com/laurent22/joplin/blob/master/readme/terminal.md)þ - [Web Clipper](https://github.com/laurent22/joplin/blob/master/readme/clipper.md)þþ- Supportþþ - [Joplin Forum](https://discourse.joplinapp.org)þ - [Markdown Guide](https://github.com/laurent22/joplin/blob/master/readme/markdown.md)þ - [How to enable end-to-end encryption](https://github.com/laurent22/joplin/blob/master/readme/e2ee.md)þ - [What is a conflict?](https://github.com/laurent22/joplin/blob/master/readme/conflict.md)þ - [End-to-end encryption spec](https://github.com/laurent22/joplin/blob/master/readme/spec.md)þ - [How to enable debug mode](https://github.com/laurent22/joplin/blob/master/readme/debugging.md)þ - [API documentation](https://github.com/laurent22/joplin/blob/master/readme/api.md)þ - [FAQ](https://github.com/laurent22/joplin/blob/master/readme/faq.md)þþ- Google Summer of Code 2020þþ - [Google Summer of Code 2020](https://github.com/laurent22/joplin/blob/master/readme/gsoc2020/index.md)þ - [Project Ideas](https://github.com/laurent22/joplin/blob/master/readme/gsoc2020/ideas.md)þþ- Aboutþþ - [Changelog (Desktop App)](https://github.com/laurent22/joplin/blob/master/readme/changelog.md)þ - [Changelog (CLI App)](https://github.com/laurent22/joplin/blob/master/readme/changelog_cli.md)þ - [Stats](https://github.com/laurent22/joplin/blob/master/readme/stats.md)þ - [Donate](https://github.com/laurent22/joplin/blob/master/readme/donate.md)þ<!-- TOC -->þþ# Featuresþþ- Desktop, mobile and terminal applications.þ- [Web Clipper](https://github.com/laurent22/joplin/blob/master/readme/clipper.md) for Firefox and Chrome.þ- End To End Encryption (E2EE)þ- Note history (revisions)þ- Synchronisation with various services, including Nextcloud, Dropbox, WebDAV and OneDrive.þ- Import Enex files (Evernote export format) and Markdown files.þ- Export JEX files (Joplin Export format) and raw files.þ- Support notes, to-dos, tags and notebooks.þ- Goto Anything feature.þ- Sort notes by multiple criteria - title, updated time, etc.þ- Support for alarms (notifications) in mobile and desktop applications.þ- Offline first, so the entire data is always available on the device even without an internet connection.þ- Markdown notes, which are rendered with images and formatting in the desktop and mobile applications. Support for extra features such as math notation and checkboxes.þ- File attachment support - images are displayed, and other files are linked and can be opened in the relevant application.þ- Search functionality.þ- Geo-location support.þ- Supports multiple languagesþ- External editor support - open notes in your favorite external editor with one click in Joplin.þþ# Importingþþ## Importing from EvernoteþþJoplin was designed as a replacement for Evernote and so can import complete Evernote notebooks, as well as notes, tags, resources (attached files) and note metadata (such as author, geo-location, etc.) via ENEX files. In terms of data, the only two things that might slightly differ are:þþ- Recognition data - Evernote images, in particular scanned (or photographed) documents have [recognition data](https://en.wikipedia.org/wiki/Optical_character_recognition) associated with them. It is the text that Evernote has been able to recognise in the document. This data is not preserved when the note are imported into Joplin. However, should it become supported in the search tool or other parts of Joplin, it should be possible to regenerate this recognition data since the actual image would still be available.þþ- Colour, font sizes and faces - Evernote text is stored as HTML and this is converted to Markdown during the import process. For notes that are mostly plain text or with basic formatting (bold, italic, bullet points, links, etc.) this is a lossless conversion, and the note, once rendered back to HTML should be very similar. Tables are also imported and converted to Markdown tables. For very complex notes, some formatting data might be lost - in particular colours, font sizes and font faces will not be imported. The text itself however is always imported in full regardless of formatting.þþTo import Evernote data, first export your Evernote notebooks to ENEX files as described [here](https://help.evernote.com/hc/en-us/articles/209005557-How-to-back-up-export-and-restore-import-notes-and-notebooks). Then follow these steps:þþIn the **desktop application**, open File > Import > ENEX and select your file. The notes will be imported into a new separate notebook. If needed they can then be moved to a different notebook, or the notebook can be renamed, etc.þþIn the **terminal application**, in [command-line mode](https://github.com/laurent22/joplin/blob/master/readme/terminal.md#command-line-mode), type `import /path/to/file.enex`. This will import the notes into a new notebook named after the filename.þþ## Importing from Markdown filesþþJoplin can import notes from plain Markdown file. You can either import a complete directory of Markdown files or individual files.þþIn the **desktop application**, open File > Import > MD and select your Markdown file or directory.þþIn the **terminal application**, in [command-line mode](https://github.com/laurent22/joplin/blob/master/readme/terminal.md#command-line-mode), type `import --format md /path/to/file.md` or `import --format md /path/to/directory/`.þþ## Importing from other applicationsþþIn general the way to import notes from any application into Joplin is to convert the notes to ENEX files (Evernote format) and to import these ENEX files into Joplin using the method above. Most note-taking applications support ENEX files so it should be relatively straightforward. For help about specific applications, see below:þþ* Standard Notes: Please see [this tutorial](https://programadorwebvalencia.com/migrate-notes-from-standard-notes-to-joplin/)þ* Tomboy Notes: Export the notes to ENEX files [as described here](https://askubuntu.com/questions/243691/how-can-i-export-my-tomboy-notes-into-evernote/608551) for example, and import these ENEX files into Joplin.þ* OneNote: First [import the notes from OneNote into Evernote](https://discussion.evernote.com/topic/107736-is-there-a-way-to-import-from-onenote-into-evernote-on-the-mac/). Then export the ENEX file from Evernote and import it into Joplin.þ* NixNote: Synchronise with Evernote, then export the ENEX files and import them into Joplin. More info [in this thread](https://discourse.joplinapp.org/t/import-from-nixnote/183/3).þþ# ExportingþþJoplin can export to the JEX format (Joplin Export file), which is a tar file that can contain multiple notes, notebooks, etc. This is a lossless format in that all the notes, but also metadata such as geo-location, updated time, tags, etc. are preserved. This format is convenient for backup purposes and can be re-imported into Joplin. A ""raw"" format is also available. This is the same as the JEX format except that the data is saved to a directory and each item represented by a single file.þþ# SynchronisationþþOne of the goals of Joplin was to avoid being tied to any particular company or service, whether it is Evernote, Google or Microsoft. As such the synchronisation is designed without any hard dependency to any particular service. Most of the synchronisation process is done at an abstract level and access to external services, such as Nextcloud or Dropbox, is done via lightweight drivers. It is easy to support new services by creating simple drivers that provide a filesystem-like interface, i.e. the ability to read, write, delete and list items. It is also simple to switch from one service to another or to even sync to multiple services at once. Each note, notebook, tags, as well as the relation between items is transmitted as plain text files during synchronisation, which means the data can also be moved to a different application, can be easily backed up, inspected, etc.þþCurrently, synchronisation is possible with Nextcloud, Dropbox, OneDrive or the local filesystem. To enable synchronisation please follow the instructions below. After that, the application will synchronise in the background whenever it is running, or you can click on ""Synchronise"" to start a synchronisation manually.þþ## Nextcloud synchronisationþþ<img src=""https://joplinapp.org/images/nextcloud-logo-background.png"" width=""100"" align=""left""> <a href=""https://nextcloud.com/"">Nextcloud</a> is a self-hosted, private cloud solution. It can store documents, images and videos but also calendars, passwords and countless other things and can sync them to your laptop or phone. As you can host your own Nextcloud server, you own both the data on your device and infrastructure used for synchronisation. As such it is a good fit for Joplin. The platform is also well supported and with a strong community, so it is likely to be around for a while - since it's open source anyway, it is not a service that can be closed, it can exist on a server for as long as one chooses.þþIn the **desktop application** or **mobile application**, go to the config screen and select Nextcloud as the synchronisation target. Then input the WebDAV URL (to get it, click on Settings in the bottom left corner of the page, in Nextcloud), this is normally `https://example.com/nextcloud/remote.php/webdav/Joplin` (**make sure to create the ""Joplin"" directory in Nextcloud**), and set the username and password. If it does not work, please [see this explanation](https://github.com/laurent22/joplin/issues/61#issuecomment-373282608) for more details.þþIn the **terminal application**, you will need to set the `sync.target` config variable and all the `sync.5.path`, `sync.5.username` and `sync.5.password` config variables to, respectively the Nextcloud WebDAV URL, your username and your password. This can be done from the command line mode using:þþ :config sync.5.path https://example.com/nextcloud/remote.php/webdav/Joplinþ :config sync.5.username YOUR_USERNAMEþ :config sync.5.password YOUR_PASSWORDþ :config sync.target 5þþIf synchronisation does not work, please consult the logs in the app profile directory - it is often due to a misconfigured URL or password. The log should indicate what the exact issue is.þþ## Dropbox synchronisationþþWhen syncing with Dropbox, Joplin creates a sub-directory in Dropbox, in `/Apps/Joplin` and read/write the notes and notebooks from it. The application does not have access to anything outside this directory.þþIn the **desktop application** or **mobile application**, select ""Dropbox"" as the synchronisation target in the config screen (it is selected by default). Then, to initiate the synchronisation process, click on the ""Synchronise"" button in the sidebar and follow the instructions.þþIn the **terminal application**, to initiate the synchronisation process, type `:sync`. You will be asked to follow a link to authorise the application. It is possible to also synchronise outside of the user interface by typing `joplin sync` from the terminal. This can be used to setup a cron script to synchronise at regular interval. For example, this would do it every 30 minutes:þþ */30 * * * * /path/to/joplin syncþþ## WebDAV synchronisationþþSelect the ""WebDAV"" synchronisation target and follow the same instructions as for Nextcloud above.þþWebDAV-compatible services that are known to work with Joplin:þþ- [Apache WebDAV Module](https://httpd.apache.org/docs/current/mod/mod_dav.html)þ- [DriveHQ](https://www.drivehq.com)þ- [Fastmail](https://www.fastmail.com/)þ- [HiDrive](https://www.strato.fr/stockage-en-ligne/) from Strato. [Setup help](https://github.com/laurent22/joplin/issues/309)þ- [Nginx WebDAV Module](https://nginx.org/en/docs/http/ngx_http_dav_module.html)þ- [Nextcloud](https://nextcloud.com/)þ- [OwnCloud](https://owncloud.org/)þ- [Seafile](https://www.seafile.com/)þ- [Stack](https://www.transip.nl/stack/)þ- [WebDAV Nav](https://www.schimera.com/products/webdav-nav-server/), a macOS server.þ- [Zimbra](https://www.zimbra.com/)þþ## OneDrive synchronisationþþWhen syncing with OneDrive, Joplin creates a sub-directory in OneDrive, in /Apps/Joplin and read/write the notes and notebooks from it. The application does not have access to anything outside this directory.þþIn the **desktop application** or **mobile application**, select ""OneDrive"" as the synchronisation target in the config screen. Then, to initiate the synchronisation process, click on the ""Synchronise"" button in the sidebar and follow the instructions.þþIn the **terminal application**, to initiate the synchronisation process, type `:sync`. You will be asked to follow a link to authorise the application (simply input your Microsoft credentials - you do not need to register with OneDrive).þþ# EncryptionþþJoplin supports end-to-end encryption (E2EE) on all the applications. E2EE is a system where only the owner of the notes, notebooks, tags or resources can read them. It prevents potential eavesdroppers - including telecom providers, internet providers, and even the developers of Joplin from being able to access the data. Please see the [End-To-End Encryption Tutorial](https://github.com/laurent22/joplin/blob/master/readme/e2ee.md) for more information about this feature and how to enable it.þþFor a more technical description, mostly relevant for development or to review the method being used, please see the [Encryption specification](https://github.com/laurent22/joplin/blob/master/readme/spec.md).þþ# Note historyþþThe Joplin applications automatically save previous versions of your notes at regular intervals. These versions are synced across devices and can be viewed from the desktop application. To do so, click on the ""Information"" button on a note, then click on ""Previous version of this note"". From this screen you can view the previous versions of the note as well as restore any of them.þþThis feature can be disabled from the ""Note history"" section in the settings, and it is also possible to change for how long the history of a note is saved.þþMore information about this feature in the [announcement post](https://www.patreon.com/posts/note-history-now-27083082).þþ# External text editorþþJoplin notes can be opened and edited using an external editor of your choice. It can be a simple text editor like Notepad++ or Sublime Text or an actual Markdown editor like Typora. In that case, images will also be displayed within the editor. To open the note in an external editor, click on the icon in the toolbar or press Ctrl+E (or Cmd+E). Your default text editor will be used to open the note. If needed, you can also specify the editor directly in the General Options, under ""Text editor command"".þþ# AttachmentsþþAny kind of file can be attached to a note. In Markdown, links to these files are represented as a simple ID to the attachment. In the note viewer, these files, if they are images, will be displayed or, if they are other files (PDF, text files, etc.) they will be displayed as links. Clicking on this link will open the file in the default application.þþIn the **desktop application**, files can be attached either by clicking the ""Attach file"" icon in the editor or via drag and drop. If you prefer to create a link to a local file instead, hold the ALT key while performing the drag and drop operation. You can also copy and paste images directly in the editor via Ctrl+V.þþResources that are not attached to any note will be automatically deleted in accordance to the [Note History](#note-history) settings.þþ**Important:** Resources larger than 10 MB are not currently supported on mobile. They will crash the application when synchronising so it is recommended not to attach such resources at the moment. The issue is being looked at.þþ## Downloading attachmentsþþThe way the attachments are downloaded during synchronisation can be customised in the Configuration screen, under ""Attachment download behaviour"". The default option (""Always"") is to download all the attachments, all the time, so that the data is available even when the device is offline. There is also the option to download the attachments manually (option ""Manual""), by clicking on it, or automatically (Option ""Auto""), in which case the attachments are downloaded only when a note is opened. These options should help saving disk space and network bandwidth, especially on mobile.þþ# NotificationsþþIn the desktop and mobile apps, an alarm can be associated with any to-do. It will be triggered at the given time by displaying a notification. How the notification will be displayed depends on the operating system since each has a different way to handle this. Please see below for the requirements for the desktop applications:þþ- **Windows**: >= 8. Make sure the Action Center is enabled on Windows. Task bar balloon for Windows < 8. Growl as fallback. Growl takes precedence over Windows balloons.þ- **macOS**: >= 10.8 or Growl if earlier.þ- **Linux**: `notify-osd` or `libnotify-bin` installed (Ubuntu should have this by default). Growl otherwiseþþSee [documentation and flow chart for reporter choice](https://github.com/mikaelbr/node-notifier/blob/master/DECISION_FLOW.md)þþOn mobile, the alarms will be displayed using the built-in notification system.þþIf for any reason the notifications do not work, please [open an issue](https://github.com/laurent22/joplin/issues).þþ# Sub-notebooksþþSub-notebooks allow organising multiple notebooks into a tree of notebooks. For example it can be used to regroup all the notebooks related to work, to family or to a particular project under a parent notebook.þþ![](https://joplinapp.org/images/SubNotebooks.png)þþ- In the **desktop application**, to create a subnotebook, drag and drop it onto another notebook. To move it back to the root, drag and drop it on the ""Notebooks"" header. Currently only the desktop app can be used to organise the notebooks.þ- The **mobile application** supports displaying and collapsing/expanding the tree of notebooks, however it does not currently support moving the subnotebooks to different notebooks.þ- The **terminal app** supports displaying the tree of subnotebooks but it does not support collapsing/expanding them or moving the subnotebooks around.þþ# MarkdownþþJoplin uses and renders a Github-flavoured Markdown with a few variations and additions. In particular it adds math formula support, interactive checkboxes and support for note links. Joplin also supports Markdown plugins which allow enabling and disabling various advanced Markdown features. Have a look at the [Markdown Guide](https://github.com/laurent22/joplin/blob/master/readme/markdown.md) for more information.þþ# Custom CSSþþRendered markdown can be customized by placing a userstyle file in the profile directory `~/.config/joplin-desktop/userstyle.css` (This path might be different on your device - check at the top of the Config screen for the exact path). This file supports standard CSS syntax. Joplin ***must*** be restarted for the new css to be applied, please ensure that Joplin is not closing to the tray, but is actually exiting. Note that this file is used for both displaying the notes and printing the notes. Be aware how the CSS may look printed (for example, printing white text over a black background is usually not wanted).þþThe whole UI can be customized by placing a custom editor style file in the profile directory `~/.config/joplin-desktop/userchrome.css`.þþImportant: userstyle.css and userchrome.css are provided for your convenience, but they are advanced settings, and styles you define may break from one version to the next. If you want to use them, please know that it might require regular development work from you to keep them working. The Joplin team cannot make a commitment to keep the application HTML structure stable.þþ# Note templatesþþIn the **desktop app**, templates can be used to create new notes or to insert into existing ones by creating a `templates` folder in Joplin's config folder and placing Markdown template files into it. For example creating the file `hours.md` in the `templates` directory with the contents:þþ```markdownþDate: {{date}}þHours:þDetails:þ```þþTemplates can then be inserted from the menu (File->Templates).þþThe currently supported template variables are:þþ| Variable | Description | Example |þ| --- | --- | --- |þ| `{{date}}` | Today's date formatted based on the settings format | 2019-01-01 |þ| `{{time}}` | Current time formatted based on the settings format | 13:00 |þ| `{{datetime}}` | Current date and time formatted based on the settings format | 01/01/19 1:00 PM |þ| `{{#custom_datetime}}` | Current date and/or time formatted based on a supplied string (using [moment.js](https://momentjs.com/) formatting) | `{{#custom_datetime}}M d{{/custom_datetime}}` |þþ# SearchingþþJoplin implements the SQLite Full Text Search (FTS4) extension. It means the content of all the notes is indexed in real time and search queries return results very fast. Both [Simple FTS Queries](https://www.sqlite.org/fts3.html#simple_fts_queries) and [Full-Text Index Queries](https://www.sqlite.org/fts3.html#full_text_index_queries) are supported. See below for the list of supported queries:þþSearch type | Description | Exampleþ------------|-------------|---------þSingle word | Returns all the notes that contain this term. | For example, searching for `cat` will return all the notes that contain this exact word. Note: it will not return the notes that contain the substring - thus, for ""cat"", notes that contain ""cataclysmic"" or ""prevaricate"" will **not** be returned.þMultiple word | Returns all the notes that contain **all** these words, but not necessarily next to each other. | `dog cat` - will return any notes that contain the words ""dog"" and ""cat"" anywhere in the note, no necessarily in that order nor next to each other. It will **not** return results that contain ""dog"" or ""cat"" only.þPhrase | Add double quotes to return the notes that contain exactly this phrase. | `""shopping list""` - will return the notes that contain these **exact terms** next to each other and in this order. It will **not** return for example a note that contains ""going shopping with my list"".þPrefix | Add a wildcard to return all the notes that contain a term with a specified prefix. | `swim*` - will return all the notes that contain eg. ""swim"", but also ""swimming"", ""swimsuit"", etc. IMPORTANT: The wildcard **can only be at the end** - it will be ignored at the beginning of a word (eg. `*swim`) and will be treated as a literal asterisk in the middle of a word (eg. `ast*rix`)þField restricted | Add either `title:` or `body:` before a note to restrict your search to just the title, or just the body. | `title:shopping`, `body:egg`þSwitch to basic search | One drawback of Full Text Search is that it ignores most non-alphabetical characters. However in some cases you might want to search for this too. To do that, you can use basic search. You switch to this mode by prefixing your search with a slash `/`. This won't provide the benefits of FTS but it will allow searching exactly for what you need. Note that it can also be much slower, even extremely slow, depending on your query. | `/""- [ ]""` - will return all the notes that contain unchecked checkboxes.þþNotes are sorted by ""relevance"". Currently it means the notes that contain the requested terms the most times are on top. For queries with multiple terms, it also matters how close to each other the terms are. This is a bit experimental so if you notice a search query that returns unexpected results, please report it in the forum, providing as many details as possible to replicate the issue.þþ# Goto AnythingþþIn the desktop application, press <kbd>Ctrl+G</kbd> or <kbd>Cmd+G</kbd> and type a note title or part of its content to jump to it. Or type <kbd>#</kbd> followed by a tag name, or <kbd>@</kbd> followed by a notebook name.þþ# PrivacyþþJoplin values your privacy and security by giving you complete control over your information and digital footprint.þþJoplin applications do not send any data to any service without your authorisation. Any data that Joplin saves, such as notes or images, are saved to your own device and you are free to delete this data at any time.þþJoplin has many modern features, some of which use third-party services. You can disable any or all of these features in the application settings. These features are:þþ|Feature | Description | Default|þ|--------|-------------|--------|þ|Auto-update|Joplin periodically connects to GitHub to check for new releases.|Enabled|þ|Geo-location|Joplin saves geo-location information in note properties when you create a note.|Enabled|þ|Synchronisation|Joplin supports synchronisation of your notes across multiple devices. If you choose to synchronise with a third-party, such as OneDrive, the notes will be sent to your OneDrive account, in which case the third-party privacy policy applies.|Disabled|þþJoplin is developed as an open-source application and the source code is freely available online to inspect.þþFor any question about Joplin privacy, please leave a message on the [Joplin Forum](https://discourse.joplinapp.org/).þþ# DonationsþþDonations to Joplin support the development of the project. Developing quality applications mostly takes time, but there are also some expenses, such as digital certificates to sign the applications, app store fees, hosting, etc. Most of all, your donation will make it possible to keep up the current development standard.þþPlease see the [donation page](https://github.com/laurent22/joplin/blob/master/readme/donate.md) for information on how to support the development of Joplin.þþ# Communityþþ- For general discussion about Joplin, user support, software development questions, and to discuss new features, go to the [Joplin Forum](https://discourse.joplinapp.org/). It is possible to login with your GitHub account.þ- Also see here for information about [the latest releases and general news](https://discourse.joplinapp.org/c/news).þ- For bug reports go to the [GitHub Issue Tracker](https://github.com/laurent22/joplin/issues). Please follow the template accordingly.þ- Feature requests must not be opened on GitHub unless they have been discussed and accepted on the forum.þ- The latest news are posted [on the Patreon page](https://www.patreon.com/joplin).þ- You can also follow us on <a rel=""me"" href=""https://mastodon.social/@joplinapp"">the Mastodon feed</a> or [the Twitter feed](https://twitter.com/joplinapp).þ- You can join the live community on [the JoplinApp discord server](https://discordapp.com/invite/d2HMPwE) to get help with Joplin or to discuss anything Joplin related.þþ# ContributingþþPlease see the guide for information on how to contribute to the development of Joplin: https://github.com/laurent22/joplin/blob/master/CONTRIBUTING.mdþþ# LocalisationþþJoplin is currently available in the languages below. If you would like to contribute a **new translation**, it is quite straightforward, please follow these steps:þþ- [Download Poedit](https://poedit.net/), the translation editor, and install it.þ- [Download the file to be translated](https://raw.githubusercontent.com/laurent22/joplin/master/CliClient/locales/joplin.pot).þ- In Poedit, open this .pot file, go into the Catalog menu and click Configuration. Change ""Country"" and ""Language"" to your own country and language.þ- From then you can translate the file.þ- Once it is done, please [open a pull request](https://github.com/laurent22/joplin/pulls) and add the file to it.þþThis translation will apply to the three applications - desktop, mobile and terminal.þþTo **update a translation**, follow the same steps as above but instead of getting the .pot file, get the .po file for your language from the table below.þþCurrent translations:þþ<!-- LOCALE-TABLE-AUTO-GENERATED -->þ&nbsp;  |  Language  |  Po File  |  Last translator  |  Percent doneþ---|---|---|---|---þ![](https://joplinapp.org/images/flags/country-4x3/arableague.png)  |  Arabic  |  [ar](https://github.com/laurent22/joplin/blob/master/CliClient/locales/ar.po)  |  أحمد باشا إبراهيم (fi_ahmed_bacha@esi.dz)  |  83%þ![](https://joplinapp.org/images/flags/es/basque_country.png)  |  Basque  |  [eu](https://github.com/laurent22/joplin/blob/master/CliClient/locales/eu.po)  |  juan.abasolo@ehu.eus  |  35%þ![](https://joplinapp.org/images/flags/country-4x3/ba.png)  |  Bosnian  |  [bs_BA](https://github.com/laurent22/joplin/blob/master/CliClient/locales/bs_BA.po)  |  Derviš T. (dervis.t@pm.me)  |  87%þ![](https://joplinapp.org/images/flags/country-4x3/bg.png)  |  Bulgarian  |  [bg_BG](https://github.com/laurent22/joplin/blob/master/CliClient/locales/bg_BG.po)  |    |  69%þ![](https://joplinapp.org/images/flags/es/catalonia.png)  |  Catalan  |  [ca](https://github.com/laurent22/joplin/blob/master/CliClient/locales/ca.po)  |  jmontane, 2019  |  55%þ![](https://joplinapp.org/images/flags/country-4x3/hr.png)  |  Croatian  |  [hr_HR](https://github.com/laurent22/joplin/blob/master/CliClient/locales/hr_HR.po)  |  Hrvoje Mandić (trbuhom@net.hr)  |  29%þ![](https://joplinapp.org/images/flags/country-4x3/cz.png)  |  Czech  |  [cs_CZ](https://github.com/laurent22/joplin/blob/master/CliClient/locales/cs_CZ.po)  |  Lukas Helebrandt (lukas@aiya.cz)  |  86%þ![](https://joplinapp.org/images/flags/country-4x3/dk.png)  |  Dansk  |  [da_DK](https://github.com/laurent22/joplin/blob/master/CliClient/locales/da_DK.po)  |  Morten Juhl-Johansen Zölde-Fejér (mjjzf@syntaktisk.  |  77%þ![](https://joplinapp.org/images/flags/country-4x3/de.png)  |  Deutsch  |  [de_DE](https://github.com/laurent22/joplin/blob/master/CliClient/locales/de_DE.po)  |  Eike (ei-ke@users.noreply.github.com)  |  97%þ![](https://joplinapp.org/images/flags/country-4x3/ee.png)  |  Eesti Keel  |  [et_EE](https://github.com/laurent22/joplin/blob/master/CliClient/locales/et_EE.po)  |    |  69%þ![](https://joplinapp.org/images/flags/country-4x3/gb.png)  |  English (UK)  |  [en_GB](https://github.com/laurent22/joplin/blob/master/CliClient/locales/en_GB.po)  |    |  100%þ![](https://joplinapp.org/images/flags/country-4x3/us.png)  |  English (US)  |  [en_US](https://github.com/laurent22/joplin/blob/master/CliClient/locales/en_US.po)  |    |  100%þ![](https://joplinapp.org/images/flags/country-4x3/es.png)  |  Español  |  [es_ES](https://github.com/laurent22/joplin/blob/master/CliClient/locales/es_ES.po)  |  Fernando Pindado (fpindado@gmail.com)  |  93%þ![](https://joplinapp.org/images/flags/esperanto.png)  |  Esperanto  |  [eo](https://github.com/laurent22/joplin/blob/master/CliClient/locales/eo.po)  |  Marton Paulo  |  40%þ![](https://joplinapp.org/images/flags/country-4x3/fr.png)  |  Français  |  [fr_FR](https://github.com/laurent22/joplin/blob/master/CliClient/locales/fr_FR.po)  |  Laurent Cozic  |  98%þ![](https://joplinapp.org/images/flags/es/galicia.png)  |  Galician  |  [gl_ES](https://github.com/laurent22/joplin/blob/master/CliClient/locales/gl_ES.po)  |  Marcos Lans (marcoslansgarza@gmail.com)  |  45%þ![](https://joplinapp.org/images/flags/country-4x3/id.png)  |  Indonesian  |  [id_ID](https://github.com/laurent22/joplin/blob/master/CliClient/locales/id_ID.po)  |  Fathy AR (16875937+fathyar@users.noreply.github.com)  |  97%þ![](https://joplinapp.org/images/flags/country-4x3/it.png)  |  Italiano  |  [it_IT](https://github.com/laurent22/joplin/blob/master/CliClient/locales/it_IT.po)  |  StarFang208  |  94%þ![](https://joplinapp.org/images/flags/country-4x3/nl.png)  |  Nederlands  |  [nl_NL](https://github.com/laurent22/joplin/blob/master/CliClient/locales/nl_NL.po)  |  TheoDutch (theo1@mailfence.com)  |  88%þ![](https://joplinapp.org/images/flags/country-4x3/be.png)  |  Nederlands  |  [nl_BE](https://github.com/laurent22/joplin/blob/master/CliClient/locales/nl_BE.po)  |    |  35%þ![](https://joplinapp.org/images/flags/country-4x3/no.png)  |  Norwegian  |  [nb_NO](https://github.com/laurent22/joplin/blob/master/CliClient/locales/nb_NO.po)  |  Mats Estensen (code@mxe.no)  |  92%þ![](https://joplinapp.org/images/flags/country-4x3/ir.png)  |  Persian  |  [fa](https://github.com/laurent22/joplin/blob/master/CliClient/locales/fa.po)  |  Mehrad Mahmoudian (mehrad@mahmoudian.me)  |  35%þ![](https://joplinapp.org/images/flags/country-4x3/pl.png)  |  Polski  |  [pl_PL](https://github.com/laurent22/joplin/blob/master/CliClient/locales/pl_PL.po)  |    |  88%þ![](https://joplinapp.org/images/flags/country-4x3/pt.png)  |  Português  |  [pt_PT](https://github.com/laurent22/joplin/blob/master/CliClient/locales/pt_PT.po)  |  Diogo Caveiro   |  92%þ![](https://joplinapp.org/images/flags/country-4x3/br.png)  |  Português (Brasil)  |  [pt_BR](https://github.com/laurent22/joplin/blob/master/CliClient/locales/pt_BR.po)  |  Renato Nunes Bastos (rnbastos@gmail.com)  |  99%þ![](https://joplinapp.org/images/flags/country-4x3/ro.png)  |  Română  |  [ro](https://github.com/laurent22/joplin/blob/master/CliClient/locales/ro.po)  |    |  35%þ![](https://joplinapp.org/images/flags/country-4x3/si.png)  |  Slovenian  |  [sl_SI](https://github.com/laurent22/joplin/blob/master/CliClient/locales/sl_SI.po)  |    |  44%þ![](https://joplinapp.org/images/flags/country-4x3/se.png)  |  Svenska  |  [sv](https://github.com/laurent22/joplin/blob/master/CliClient/locales/sv.po)  |  Jonatan Nyberg (jonatan@autistici.org)  |  74%þ![](https://joplinapp.org/images/flags/country-4x3/th.png)  |  Thai  |  [th_TH](https://github.com/laurent22/joplin/blob/master/CliClient/locales/th_TH.po)  |    |  55%þ![](https://joplinapp.org/images/flags/country-4x3/.png)  |  Tiếng Việt  |  [vi](https://github.com/laurent22/joplin/blob/master/CliClient/locales/vi.po)  |    |  89%þ![](https://joplinapp.org/images/flags/country-4x3/tr.png)  |  Türkçe  |  [tr_TR](https://github.com/laurent22/joplin/blob/master/CliClient/locales/tr_TR.po)  |  Arda Kılıçdağı (arda@kilicdagi.com)  |  98%þ![](https://joplinapp.org/images/flags/country-4x3/gr.png)  |  Ελληνικά  |  [el_GR](https://github.com/laurent22/joplin/blob/master/CliClient/locales/el_GR.po)  |  Harris Arvanitis (xaris@tuta.io)  |  94%þ![](https://joplinapp.org/images/flags/country-4x3/ru.png)  |  Русский  |  [ru_RU](https://github.com/laurent22/joplin/blob/master/CliClient/locales/ru_RU.po)  |  Sergey Segeda (thesermanarm@gmail.com)  |  92%þ![](https://joplinapp.org/images/flags/country-4x3/rs.png)  |  српски језик  |  [sr_RS](https://github.com/laurent22/joplin/blob/master/CliClient/locales/sr_RS.po)  |    |  75%þ![](https://joplinapp.org/images/flags/country-4x3/cn.png)  |  中文 (简体)  |  [zh_CN](https://github.com/laurent22/joplin/blob/master/CliClient/locales/zh_CN.po)  |  yaozeye@outlook.com  |  97%þ![](https://joplinapp.org/images/flags/country-4x3/tw.png)  |  中文 (繁體)  |  [zh_TW](https://github.com/laurent22/joplin/blob/master/CliClient/locales/zh_TW.po)  |  Ethan Chen (ethan42411@gmail.com)  |  93%þ![](https://joplinapp.org/images/flags/country-4x3/jp.png)  |  日本語  |  [ja_JP](https://github.com/laurent22/joplin/blob/master/CliClient/locales/ja_JP.po)  |  genneko (genneko217@gmail.com)  |  97%þ![](https://joplinapp.org/images/flags/country-4x3/kr.png)  |  한국어  |  [ko](https://github.com/laurent22/joplin/blob/master/CliClient/locales/ko.po)  |    |  90%þ<!-- LOCALE-TABLE-AUTO-GENERATED -->þþ# ContributorsþþThank you to everyone who've contributed to Joplin's source code!þþ<!-- CONTRIBUTORS-TABLE-AUTO-GENERATED -->þ|     |     |     |     |     |þ| :---: | :---: | :---: | :---: | :---: |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/1285584?v=4""/></br>[laurent22](https://api.github.com/users/laurent22) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/223439?v=4""/></br>[tessus](https://api.github.com/users/tessus) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/1732810?v=4""/></br>[mic704b](https://api.github.com/users/mic704b) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/2179547?v=4""/></br>[CalebJohn](https://api.github.com/users/CalebJohn) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/3542031?v=4""/></br>[PackElend](https://api.github.com/users/PackElend) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/4553672?v=4""/></br>[tanrax](https://api.github.com/users/tanrax) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/8701534?v=4""/></br>[rtmkrlv](https://api.github.com/users/rtmkrlv) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/10997189?v=4""/></br>[fmrtn](https://api.github.com/users/fmrtn) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/29672555?v=4""/></br>[genneko](https://api.github.com/users/genneko) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/6979755?v=4""/></br>[devonzuegel](https://api.github.com/users/devonzuegel) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/16101778?v=4""/></br>[gabcoh](https://api.github.com/users/gabcoh) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/10927304?v=4""/></br>[matsest](https://api.github.com/users/matsest) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/6319051?v=4""/></br>[abonte](https://api.github.com/users/abonte) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/1685517?v=4""/></br>[Abijeet](https://api.github.com/users/Abijeet) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/27751740?v=4""/></br>[ishantgupta777](https://api.github.com/users/ishantgupta777) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/208212?v=4""/></br>[foxmask](https://api.github.com/users/foxmask) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/6557454?v=4""/></br>[innocuo](https://api.github.com/users/innocuo) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/26695184?v=4""/></br>[anjulalk](https://api.github.com/users/anjulalk) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/44024553?v=4""/></br>[rabeehrz](https://api.github.com/users/rabeehrz) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/35633575?v=4""/></br>[coderrsid](https://api.github.com/users/coderrsid) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/4237724?v=4""/></br>[alexdevero](https://api.github.com/users/alexdevero) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/35904727?v=4""/></br>[Runo-saduwa](https://api.github.com/users/Runo-saduwa) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/5365582?v=4""/></br>[marcosvega91](https://api.github.com/users/marcosvega91) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/37639389?v=4""/></br>[petrz12](https://api.github.com/users/petrz12) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/3194829?v=4""/></br>[moltenform](https://api.github.com/users/moltenform) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/5199995?v=4""/></br>[zuphilip](https://api.github.com/users/zuphilip) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/1904967?v=4""/></br>[readingsnail](https://api.github.com/users/readingsnail) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/3985557?v=4""/></br>[XarisA](https://api.github.com/users/XarisA) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/4245227?v=4""/></br>[zblesk](https://api.github.com/users/zblesk) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/31567272?v=4""/></br>[0ndrey](https://api.github.com/users/0ndrey) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/12906090?v=4""/></br>[amitsin6h](https://api.github.com/users/amitsin6h) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/23281486?v=4""/></br>[martonpaulo](https://api.github.com/users/martonpaulo) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/4497566?v=4""/></br>[rccavalcanti](https://api.github.com/users/rccavalcanti) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/54268438?v=4""/></br>[Rahulm2310](https://api.github.com/users/Rahulm2310) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/559346?v=4""/></br>[metbril](https://api.github.com/users/metbril) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/1540054?v=4""/></br>[ShaneKilkelly](https://api.github.com/users/ShaneKilkelly) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/6734573?v=4""/></br>[stweil](https://api.github.com/users/stweil) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/937861?v=4""/></br>[archont00](https://api.github.com/users/archont00) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/32770029?v=4""/></br>[bradmcl](https://api.github.com/users/bradmcl) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/22592201?v=4""/></br>[tfinnberg](https://api.github.com/users/tfinnberg) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/3870964?v=4""/></br>[marcushill](https://api.github.com/users/marcushill) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/102242?v=4""/></br>[nathanleiby](https://api.github.com/users/nathanleiby) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/226708?v=4""/></br>[RaphaelKimmig](https://api.github.com/users/RaphaelKimmig) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/17768566?v=4""/></br>[RenatoXSR](https://api.github.com/users/RenatoXSR) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/36303913?v=4""/></br>[sensor-freak](https://api.github.com/users/sensor-freak) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/2063957?v=4""/></br>[Ardakilic](https://api.github.com/users/Ardakilic) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/21161146?v=4""/></br>[BartBucknill](https://api.github.com/users/BartBucknill) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/2494769?v=4""/></br>[mrwulf](https://api.github.com/users/mrwulf) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/560571?v=4""/></br>[chrisb86](https://api.github.com/users/chrisb86) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/1686759?v=4""/></br>[chrmoritz](https://api.github.com/users/chrmoritz) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/5001259?v=4""/></br>[ethan42411](https://api.github.com/users/ethan42411) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/2733783?v=4""/></br>[JOJ0](https://api.github.com/users/JOJ0) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/3140223?v=4""/></br>[jdrobertso](https://api.github.com/users/jdrobertso) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/339645?v=4""/></br>[jmontane](https://api.github.com/users/jmontane) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/4168339?v=4""/></br>[solariz](https://api.github.com/users/solariz) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/390889?v=4""/></br>[mmahmoudian](https://api.github.com/users/mmahmoudian) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/25288?v=4""/></br>[maicki](https://api.github.com/users/maicki) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/2136373?v=4""/></br>[mjjzf](https://api.github.com/users/mjjzf) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/30305957?v=4""/></br>[naviji](https://api.github.com/users/naviji) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/27608187?v=4""/></br>[rt-oliveira](https://api.github.com/users/rt-oliveira) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/54576074?v=4""/></br>[Rishgod](https://api.github.com/users/Rishgod) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/2486806?v=4""/></br>[sebastienjust](https://api.github.com/users/sebastienjust) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/28362310?v=4""/></br>[sealch](https://api.github.com/users/sealch) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/34258070?v=4""/></br>[StarFang208](https://api.github.com/users/StarFang208) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/1782292?v=4""/></br>[SubodhDahal](https://api.github.com/users/SubodhDahal) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/5912371?v=4""/></br>[TobiasDev](https://api.github.com/users/TobiasDev) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/692072?v=4""/></br>[conyx](https://api.github.com/users/conyx) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/5730052?v=4""/></br>[vsimkus](https://api.github.com/users/vsimkus) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/4079047?v=4""/></br>[Zorbeyd](https://api.github.com/users/Zorbeyd) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/5077221?v=4""/></br>[axq](https://api.github.com/users/axq) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/8808502?v=4""/></br>[barbowza](https://api.github.com/users/barbowza) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/4316805?v=4""/></br>[lightray22](https://api.github.com/users/lightray22) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/17399340?v=4""/></br>[pf-siedler](https://api.github.com/users/pf-siedler) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/17232523?v=4""/></br>[ruuti](https://api.github.com/users/ruuti) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/23638148?v=4""/></br>[s1nceri7y](https://api.github.com/users/s1nceri7y) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/10117386?v=4""/></br>[kornava](https://api.github.com/users/kornava) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/7471938?v=4""/></br>[ShuiHuo](https://api.github.com/users/ShuiHuo) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/11596277?v=4""/></br>[ikunya](https://api.github.com/users/ikunya) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/59133880?v=4""/></br>[bedwardly-down](https://api.github.com/users/bedwardly-down) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/47456195?v=4""/></br>[hexclover](https://api.github.com/users/hexclover) |þ| <img width=""50"" src=""https://avatars2.githubusercontent.com/u/45535789?v=4""/></br>[2jaeyeol](https://api.github.com/users/2jaeyeol) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/15862474?v=4""/></br>[aaronxn](https://api.github.com/users/aaronxn) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/3660978?v=4""/></br>[alanfortlink](https://api.github.com/users/alanfortlink) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/14836659?v=4""/></br>[apankratov](https://api.github.com/users/apankratov) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/7045739?v=4""/></br>[teterkin](https://api.github.com/users/teterkin) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/41290751?v=4""/></br>[serenitatis](https://api.github.com/users/serenitatis) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/4408379?v=4""/></br>[lex111](https://api.github.com/users/lex111) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/5417051?v=4""/></br>[tekdel](https://api.github.com/users/tekdel) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/498326?v=4""/></br>[Shaxine](https://api.github.com/users/Shaxine) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/201215?v=4""/></br>[assimd](https://api.github.com/users/assimd) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/42698687?v=4""/></br>[baymoe](https://api.github.com/users/baymoe) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/7034200?v=4""/></br>[bimlas](https://api.github.com/users/bimlas) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/16287077?v=4""/></br>[carlbordum](https://api.github.com/users/carlbordum) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/105843?v=4""/></br>[chaifeng](https://api.github.com/users/chaifeng) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/549349?v=4""/></br>[charles-e](https://api.github.com/users/charles-e) |þ| <img width=""50"" src=""https://avatars2.githubusercontent.com/u/2348463?v=4""/></br>[Techwolf12](https://api.github.com/users/Techwolf12) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/2282880?v=4""/></br>[cloudtrends](https://api.github.com/users/cloudtrends) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/1044056?v=4""/></br>[daniellandau](https://api.github.com/users/daniellandau) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/26189247?v=4""/></br>[daukadolt](https://api.github.com/users/daukadolt) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/28535750?v=4""/></br>[NeverMendel](https://api.github.com/users/NeverMendel) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/11378282?v=4""/></br>[diego-betto](https://api.github.com/users/diego-betto) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/215270?v=4""/></br>[erdody](https://api.github.com/users/erdody) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/10371667?v=4""/></br>[domgoodwin](https://api.github.com/users/domgoodwin) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/72066?v=4""/></br>[b4mboo](https://api.github.com/users/b4mboo) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/5131923?v=4""/></br>[donbowman](https://api.github.com/users/donbowman) |þ| <img width=""50"" src=""https://avatars2.githubusercontent.com/u/47756?v=4""/></br>[dflock](https://api.github.com/users/dflock) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/7990534?v=4""/></br>[drobilica](https://api.github.com/users/drobilica) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/1962738?v=4""/></br>[einverne](https://api.github.com/users/einverne) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/628474?v=4""/></br>[Atalanttore](https://api.github.com/users/Atalanttore) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/16492558?v=4""/></br>[eodeluga](https://api.github.com/users/eodeluga) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/3057302?v=4""/></br>[fer22f](https://api.github.com/users/fer22f) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/43272148?v=4""/></br>[fpindado](https://api.github.com/users/fpindado) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/1714374?v=4""/></br>[FleischKarussel](https://api.github.com/users/FleischKarussel) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/18525376?v=4""/></br>[talkdirty](https://api.github.com/users/talkdirty) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/6190183?v=4""/></br>[gmag11](https://api.github.com/users/gmag11) |þ| <img width=""50"" src=""https://avatars2.githubusercontent.com/u/24235344?v=4""/></br>[guiemi](https://api.github.com/users/guiemi) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/2257024?v=4""/></br>[gusbemacbe](https://api.github.com/users/gusbemacbe) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/18524580?v=4""/></br>[Fvbor](https://api.github.com/users/Fvbor) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/22606250?v=4""/></br>[bennetthanna](https://api.github.com/users/bennetthanna) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/3379379?v=4""/></br>[sczhg](https://api.github.com/users/sczhg) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/1716229?v=4""/></br>[Vistaus](https://api.github.com/users/Vistaus) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/19862172?v=4""/></br>[iahmedbacha](https://api.github.com/users/iahmedbacha) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/1533624?v=4""/></br>[IrvinDominin](https://api.github.com/users/IrvinDominin) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/33200024?v=4""/></br>[ishammahajan](https://api.github.com/users/ishammahajan) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/19985741?v=4""/></br>[JRaiden16](https://api.github.com/users/JRaiden16) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/11466782?v=4""/></br>[jacobherrington](https://api.github.com/users/jacobherrington) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/9365179?v=4""/></br>[jamesadjinwa](https://api.github.com/users/jamesadjinwa) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/4995433?v=4""/></br>[jaredcrowe](https://api.github.com/users/jaredcrowe) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/4374338?v=4""/></br>[potatogim](https://api.github.com/users/potatogim) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/163555?v=4""/></br>[JoelRSimpson](https://api.github.com/users/JoelRSimpson) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/6965062?v=4""/></br>[joeltaylor](https://api.github.com/users/joeltaylor) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/242107?v=4""/></br>[exic](https://api.github.com/users/exic) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/23194385?v=4""/></br>[jony0008](https://api.github.com/users/jony0008) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/6048003?v=4""/></br>[joybinchen](https://api.github.com/users/joybinchen) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/1560189?v=4""/></br>[y-usuzumi](https://api.github.com/users/y-usuzumi) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/1660460?v=4""/></br>[xuhcc](https://api.github.com/users/xuhcc) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/16933735?v=4""/></br>[kirtanprht](https://api.github.com/users/kirtanprht) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/7824233?v=4""/></br>[kklas](https://api.github.com/users/kklas) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/8622992?v=4""/></br>[xmlangel](https://api.github.com/users/xmlangel) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/1055100?v=4""/></br>[troilus](https://api.github.com/users/troilus) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/50335724?v=4""/></br>[Lorinson](https://api.github.com/users/Lorinson) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/2599210?v=4""/></br>[lboullo0](https://api.github.com/users/lboullo0) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/1562062?v=4""/></br>[dbinary](https://api.github.com/users/dbinary) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/5699725?v=4""/></br>[mvonmaltitz](https://api.github.com/users/mvonmaltitz) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/11036464?v=4""/></br>[mlkood](https://api.github.com/users/mlkood) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/5788516?v=4""/></br>[Marmo](https://api.github.com/users/Marmo) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/640949?v=4""/></br>[freaktechnik](https://api.github.com/users/freaktechnik) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/12831489?v=4""/></br>[mgroth0](https://api.github.com/users/mgroth0) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/21796?v=4""/></br>[silentmatt](https://api.github.com/users/silentmatt) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/51273874?v=4""/></br>[MichipX](https://api.github.com/users/MichipX) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/53177864?v=4""/></br>[MrTraduttore](https://api.github.com/users/MrTraduttore) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/9076687?v=4""/></br>[NJannasch](https://api.github.com/users/NJannasch) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/12369770?v=4""/></br>[Ouvill](https://api.github.com/users/Ouvill) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/43815417?v=4""/></br>[shorty2380](https://api.github.com/users/shorty2380) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/19418601?v=4""/></br>[Rakleed](https://api.github.com/users/Rakleed) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/6306608?v=4""/></br>[Diadlo](https://api.github.com/users/Diadlo) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/13197246?v=4""/></br>[R-L-T-Y](https://api.github.com/users/R-L-T-Y) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/42652941?v=4""/></br>[rajprakash00](https://api.github.com/users/rajprakash00) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/54888685?v=4""/></br>[RedDocMD](https://api.github.com/users/RedDocMD) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/17312341?v=4""/></br>[reinhart1010](https://api.github.com/users/reinhart1010) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/744655?v=4""/></br>[ruzaq](https://api.github.com/users/ruzaq) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/19328605?v=4""/></br>[SamuelBlickle](https://api.github.com/users/SamuelBlickle) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/1776?v=4""/></br>[bronson](https://api.github.com/users/bronson) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/24606935?v=4""/></br>[semperor](https://api.github.com/users/semperor) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/7091080?v=4""/></br>[sinkuu](https://api.github.com/users/sinkuu) |þ| <img width=""50"" src=""https://avatars2.githubusercontent.com/u/9937486?v=4""/></br>[SFoskitt](https://api.github.com/users/SFoskitt) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/505011?v=4""/></br>[kcrt](https://api.github.com/users/kcrt) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/538584?v=4""/></br>[xissy](https://api.github.com/users/xissy) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/466122?v=4""/></br>[Tekki](https://api.github.com/users/Tekki) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/21969426?v=4""/></br>[TheoDutch](https://api.github.com/users/TheoDutch) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/8731922?v=4""/></br>[tbroadley](https://api.github.com/users/tbroadley) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/114300?v=4""/></br>[Kriechi](https://api.github.com/users/Kriechi) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/3457339?v=4""/></br>[tkilaker](https://api.github.com/users/tkilaker) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/4201229?v=4""/></br>[tcyrus](https://api.github.com/users/tcyrus) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/834914?v=4""/></br>[tobias-grasse](https://api.github.com/users/tobias-grasse) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/6691273?v=4""/></br>[strobeltobias](https://api.github.com/users/strobeltobias) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/70296?v=4""/></br>[tbergeron](https://api.github.com/users/tbergeron) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/10265443?v=4""/></br>[Ullas-Aithal](https://api.github.com/users/Ullas-Aithal) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/6104498?v=4""/></br>[MyTheValentinus](https://api.github.com/users/MyTheValentinus) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/26511487?v=4""/></br>[WisdomCode](https://api.github.com/users/WisdomCode) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/1921957?v=4""/></br>[xsak](https://api.github.com/users/xsak) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/11031696?v=4""/></br>[ymitsos](https://api.github.com/users/ymitsos) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/29891001?v=4""/></br>[jyuvaraj03](https://api.github.com/users/jyuvaraj03) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/15380913?v=4""/></br>[kowalskidev](https://api.github.com/users/kowalskidev) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/63324960?v=4""/></br>[abolishallprivateproperty](https://api.github.com/users/abolishallprivateproperty) |þ| <img width=""50"" src=""https://avatars2.githubusercontent.com/u/11336076?v=4""/></br>[aerotog](https://api.github.com/users/aerotog) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/49116134?v=4""/></br>[anihm136](https://api.github.com/users/anihm136) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/35600612?v=4""/></br>[boring10](https://api.github.com/users/boring10) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/35413451?v=4""/></br>[chenlhlinux](https://api.github.com/users/chenlhlinux) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/30935096?v=4""/></br>[cybertramp](https://api.github.com/users/cybertramp) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/9694906?v=4""/></br>[delta-emil](https://api.github.com/users/delta-emil) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/926263?v=4""/></br>[doc75](https://api.github.com/users/doc75) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/2903013?v=4""/></br>[ebayer](https://api.github.com/users/ebayer) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/701050?v=4""/></br>[espinosa](https://api.github.com/users/espinosa) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/18619090?v=4""/></br>[exponentactivity](https://api.github.com/users/exponentactivity) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/16708935?v=4""/></br>[exprez135](https://api.github.com/users/exprez135) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/9768112?v=4""/></br>[fab4x](https://api.github.com/users/fab4x) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/47755037?v=4""/></br>[fabianski7](https://api.github.com/users/fabianski7) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/14201321?v=4""/></br>[rasperepodvipodvert](https://api.github.com/users/rasperepodvipodvert) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/748808?v=4""/></br>[gasolin](https://api.github.com/users/gasolin) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/47191051?v=4""/></br>[githubaccount073](https://api.github.com/users/githubaccount073) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/11388094?v=4""/></br>[hydrandt](https://api.github.com/users/hydrandt) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/557540?v=4""/></br>[jabdoa2](https://api.github.com/users/jabdoa2) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/53862536?v=4""/></br>[johanvanheusden](https://api.github.com/users/johanvanheusden) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/54991735?v=4""/></br>[krzysiekwie](https://api.github.com/users/krzysiekwie) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/12849008?v=4""/></br>[lighthousebulb](https://api.github.com/users/lighthousebulb) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/4140247?v=4""/></br>[luzpaz](https://api.github.com/users/luzpaz) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/30428258?v=4""/></br>[nmiquan](https://api.github.com/users/nmiquan) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/31123054?v=4""/></br>[nullpointer666](https://api.github.com/users/nullpointer666) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/2979926?v=4""/></br>[oscaretu](https://api.github.com/users/oscaretu) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/36965591?v=4""/></br>[daehruoydeef](https://api.github.com/users/daehruoydeef) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/42961947?v=4""/></br>[pensierocrea](https://api.github.com/users/pensierocrea) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/10206967?v=4""/></br>[rhtenhove](https://api.github.com/users/rhtenhove) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/16728217?v=4""/></br>[rikanotank1](https://api.github.com/users/rikanotank1) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/51550769?v=4""/></br>[rnbastos](https://api.github.com/users/rnbastos) |þ| <img width=""50"" src=""https://avatars3.githubusercontent.com/u/14062932?v=4""/></br>[simonsan](https://api.github.com/users/simonsan) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/5004545?v=4""/></br>[stellarpower](https://api.github.com/users/stellarpower) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/12995773?v=4""/></br>[sumomo-99](https://api.github.com/users/sumomo-99) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/6908872?v=4""/></br>[taw00](https://api.github.com/users/taw00) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/10956653?v=4""/></br>[tcassaert](https://api.github.com/users/tcassaert) |þ| <img width=""50"" src=""https://avatars1.githubusercontent.com/u/46327531?v=4""/></br>[vicoutorama](https://api.github.com/users/vicoutorama) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/2216902?v=4""/></br>[xcffl](https://api.github.com/users/xcffl) | <img width=""50"" src=""https://avatars2.githubusercontent.com/u/37692927?v=4""/></br>[zaoyifan](https://api.github.com/users/zaoyifan) | <img width=""50"" src=""https://avatars3.githubusercontent.com/u/55245068?v=4""/></br>[zen-quo](https://api.github.com/users/zen-quo) | <img width=""50"" src=""https://avatars0.githubusercontent.com/u/25315?v=4""/></br>[xcession](https://api.github.com/users/xcession) |þ| <img width=""50"" src=""https://avatars0.githubusercontent.com/u/34542665?v=4""/></br>[paventyang](https://api.github.com/users/paventyang) | <img width=""50"" src=""https://avatars1.githubusercontent.com/u/1308646?v=4""/></br>[zhangmx](https://api.github.com/users/zhangmx) |  |  |  |þ<!-- CONTRIBUTORS-TABLE-AUTO-GENERATED -->þþ# Known bugsþþ- Resources larger than 10 MB are not currently supported on mobile as they can crash the application.þ- Non-alphabetical characters such as Chinese or Arabic might create glitches in the terminal on Windows. This is a limitation of the current Windows console.þþ# LicenseþþMIT LicenseþþCopyright (c) 2016-2020 Laurent CozicþþPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:þþThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.þþTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
audreyr/favicon-cheat-sheet,,False,False,False,329,3,9447,296,407,1,4,1,1,"[127, 390, 1219, 1489, 1534, 1578, 1620, 1626, 1643, 1719]",User,Obsessive cheat sheet to favicon sizes/types. Please contribute! (Note: this may be in flux as I learn new things about favicon best practices.),"{'ai': 1, '': 1, 'rst': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",,91,1,0,22,0,2532,True,30,9,0,0,15,26,2,0,6,0,0,0,,,1,"favicon-cheat-sheetþ===================þþA painfully obsessive cheat sheet to favicon sizes/types. Compiled from:þþ* http://mathiasbynens.be/notes/rel-shortcut-icon <-- special thanks `@mathiasbynens`_þ* http://mathiasbynens.be/notes/touch-icons <-- special thanks `@mathiasbynens`_þ* http://www.jonathantneal.com/blog/understand-the-favicon/þ* https://en.wikipedia.org/wiki/Favicon.icoþ* http://snook.ca/archives/design/making_a_good_faviconþ* http://www.netmagazine.com/features/create-perfect-faviconþ* http://www.ravelrumba.com/blog/android-apple-touch-icon/þ* http://msdn.microsoft.com/en-us/library/ie/gg491740(v=vs.85).aspxþþ.. _`@mathiasbynens`: https://github.com/mathiasbynensþþThe HTMLþ--------þþBasicsþ~~~~~~þþFor the main favicon itself, it's best for cross-browser compatibility not toþuse any HTML. Just name the file `favicon.ico` and place it in the root of yourþdomain. [1]_ [2]_þþThis works in every desktop browser/version all the way back to IE6, except for SeaMonkey. [1]_þþOptional But Encouragedþ~~~~~~~~~~~~~~~~~~~~~~~þþYou probably also want the following:þþ1. Touch icon for iOS 2.0+ and Android 2.1+:þþ    .. code-block:: htmlþþ        <link rel=""apple-touch-icon-precomposed"" href=""path/to/favicon-180.png"">þ   þ2. IE 10 Metro tile icon (Metro equivalent of apple-touch-icon):þþ    .. code-block:: htmlþþ        <meta name=""msapplication-TileColor"" content=""#FFFFFF"">þ        <meta name=""msapplication-TileImage"" content=""/path/to/favicon-144.png"">þþ   Replace #FFFFFF with your desired tile color.þ3. IE 11 Tile for Windows 8.1 Start Screenþþ    .. code-block:: htmlþþ        <meta name=""application-name"" content=""Name"">þ        <meta name=""msapplication-tooltip"" content=""Tooltip"">þ        <meta name=""msapplication-config"" content=""/path/to/ieconfig.xml"">þþ        þ    ieconfig.xmlþþ    .. code-block:: xmlþþ        <?xml version=""1.0"" encoding=""utf-8""?>þ            <browserconfig>þ              <msapplication>þ                <tile>þ                  <square70x70logo src=""/path/to/smalltile.png""/>þ                  <square150x150logo src=""/path/to/mediumtile.png""/>þ                  <wide310x150logo src=""/path/to/widetile.png""/>þ                  <square310x310logo src=""/path/to/largetile.png""/>þ                  <TileColor>#FFFFFF</TileColor>þ                </tile>þ              </msapplication>þ            </browserconfig>þþ        þþVery Optional, for the Obsessiveþ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~þþIf you're obsessive, you want all this too:þþ1. Largest to smallest apple-touch-icons [3]_:þþ    .. code-block:: htmlþ  <!-- For Iphone 6 plus running iOS 8: -->þ  <link rel=""apple-touch-icon-precomposed"" sizes=""180x180"" href=""/path/to/favicon-180.png"">þ  þ        <!-- For iPad with high-resolution Retina display running iOS ≥ 7: -->þ        <link rel=""apple-touch-icon-precomposed"" sizes=""152x152"" href=""/path/to/favicon-152.png"">þþ        <!-- For iPad with high-resolution Retina display running iOS ≤ 6: -->þ        <link rel=""apple-touch-icon-precomposed"" sizes=""144x144"" href=""/path/to/favicon-144.png"">þþ        <!-- For iPhone with high-resolution Retina display running iOS ≥ 7: -->þ        <link rel=""apple-touch-icon-precomposed"" sizes=""120x120"" href=""/path/to/favicon-120.png"">þþ        <!-- For iPhone with high-resolution Retina display running iOS ≤ 6: -->þ        <link rel=""apple-touch-icon-precomposed"" sizes=""114x114"" href=""/path/to/favicon-114.png"">þþ        <!-- For first- and second-generation iPad: -->þ        <link rel=""apple-touch-icon-precomposed"" sizes=""76x76"" href=""/path/to/favicon-76.png"">þþ        <!-- For non-Retina iPhone, iPod Touch, and Android 2.1+ devices: -->þ        <link rel=""apple-touch-icon-precomposed"" href=""/path/to/favicon-57.png"">þþ2. Favicons targeted to any additional png sizes that you add that aren't covered above:þþ    .. code-block:: htmlþþ        <link rel=""icon"" href=""/path/to/favicon-32.png"" sizes=""32x32"">þ3. Favicon Chrome for Androidþþ    .. code-block:: htmlþþ        <link rel=""shortcut icon"" sizes=""196x196"" href=""/path/to/favicon-196.png"">þ        þThe Imagesþ----------þþCreate at least this:þþ============= =============== =======================================================================þSizes         Name            Purposeþ============= =============== =======================================================================þ16x16 & 32x32 favicon.ico     Default required by IE. Chrome and Safari may pick ico over png, sadly.þ============= =============== =======================================================================þþMore about favicon.ico below. Yes, it's 1 file with multiple sizes.þþIf you also sort of care about iOS and Android but are lazy:þþ======= =============== =======================================================================þSize    Name            Purposeþ======= =============== =======================================================================þ180x180 favicon-180.png General use iOS/Android icon, auto-downscaled by devices.þ======= =============== =======================================================================þþBut keep in mind that icons with complex detail often don't downscale well.þOften you have to tweak subtle design details for smaller sizes.þþIf you're obsessive, create these too:þþ======= =============== =======================================================================þSize    Name            Purposeþ======= =============== =======================================================================þ32x32   favicon-32.png  Certain old but not too old Chrome versions mishandle icoþ57x57   favicon-57.png  Standard iOS home screen (iPod Touch, iPhone first generation to 3G)þ76x76   favicon-76.png  iPad home screen iconþ96x96   favicon-96.png  GoogleTV iconþ120x120 favicon-120.png iPhone retina touch icon (Change for iOS 7: up from 114x114)þ128x128 favicon-128.png Chrome Web Store iconþ128x128 smalltile.png Small Windows 8 Star Screen Iconþ144x144 favicon-144.png IE10 Metro tile for pinned siteþ152x152 favicon-152.png iPad retina touch icon (Change for iOS 7: up from 144x144)þ180x180 favicon-180.png iPhone 6 plusþ195x195 favicon-195.png Opera Speed Dial icon (Not working in Opera 15 and later)þ196x196 favicon-196.png Chrome for Android home screen iconþ228x228 favicon-228.png Opera Coast iconþ270x270 mediumtile.png Medium Windows 8 Start Screen Iconþ558x270 widetile.png Wide Windows 8 Start Screen Iconþ558x558 largetile.png Large Windows 8 Start Screen Iconþ======= =============== =======================================================================þþICO Fileþ--------þþAn .ico file is a container for multiple .bmp or .png icons of different sizes.þIn favicon.ico, create at least these:þþ======= =======================================================================þSize    Purposeþ======= =======================================================================þ16x16   IE9 address bar, Pinned site Jump List/Toolbar/Overlayþ32x32   New tab page in IE, taskbar button in Win 7+, Safari Read Later sidebarþ48x48   Windows site icons [4]_þ======= =======================================================================þþIf you're obsessive and don't mind 1-3kb extra size, also include these sizesþin your .ico:þþ======= =======================================================================þSize    Purposeþ======= =======================================================================þ24x24   IE9 Pinned site browser UIþ64x64   Windows site icons [4]_, Safari Reading List sidebar in HiDPI/Retinaþ======= =======================================================================þþCreate your .ico out of optimized .png files.þþTODO: get confirmation that IE9+ supports .ico files that contain .png files (issue `#9`_)þþ.. _`#9`: https://github.com/audreyr/favicon-cheat-sheet/issues/9þþSVG Fileþ--------þþPinned tabs in Safari 9+ use an SVG vector mask for the favicon instead of any other PNG/ICO/etc. favicons that may be present. Vector artwork in the SVG file should be black only (no shades of black or other colors) with a transparent background. Also, a fill color needs to be defined in the <link> tag - a hex value or color shorthand will work. Here's the markup for adding the icon:þþ    .. code-block:: htmlþ    þ     <link rel='mask-icon' href='icon.svg' color='#ff0000'>þþHelpful Toolsþ-------------þþI recommend:þþ1. OptiPNG, to optimize .png files before putting them into an .ico: http://optipng.sourceforge.net/þ2. ImageMagick, to create an .ico from .png files: http://blog.morzproject.com/convert-multiple-png-images-into-a-single-icon-file/ & http://www.imagemagick.org/Usage/thumbnails/#faviconþþ    .. code-block:: bashþþ        $ convert favicon-16.png favicon-32.png favicon.icoþþOthers that I haven't tried:þþ* Favic-o-matic: http://www.favicomatic.com - A favicon generator that cares of .ico, .png and HTML code to make your website shine on every platform, browser or deviceþ* Ubuntu/Debian package `icoutil` (Fedora package `icoutils`_) provides the program `icotool` which creates .ico from .png files.þ* MSDN recommends this web-based .ico creator: http://www.xiconeditor.comþ* Resize favicons: http://faviconer.comþ* More resizing: https://github.com/abrkn/iconþ* Dynamically setting favicons: https://github.com/HenrikJoreteg/favicon-setterþ* Fancy favicon tricks: https://github.com/component/pieconþ* Web Icon - a simple shell script that generates favicon and touch icons: https://github.com/emarref/webiconþ* Icon Slate app (OS X): https://itunes.apple.com/us/app/icon-slate/id439697913þ* png2ico wrapper for ImageMagick: https://github.com/bebraw/png2icoþ* `GIMP`_: export as .ico, each layer is saved as an imageþþ.. _`icoutils`: https://apps.fedoraproject.org/packages/icoutilsþ.. _`GIMP`: https://www.gimp.org/þþForcing a Favicon Refreshþ-------------------------þþNot normally needed. This is only for those frustrating times when you can'tþget your favicon to refresh, during development:þþ* Clear the browser cache on Windows (Ctrl+F5 or Ctrl+Shift+R) and on Mac (Command + Shift + R).þ* Also close and reopen browser if IE.þ* If still stuck, try opening new tab. Or see http://stackoverflow.com/questions/2208933/how-do-i-force-a-favicon-refreshþ* Temporarily add explicit HTML markup and append a query string. Removeþ  this when you're done:þþ    .. code-block:: htmlþþ        <link rel=""shortcut icon"" href=""http://www.yoursite.com/favicon.ico?v=2"" />þ        <link rel=""icon"" sizes=""16x16 32x32"" href=""/favicon.ico?v=2"">þþFor large versioned deployments, if all site visitors need their faviconþforce-refreshed in an extreme situation:þþ* Add explicit HTML markup (customize the sizes part) and put your versionþ  number in the filename.þþ    .. code-block:: htmlþþ        <link rel=""shortcut icon"" href=""/favicon-v2.ico"" />þ        <link rel=""icon"" sizes=""16x16 32x32"" href=""/favicon-v2.ico"">þþ  TODO: find edge cases where this markup doesn't work (issue `#3`_).þþ.. _`#3`: https://github.com/audreyr/favicon-cheat-sheet/issues/3þþFAQþ---þþ**What about having both a default root favicon.ico and favicon.png?**þI think it's actually better to provide only `favicon.ico` and not `favicon.png`, because:þþ* An `.ico` is a container for multiple `.bmp` or `.png` files. If you specify 1 default `favicon.png`, and if that `favicon.png` overrides the `favicon.ico`, you are giving up control over how the favicon looks at different resolutions and allowing the browser to do all resizing. For example, you might want the 64x64 version to contain text and the 16x16 version to not display the text at all, since at 16x16 it would be unreadable anyway.þ* There is no `favicon.png` in the HTML5 specification, just `/favicon.ico`. From http://www.w3.org/TR/html5/links.html#rel-icon:þ   - 'In the absence of a link with the icon keyword, for Documents obtained over HTTP or HTTPS, user agents may instead attempt to fetch and use an icon with the absolute URL obtained by resolving the URL ""/favicon.ico"" against the document's address, as if the page had declared that icon using the icon keyword.'þþMore about this in http://stackoverflow.com/questions/1344122/favicon-png-vs-favicon-ico-why-should-i-use-pngs-instead-of-icos/1344379#1344379 (Note: the text in the chosen answer about alpha transparency is incorrect. See the 2nd answer.)þþ**Is it true that favicons should be in the site root?**þNo, that's only if you don't explicitly specify the browser/device-specificþ`<link>` tags with a favicon path. See https://en.wikipedia.org/wiki/Favicon.ico.þþIf you don't have favicon.ico in the root consider adding one, or returning a HTTP 204 instead.þMany tools and services e.g. bookmarking sites, feed readers, web crawlers etc., request a þfavicon.ico from the site root, and so receive a HTTP 404 if it's not present. In the worst þcase some frameworks will return a custom error page which is likely to be many times largerþthan the missing favicon.þþ**Is it true that the png has to be named favicon.png?**þNo, this has never been true as far as I can tell from my obsessive research.þþ**Is it true that the ico has to be named favicon.ico?**þIf you don't explicitly specify its `<link>` tag, yes. Explicitness is best,þso we both name it `favicon.ico` and explicitly specify the `<link>` tag.þþ**Why not prefix with ""apple-touch-icon""?**þIf you don't specify `<link>` tags, iOS looks for files prefixed withþ`apple-touch-icon` or `apple-touch-icon-precomposed`. Many (e.g. HTML5þBoilerplate) rely on this assumption, but:þþ* Explicitly specifying `<link>` tags is clearer and supported by Apple.þ* Not hard-coding names as `apple-touch-icon` clears up confusion as to whetherþ  the same icons can be reused for other purposes as-is, e.g. reusingþ  favicon-144.png for Windows pinned site.þþ**Why use iOS precomposed icons?**þþ* iOS non-precomposed icons add rounded corners, drop shadow, and reflectiveþ  shine. Sounds great in theory, but in practice the results can be veryþ  frustrating, especially to designers.þ* Non-precomposed icons don't work with Android 2.1.þþ**Why absolute paths?**þSome Firefox versions require absolute paths. Since all browsers support them,þit's the simplest choice.þþ**Why not append a query string to force-refresh for all visitors?**þSome proxies and load balancers can fail to read query strings in edge cases.þþContribute!þ-----------þþSend pull requests if you have anything to add/change, providing citationsþand justification. I'd love to see this improve. þþNote on March 6, 2020: I'm behind on merging PRs but am slowly catching up. þBear with me while I get this repo caught up. ❤️þþReferencesþ----------þþ.. [1] http://mathiasbynens.be/notes/rel-shortcut-iconþ.. [2] http://www.w3.org/TR/html5/links.html#rel-iconþ.. [3] Adapted from http://mathiasbynens.be/notes/touch-iconsþ.. [4] No specifics given by MSDN.þ.. [5] http://blog.morzproject.com/convert-multiple-png-images-into-a-single-icon-file/",
datawhalechina/leeml-notes,,False,False,False,251101,1046,5195,233,1643,8,17,45,1,"[62, 106, 237, 286, 294, 298, 300, 301, 312, 317]",Organization,李宏毅《机器学习》笔记，在线阅读地址：https://datawhalechina.github.io/leeml-notes,"{'': 3, 'md': 54, 'csv': 10, 'py': 10, 'data': 1, 'names': 1, 'test': 1, 'ipynb': 3, 'png': 960, 'jpg': 2, 'html': 1}",,"{'key': 'gpl-3.0', 'name': 'GNU General Public License v3.0', 'spdx_id': 'GPL-3.0', 'url': 'https://api.github.com/licenses/gpl-3.0', 'node_id': 'MDc6TGljZW5zZTk='}",,400,1,0,9,2,464,True,15,25,1,5,2,3,0,0,27,0,0,0,22,0,,"# 李宏毅机器学习笔记(LeeML-Notes)þ李宏毅老师的[机器学习视频](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17.html)是机器学习领域经典的中文视频之一，也被称为中文世界中最好的机器学习视频。李老师以幽默风趣的上课风格让很多晦涩难懂的机器学习理论变得轻松易懂，并且老师会通过很多有趣的例子结合机器学习理论在课堂上展现出来，并且逐步推导深奥的理论知识。比如老师会经常用宝可梦来结合很多机器学习算法。对于想入门机器学习又想看中文讲解的人来说绝对是非常推荐的。学有余力的同学也可以看一下[李宏毅机器学习2019](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html)(大部分是一样的，只有小部分更新)þþþ## 使用说明þ这个笔记是根据李宏毅老师机器学习视频的一个辅助资料，本笔记基本上完全复刻李老师课堂上讲的所有内容，并加入了一些和相关的学习补充资料和参考资料，结合这些资料一起学习，相信你会对机器学习有更加深刻的理解。þþ### 笔记在线阅读地址þ在线阅读地址：https://datawhalechina.github.io/leeml-notesþþ### 课程在线观看地址þ- bilibili：[李宏毅《机器学习》](https://www.bilibili.com/video/av59538266)þþ# 目录þ- [P1 机器学习介绍](https://datawhalechina.github.io/leeml-notes/#/chapter1/chapter1)þ- [P2 为什么要学习机器学习](https://datawhalechina.github.io/leeml-notes/#/chapter2/chapter2)þ- [P3 回归](https://datawhalechina.github.io/leeml-notes/#/chapter3/chapter3)þ- [P4 回归-演示](https://datawhalechina.github.io/leeml-notes/#/chapter4/chapter4)þ- [P5 误差从哪来？](https://datawhalechina.github.io/leeml-notes/#/chapter5/chapter5)þ- [P6 梯度下降](https://datawhalechina.github.io/leeml-notes/#/chapter6/chapter6)þ- [P7 梯度下降（用AOE演示）](https://datawhalechina.github.io/leeml-notes/#/chapter7/chapter7)þ- [P8 梯度下降（用Minecraft演示）](https://datawhalechina.github.io/leeml-notes/#/chapter8/chapter8)þ- [P9 作业1-PM2.5预测](https://datawhalechina.github.io/leeml-notes/#/chapter9/chapter9)þ- [P10 概率分类模型](https://datawhalechina.github.io/leeml-notes/#/chapter10/chapter10)þ- [P11 logistic回归](https://datawhalechina.github.io/leeml-notes/#/chapter11/chapter11)þ- [P12 作业2-赢家还是输家](https://datawhalechina.github.io/leeml-notes/#/chapter12/chapter12)þ- [P13 深度学习简介](https://datawhalechina.github.io/leeml-notes/#/chapter13/chapter13)þ- [P14 反向传播](https://datawhalechina.github.io/leeml-notes/#/chapter14/chapter14)þ- [P15 深度学习初试](https://datawhalechina.github.io/leeml-notes/#/chapter15/chapter15)þ- [P16 Keras2.0](https://datawhalechina.github.io/leeml-notes/#/chapter16/chapter16)þ- [P17 Keras演示](https://datawhalechina.github.io/leeml-notes/#/chapter17/chapter17)þ- [P18 深度学习技巧](https://datawhalechina.github.io/leeml-notes/#/chapter18/chapter18)þ- [P19 Keras演示2](https://datawhalechina.github.io/leeml-notes/#/chapter19/chapter19)þ- [P20 Tensorflow 实现 Fizz Buzz](https://datawhalechina.github.io/leeml-notes/#/chapter20/chapter20)þ- [P21 卷积神经网络](https://datawhalechina.github.io/leeml-notes/#/chapter21/chapter21)þ- [P22 为什么要“深度”学习？](https://datawhalechina.github.io/leeml-notes/#/chapter22/chapter22)þ- [P23 半监督学习](https://datawhalechina.github.io/leeml-notes/#/chapter23/chapter23)þ- [P24 无监督学习-线性降维](https://datawhalechina.github.io/leeml-notes/#/chapter24/chapter24)þ- [P25 无监督学习-词嵌入](https://datawhalechina.github.io/leeml-notes/#/chapter25/chapter25)þ- [P26 无监督学习-领域嵌入](https://datawhalechina.github.io/leeml-notes/#/chapter26/chapter26)þ- [P27 无监督学习-深度自编码器](https://datawhalechina.github.io/leeml-notes/#/chapter27/chapter27)þ- [P28 无监督学习-深度生成模型I](https://datawhalechina.github.io/leeml-notes/#/chapter28/chapter28)þ- [P29 无监督学习-深度生成模型II](https://datawhalechina.github.io/leeml-notes/#/chapter29/chapter29)þ- [P30 迁移学习](https://datawhalechina.github.io/leeml-notes/#/chapter30/chapter30)þ- [P31 支持向量机](https://datawhalechina.github.io/leeml-notes/#/chapter31/chapter31)þ- [P32 结构化学习-介绍](https://datawhalechina.github.io/leeml-notes/#/chapter32/chapter32)þ- [P33 结构化学习-线性模型](https://datawhalechina.github.io/leeml-notes/#/chapter33/chapter33)þ- [P34 结构化学习-结构化支持向量机](https://datawhalechina.github.io/leeml-notes/#/chapter34/chapter34)þ- [P35 结构化学习-序列标注](https://datawhalechina.github.io/leeml-notes/#/chapter35/chapter35)þ- [P36 循环神经网络I](https://datawhalechina.github.io/leeml-notes/#/chapter36/chapter36)þ- [P37 循环神经网络II](https://datawhalechina.github.io/leeml-notes/#/chapter37/chapter37)þ- [P38 集成学习](https://datawhalechina.github.io/leeml-notes/#/chapter38/chapter38)þ- [P39 深度强化学习浅析](https://datawhalechina.github.io/leeml-notes/#/chapter39/chapter39)þ- [P40 机器学习的下一步](https://datawhalechina.github.io/leeml-notes/#/chapter40/chapter40)þ- [P41 异常检测(1)](https://datawhalechina.github.io/leeml-notes/#/chapter41/chapter41)þ- [P42 异常检测(2)](https://datawhalechina.github.io/leeml-notes/#/chapter42/chapter42)þ- [P43 异常检测(3)](https://datawhalechina.github.io/leeml-notes/#/chapter43/chapter43)þ- [P44 异常检测(4)](https://datawhalechina.github.io/leeml-notes/#/chapter44/chapter44)þ- [P45 异常检测(5)](https://datawhalechina.github.io/leeml-notes/#/chapter45/chapter45)þ- [P46 异常检测(6)](https://datawhalechina.github.io/leeml-notes/#/chapter46/chapter46)þ- [P47 异常检测(7)](https://datawhalechina.github.io/leeml-notes/#/chapter47/chapter47)þ- [P48 对抗机器学习模型(1)](https://datawhalechina.github.io/leeml-notes/#/chapter48/chapter48)þþþ# 修订记录：þ|版本|时间|作者|文档信息 |þ|---|:--:|:--:|:--|þ| v0.1 |2019.06.28|[@DatawhaleXiuyuan](https://github.com/DatawhaleXiuyuan)<br>[@hahlw](https://github.com/hahlw)<br>[@Heitao5200](https://github.com/Heitao5200)<br>[@ImayKing](https://github.com/Imay-King)<br>[@spareribs](https://github.com/spareribs)|建立初始仓库 |þ| v1.0 |2019.07.20|[@DatawhaleXiuyuan](https://github.com/DatawhaleXiuyuan)<br>[@hahlw](https://github.com/hahlw)<br>[@Heitao5200](https://github.com/Heitao5200)<br>[@Hirotransfer](https://github.com/Hirotransfer)<br>[@huangmh11](https://github.com/huangmh11)<br>[@ImayKing](https://github.com/Imay-King)<br>[@LilRache](https://github.com/LilRachel)<br>[@spareribs](https://github.com/spareribs)<br> |正式对外公开|þ| v1.2|-|-|- |þþþþ# 主要贡献者（按首字母排名）þþ- [@DatawhaleXiuyuan](https://github.com/DatawhaleXiuyuan)þ- [@hahlw](https://github.com/hahlw)þ- [@Heitao5200](https://github.com/Heitao5200)þ- [@Hirotransfer](https://github.com/Hirotransfer)þ- [@huangmh11](https://github.com/huangmh11)þ- [@ImayKing](https://github.com/Imay-King)þ- [@LilRache](https://github.com/LilRachel)þ- [@spareribs](https://github.com/spareribs)þþþ# 关注我们þþ<div align=center><img src=""https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg"" width = ""250"" height = ""270"" alt=""Datawhale，一个专注于AI领域的学习圈子。初衷是for the learner，和学习者一起成长。目前加入学习社群的人数已经数千人，组织了机器学习，深度学习，数据分析，数据挖掘，爬虫，编程，统计学，Mysql，数据竞赛等多个领域的内容学习，微信搜索公众号Datawhale可以加入我们。""></div>",
Laverna/laverna,,False,False,False,6664,448,8596,358,829,0,0,0,0,"[876, 879, 895, 902, 907, 915, 930, 960, 977, 979]",Organization,Laverna is a JavaScript note taking application with Markdown editor and encryption support. Consider it like open source alternative to Evernote.,"{'': 9, 'yml': 2, 'md': 3, 'html': 49, 'xml': 2, 'ico': 1, 'png': 17, 'icns': 1, 'xcf': 1, 'json': 38, 'webapp': 1, 'txt': 3, 'js': 279, 'less': 38, 'eot': 1, 'svg': 1, 'ttf': 1, 'woff': 1}",https://laverna.cc/index.html,"{'key': 'mpl-2.0', 'name': 'Mozilla Public License 2.0', 'spdx_id': 'MPL-2.0', 'url': 'https://api.github.com/licenses/mpl-2.0', 'node_id': 'MDc6TGljZW5zZTE0'}",JavaScript,1667,3,23,23,6,2528,True,433,337,0,0,10,216,0,0,14,3,0,0,7,2,,"# Laverna - note taking web appþþ[![Join the chat at https://gitter.im/Laverna/laverna](https://badges.gitter.im/Laverna/laverna.svg)](https://gitter.im/Laverna/laverna?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)þþ[![Build Status](https://travis-ci.org/Laverna/laverna.svg?branch=dev)](https://travis-ci.org/Laverna/laverna) [![devDependency Status](https://david-dm.org/Laverna/laverna/dev-status.svg)](https://david-dm.org/Laverna/laverna#info=devDependencies) [![Code Climate](https://codeclimate.com/github/Laverna/laverna/badges/gpa.svg)](https://codeclimate.com/github/Laverna/laverna)þþLaverna is a JavaScript note-taking web application with a Markdown editor and encryption support.  It's built to be an open source alternative to Evernote.þþThe application stores all your notes in your browser databases such as indexedDB or localStorage, which is good for security reasons, because only you have access to them.þþ**Demo**: https://laverna.cc/ OR http://laverna.github.io/static-lavernaþþ## Featuresþ-----------þþ* Markdown editor based on Pagedownþ* Manage your notes, even when you're offlineþ* Secure client-side encryptionþ* Synchronizes with cloud storage services (currently only with Dropbox and RemoteStorage)þ* Three editing modes: distraction free, preview, and normal modeþ* WYSIWYG control buttonsþ* MathJax supportþ* Syntax highlightingþ* No registration requiredþ* Web basedþ* Keybindingsþþ## ToolsþþOn the front-end this project uses JavaScript and the [Marionette JS](http://marionettejs.com/) framework while [Node JS](https://nodejs.org/en/), [Bower](https://bower.io/), and [Gulp.js](http://gulpjs.com/) are used on the back-end.  The test runner used is [karma](https://karma-runner.github.io/1.0/index.html) however,þcontributors are free to utilize whatever testing tools they desire.þþþ## Installationþ---------------þThere are several ways to start using Laverna:þþ1. Open [laverna.cc][10] and start using it. No extra steps are needed.þ2. Use a desktop app.þ3. Use a prebuilt version from [Laverna/static-laverna][9] repository.þ4. Build it from the source code.þþ### Desktop app installationþ---------------þDownload the latest [Laverna release][13] for your operating system. After downloading the archive, you need to unpack it. Then, in the unpacked folder you need to run an executable (laverna.exe for Windows, laverna for Linux and Mac).þþ#### Arch Linux (or derived distributions)þþThe package can be found [here](https://aur.archlinux.org/packages/laverna/). þþFor installation please use :þþ```bashþ$ pacaur -S lavernaþ```þþFor issue about installation please report [here](https://github.com/funilrys/PKGBUILD/issues/new) or contact [@funilrys](https://github.com/funilrys) on gitter [here](https://gitter.im/funilrys_/PKGBUILD)þþþ### Installation of a prebuilt versionþ------------þ#### 1. Downloadþþ```bashþ$ wget https://github.com/Laverna/static-laverna/archive/gh-pages.zip -O laverna.zipþ```þþ#### 2. Unpack the downloaded archiveþþ```bashþ$ unzip laverna.zipþ```þþ#### 3. Open index.html in a browserþOpen in your favorite browser the index.html file which is located inside *laverna* directory.þþþ## Installation from sourceþ---------------þTo install, do the following:þþ#### 1. Install GitþþThis project requires that you have the latest version of git installed. To do so, see [Installing Git][14] (first-time users of git might want to check out the next section for configuring git).þþ**Note:** Windows users will have to set the PATH variable for git after installing it.þþþþ#### 2. Clone repository:þþFor those who plan on contributing to the project's development , hit the fork button at the top of the page first (others can go on to the next step). Open a terminal, or command line, and navigate to the desired location of where you want to download the repository. Then enter the following commands to clone the repo:þþ```bashþ# clone the repositoryþ$ git clone git@github.com:Laverna/laverna.gitþ# navigate to the project directoryþcd lavernaþ```þþ**3. Ensure you have the node.js platform installed.** (See OS-specific instructions on their [website][8]).þþ**4. Ensure you have the bower and gulp packages installed** (locally and globally):þþ```bashþ$ npm install bowerþ$ npm install -g bowerþ$ npm install gulpþ$ npm install -g gulpþ```þþ#### 5. Install Laverna's dependencies:þþ```bashþ$ npm installþ$ bower installþ$ cd testþ$ bower installþ$ cd ..þ```þþ#### 6. Build minified version of Laverna:þþ```bashþ$ gulp buildþ```þþ#### 7. Start Laverna:þþ```bashþ$ gulpþ```þþ## MacOS notes on accepting incoming connectionsþBecause currently Laverna does not sign it's Mac packages, if you want to avoid the ""Accept incoming connections"" warning message everytime the application is launched, you can run the following commands. Assuming your current direction contains the laverna application:þþ```bashþcodesign -s - -f ./laverna.app/Contents/Frameworks/Electron\ Framework.frameworkþcodesign -s - -f ./laverna.app/Contents/Frameworks/Electron\ Helper\ EH.app þcodesign -s - -f ./laverna.app/Contents/Frameworks/Electron\ Helper\ NP.appþcodesign -s - -f ./laverna.app/Contents/Frameworks/Electron\ Helper.app þcodesign -s - -f ./laverna.app/Contents/Frameworks/Mantle.framework þcodesign -s - -f ./laverna.app/Contents/Frameworks/ReactiveCocoa.framework þcodesign -s - -f ./laverna.app/Contents/Frameworks/Squirrel.framework þcodesign --verify -vv ./laverna.appþ```þþ## Do you have questions?þ---------------þPlease have a look in our [wiki][15].þþ## Supportþ---------------þþ* Hit star button on [github][6]þ* Like us on [alternativeto.net][5]þ* [Contribute][7]þþ### Coding Style GuidelinesþþFor those wanting to contribute code, we ask that you use either plain JavaScript or the Marionette.js framework. (For more details on the preferred coding style see [.editorconfig](https://github.com/Laverna/laverna/blob/master/.editorconfig)). Also, all experimental changes are being pushed on the **dev** branch, so any feature changes are preferred to be done on either this branch or a branch that uses the dev branch as its parent.  þþþ## Donation:þ-----------þþ* [Bitcoin][3]þ* [BountySource][12]þþ## Securityþ--------------þLaverna uses the [SJCL] [1] library implementing the AES algorithm. You can review the code at:þþ* https://github.com/Laverna/laverna/blob/master/app/scripts/classes/encryption.jsþ* https://github.com/Laverna/laverna/blob/master/app/scripts/apps/encryption/þþ## Licenseþ--------------þPublished under [MPL-2.0 License][11].þþLaverna uses a lot of other libraries and each of these [libraries use different licenses][2].þþ[1]: http://bitwiseshiftleft.github.io/sjcl/þ[2]: https://github.com/Laverna/laverna/blob/master/bower.jsonþ[3]: http://blockchain.info/address/1Q68HfLjNvWbLFr3KGK6nfXg7vc3hpDr11þ[4]: https://www.gittip.com/Laverna/þ[5]: http://alternativeto.net/software/laverna/þ[6]: https://github.com/Laverna/lavernaþ[7]: https://github.com/Laverna/laverna/blob/master/CONTRIBUTE.mdþ[8]: http://nodejs.orgþ[9]: https://github.com/Laverna/static-laverna/archive/gh-pages.zipþ[10]: https://laverna.cc/index.htmlþ[11]: https://www.mozilla.org/en-US/MPL/2.0/þ[12]: https://www.bountysource.com/teams/lavernaþ[13]: https://github.com/Laverna/laverna/releasesþ[14]: https://git-scm.com/book/en/v2þ[15]: https://github.com/Laverna/laverna/wiki",
hackmdio/codimd,,False,False,False,25278,404,6153,149,771,142,27046,21728,16,"[1, 2, 9, 14, 40]",Organization,CodiMD - Realtime collaborative markdown notes on all platforms.,"{'': 16, 'example': 3, 'yml': 2, 'md': 7, 'js': 163, 'json': 28, 'sh': 4, 'png': 22, 'css': 24, 'eot': 22, 'ttf': 22, 'woff': 22, 'svg': 37, 'ejs': 27, 'html': 2, 'aff': 1, 'dic': 1, 'hbs': 1}",https://hackmd.io/c/codimd-documentation,"{'key': 'agpl-3.0', 'name': 'GNU Affero General Public License v3.0', 'spdx_id': 'AGPL-3.0', 'url': 'https://api.github.com/licenses/agpl-3.0', 'node_id': 'MDc6TGljZW5zZTE='}",JavaScript,2706,13,29,29,6,1895,True,242,642,56,31,11,646,8,65,43,1,0,0,54,6,,"CodiMDþ===þþ[![build status][travis-image]][travis-url]þ[![version][github-version-badge]][github-release-page]þ[![Gitter][gitter-image]][gitter-url]þ[![POEditor][poeditor-image]][poeditor-url]þþCodiMD lets you collaborate in real-time with markdown.þBuilt on [HackMD](https://hackmd.io) source code, CodiMD lets you host and control your team's content with speed and ease.þþ![screenshot](https://raw.githubusercontent.com/hackmdio/codimd/develop/public/screenshot.png)þþ<!-- START doctoc generated TOC please keep comment here to allow auto update -->þ<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->þ# Table of Contentsþþ- [HackMD](#hackmd)þ- [CodiMD - The Open Source HackMD](#codimd---the-open-source-hackmd)þ- [Documentation](#documentation)þ  - [Deployment](#deployment)þ  - [Configuration](#configuration)þ  - [Upgrading and Migration](#upgrading-and-migration)þ  - [Developer](#developer)þ- [Contribution and Discussion](#contribution-and-discussion)þ- [Browser Support](#browser-support)þ- [License](#license)þþ<!-- END doctoc generated TOC please keep comment here to allow auto update -->þþ## HackMDþþ[HackMD](https://hackmd.io) helps developers write better documents and build active communities with open collaboration.þHackMD is built with one promise - **You own and control all your content**:þ- You should be able to easily [download all your online content at once](https://hackmd.io/c/news/%2Fs%2Fr1cx3a3SE).þ- Your content formatting should be portable as well. (That's why we choose [markdown](https://hackmd.io/features#Typography).)þ- You should be able to control your content's presentation with HTML, [slide mode](https://hackmd.io/p/slide-example), or [book mode](https://hackmd.io/c/book-example/).þþ## CodiMD - The Open Source HackMDþþCodiMD is the free software version of [HackMD](https://hackmd.io), developed and opened source by the HackMD team with reduced features (without book mode), you can use CodiMD for your community and own all your data. *(See the [origin of the name CodiMD](https://github.com/hackmdio/hackmd/issues/720).)* þþCodiMD is perfect for open communities, while HackMD emphasizes on permission and access controls for commercial use cases. þþHackMD team is committed to keep CodiMD open source. All contributions are welcome!þþ## DocumentationþYou would find all documentation here: [CodiMD Documentation](https://hackmd.io/c/codimd-documentation)þþ### DeploymentþIf you want to spin up an instance and start using immediately, see [Docker deployment](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-docker-deployment).þIf you want to contribute to the project, start with [manual deployment](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-manual-deployment).þþ### ConfigurationþCodiMD is highly customizable, learn about all configuration options of networking, security, performance, resources, privilege, privacy, image storage, and authentication in [CodiMD Configuration](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-configuration).þþ### Upgrading and MigrationþUpgrade CodiMD from previous version? See [this guide](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-upgrade)<br>þMigrating from Etherpad? Follow [this guide](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-migration-etherpad)þþ### DeveloperþJoin our contributor community! Start from deploying [CodiMD manually](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-manual-deployment), [connecting to your own database](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-db-connection), [learn about the project structure](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-project-structure), to [build your changes](https://hackmd.io/c/codimd-documentation/%2Fs%2Fcodimd-webpack) with the help of webpack.þþ## Contribution and DiscussionþAll contributions are welcome! Even asking a question helps.þþ| Project | Contribution Types | Contribution Venue |þ| ------- | ------------------ | ------------------ |þ|**CodiMD**|:couple: Community chat|[Gitter][gitter-url]|þ||:bug: Issues, bugs, and feature requests|[Issue tracker](https://github.com/hackmdio/codimd/issues)|þ||:books: Improve documentation|[Documentations](https://hackmd.io/c/codimd-documentation)|þ||:pencil: Translation|[POEditor][poeditor-url]|þ||:coffee: Donation|[Buy us coffee](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=KDGS4PREHX6QQ&lc=US&item_name=HackMD&currency_code=USD&bn=PP%2dDonationsBF%3abtn_donate_LG%2egif%3aNonHosted)|þ|**HackMD**|:question: Issues related to [HackMD](https://hackmd.io/)|[Issue tracker](https://github.com/hackmdio/hackmd-io-issues/issues)|þ||:pencil2: Translation|[hackmd-locales](https://github.com/hackmdio/hackmd-locales/tree/master/locales)|þþ## Browser SupportþþCodiMD is a service that runs on Node.js, while users use the service through browsers. We support your users using the following browsers: þ- <img src=""https://raw.githubusercontent.com/alrra/browser-logos/master/src/chrome/chrome_48x48.png"" alt=""Chrome"" width=""24px"" height=""24px"" /> Chrome >= 47, Chrome for Android >= 47þ- <img src=""https://raw.githubusercontent.com/alrra/browser-logos/master/src/safari/safari_48x48.png"" alt=""Safari"" width=""24px"" height=""24px"" /> Safari >= 9, iOS Safari >= 8.4þ- <img src=""https://raw.githubusercontent.com/alrra/browser-logos/master/src/firefox/firefox_48x48.png"" alt=""Firefox"" width=""24px"" height=""24px"" /> Firefox >= 44þ- <img src=""https://raw.githubusercontent.com/alrra/browser-logos/master/src/edge/edge_48x48.png"" alt=""IE / Edge"" width=""24px"" height=""24px"" /> IE >= 9, Edge >= 12þ- <img src=""https://raw.githubusercontent.com/alrra/browser-logos/master/src/opera/opera_48x48.png"" alt=""Opera"" width=""24px"" height=""24px"" /> Opera >= 34, Opera Mini not supportedþ- Android Browser >= 4.4þþTo stay up to date with your installation it's recommended to subscribe the [release feed][github-release-feed].þþ## Licenseþþ**License under AGPL.**þþ[gitter-image]: https://img.shields.io/badge/gitter-hackmdio/codimd-blue.svg þ[gitter-url]: https://gitter.im/hackmdio/hackmdþ[travis-image]: https://travis-ci.com/hackmdio/codimd.svg?branch=masterþ[travis-url]: https://travis-ci.com/hackmdio/codimdþ[github-version-badge]: https://img.shields.io/github/release/hackmdio/codimd.svgþ[github-release-page]: https://github.com/hackmdio/codimd/releasesþ[github-release-feed]: https://github.com/hackmdio/codimd/releases.atomþ[poeditor-image]: https://img.shields.io/badge/POEditor-translate-blue.svgþ[poeditor-url]: https://poeditor.com/join/project/q0nuPWyztp",
northbright/Notes,,False,False,False,17044,860,158,13,61,213,4818,1935,1,"[8, 14, 35, 37, 38, 41, 44, 45, 48, 50]",User,Development Notes,"{'md': 645, 'mk': 7, 'xml': 12, '': 7, 'jar': 13, 'java': 8, 'jpg': 45, 'txt': 7, 'bat': 16, 'sh': 15, 'dll': 2, 'exe': 3, 'ini': 1, 'cfg': 1, 'png': 66, 'flags': 2, 'service': 1, 'reg': 3, 'zip': 1, 'c': 1, 'css': 1, 'html': 1, 'dot': 1, 'svg': 1}",,,Java,1420,1,0,0,0,2153,True,0,0,0,0,0,0,0,0,7,0,0,0,,,14,# Development NotesþþRecord the development notes for future use.þþLicense:  þCode: Following the License metioned in the source code.   þNotes: [CC BY-SA 3.0 License](http://creativecommons.org/licenses/by-sa/3.0/)þþAuthor:  þfrank.xu@northbright.com,
cs231n/cs231n.github.io,,False,False,False,35476,205,7573,548,3427,51,8214,595,11,"[37, 50, 54, 56, 58, 60, 77, 79, 80, 82]",Organization,Public facing notes page,"{'': 2, 'md': 39, 'yml': 1, 'html': 8, 'png': 69, 'svg': 2, 'jpg': 19, 'jpeg': 44, 'js': 2, 'gif': 2, 'zip': 14, 'css': 1, 'ipynb': 2}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",Jupyter Notebook,732,3,0,84,0,2014,True,57,24,3,3,16,136,1,5,7,0,0,0,2,6,,Notes and assignments for Stanford CS class [CS231n: Convolutional Neural Networks for Visual Recognition](http://vision.stanford.edu/teaching/cs231n/),
conventional-changelog/conventional-changelog,,False,False,False,4245,267,4566,38,455,21,11511,12592,10,"[19, 21, 22, 36, 38, 64, 132, 144, 145, 169]",Organization,Generate changelogs and release notes from a project's commit messages and metadata.,"{'yml': 2, '': 6, 'json': 46, 'yaml': 1, 'md': 66, 'js': 107, 'hbs': 34, 'ldjson': 1, 'txt': 4}",,"{'key': 'isc', 'name': 'ISC License', 'spdx_id': 'ISC', 'url': 'https://api.github.com/licenses/isc', 'node_id': 'MDc6TGljZW5zZTEw'}",JavaScript,1369,8,641,641,5,2380,True,117,203,24,9,12,325,10,31,18,1,44664,1796,11,12,,"# Conventional Changelogþþ[![Build Status](https://travis-ci.org/conventional-changelog/conventional-changelog.svg?branch=master)](https://travis-ci.org/conventional-changelog/conventional-changelog)þ[![Coverage Status](https://coveralls.io/repos/conventional-changelog/conventional-changelog/badge.svg?branch=master)](https://coveralls.io/r/conventional-changelog/conventional-changelog?branch=master)þ[![Standard Version](https://img.shields.io/badge/release-standard%20version-brightgreen.svg)](https://github.com/conventional-changelog/standard-version)þ[![community slack](http://devtoolscommunity.herokuapp.com/badge.svg)](http://devtoolscommunity.herokuapp.com)þþ_Having problems? want to contribute? join our [community slack](http://devtoolscommunity.herokuapp.com)_.þþ> Generate a CHANGELOG from git metadataþþ## About this RepoþþThe conventional-changelog repo is managed as a [monorepo](https://github.com/babel/babel/blob/master/doc/design/monorepo.md); it's composed of many npm packages.þþThe original `conventional-changelog/conventional-changelog` API repo can beþfound in [packages/conventional-changelog](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog).þþ## Getting startedþþIt's recommended you use the high level [standard-version](https://github.com/conventional-changelog/standard-version) library, which is a drop-in replacement for npm's `version` command, handling automated version bumping, tagging and CHANGELOG generation.þþAlternatively, if you'd like to move towards completely automating your release process as an output from CI/CD, consider using [semantic-release](https://github.com/semantic-release/semantic-release).þþYou can also use one of the plugins if you are already using the tool:þþ## Plugins Supporting Conventional Changelogþþ- [grunt](https://github.com/btford/grunt-conventional-changelog)þ- [gulp](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/gulp-conventional-changelog)þ- [atom](https://github.com/conventional-changelog/atom-conventional-changelog)þ- [vscode](https://github.com/axetroy/vscode-changelog-generator)þþ## Modules Important to Conventional Changelog Ecosystemþþ- [conventional-changelog-cli](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog-cli) - the full-featured command line interfaceþ- [standard-changelog](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/standard-changelog) - command line interface for the angular commit format.þ- [conventional-github-releaser](https://github.com/conventional-changelog/conventional-github-releaser) - Make a new GitHub release from git metadataþ- [conventional-recommended-bump](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-recommended-bump) - Get a recommended version bump based on conventional commitsþ- [conventional-commits-detector](https://github.com/conventional-changelog/conventional-commits-detector) - Detect what commit message convention your repository is usingþ- [commitizen](https://github.com/commitizen/cz-cli) - Simple commit conventions for internet citizens.þ- [commitlint](https://github.com/conventional-changelog/commitlint) - Lint commit messagesþþ## Node Support PolicyþþWe only support [Long-Term Support](https://github.com/nodejs/Release) versions of Node.þþWe specifically limit our support to LTS versions of Node, not because this package won't work on other versions, but because we have a limited amount of time, and supporting LTS offers the greatest return on that investment.þþIt's possible this package will work correctly on newer versions of Node. It may even be possible to use this package on older versions of Node, though that's more unlikely as we'll make every effort to take advantage of features available in the oldest LTS version we support.þþAs each Node LTS version reaches its end-of-life we will remove that version from the `node` `engines` property of our package's `package.json` file. Removing a Node version is considered a breaking change and will entail the publishing of a new major version of this package. We will not accept any requests to support an end-of-life version of Node. Any merge requests or issues supporting an end-of-life version of Node will be closed.þþWe will accept code that allows this package to run on newer, non-LTS, versions of Node. Furthermore, we will attempt to ensure our own changes work on the latest version of Node. To help in that commitment, our continuous integration setup runs against all LTS versions of Node in addition the most recent Node release; called _current_.þþJavaScript package managers should allow you to install this package with any version of Node, with, at most, a warning if your version of Node does not fall within the range specified by our `node` `engines` property. If you encounter issues installing this package, please report the issue to your package manager.",
jrnl-org/jrnl,,False,False,False,7962,148,4346,92,400,152,3732,1369,20,"[0, 13, 21, 28, 35, 42, 44, 45, 49, 50]",Organization,Collect your thoughts and notes without leaving the command line.,"{'sh': 1, 'yml': 7, '': 6, 'md': 19, 'css': 3, 'png': 2, 'ico': 1, 'svg': 5, 'html': 1, 'js': 1, 'feature': 14, 'yaml': 25, 'json': 5, 'journal': 18, 'doentry': 7, 'template': 2, 'py': 29, 'lock': 1, 'toml': 1}",https://jrnl.sh,"{'key': 'gpl-3.0', 'name': 'GNU General Public License v3.0', 'spdx_id': 'GPL-3.0', 'url': 'https://api.github.com/licenses/gpl-3.0', 'node_id': 'MDc6TGljZW5zZTk='}",Python,962,5,46,46,7,3026,True,63,520,29,66,9,409,9,100,21,0,0,0,2,2,,"jrnl [![Build Status](https://travis-ci.com/jrnl-org/jrnl.svg?branch=master)](https://travis-ci.com/jrnl-org/jrnl) [![Downloads](https://pepy.tech/badge/jrnl)](https://pepy.tech/project/jrnl) [![Version](http://img.shields.io/pypi/v/jrnl.svg?style=flat)](https://pypi.python.org/pypi/jrnl/)þ====þþ_To get help, [submit an issue](https://github.com/jrnl-org/jrnl/issues/new) onþGithub._þþ*jrnl* is a simple journal application for your command line. Journals areþstored as human readable plain text files - you can put them into a Dropboxþfolder for instant syncing and you can be assured that your journal will stillþbe readable in 2050, when all your fancy iPad journal applications will long beþforgotten.þþOptionally, your journal can be encrypted using the [256-bitþAES](http://en.wikipedia.org/wiki/Advanced_Encryption_Standard).þþ### Why keep a journal?þþJournals aren't just for people who have too much time on their summerþvacation. A journal helps you to keep track of the things you get done and howþyou did them. Your imagination may be limitless, but your memory isn't. Forþpersonal use, make it a good habit to write at least 20 words a day. Just toþreflect what made this day special, or why you haven't wasted it. Forþprofessional use, consider a text-based journal to be the perfect complement toþyour GTD todo list - a documentation of what and how you've done it.þþIn a Nutshellþ-------------þþTo make a new entry, just typeþþ    jrnl yesterday: Called in sick. Used the time cleaning the house and writing my book.þþand hit return. `yesterday:` will be interpreted as a timestamp. Everythingþuntil the first sentence mark (`.?!`) will be interpreted as the title, theþrest as the body. In your journal file, the result will look like this:þþ    [2012-03-29 09:00] Called in sick.þ    Used the time cleaning the house and writing my book.þþIf you just call `jrnl`, you will be prompted to compose your entry - but youþcan also configure _jrnl_ to use your external editor.þþFor more information, please read our [documentation](https://jrnl.sh/overview/).þþ## Contributorsþþ### MaintainersþOur maintainers help keep the lights on for the project. Please thank them ifþyou like jrnl.þ * Jonathan Wren ([wren](https://github.com/wren))þ * Micah Ellison ([micahellison](https://github.com/micahellison))þþ### Code ContributorsþThis project is made with love by the many fabulous people who haveþcontributed. Jrnl couldn't exist without each and every one of you!þþ<a href=""https://github.com/jrnl-org/jrnl/graphs/contributors""><imgþsrc=""https://opencollective.com/jrnl/contributors.svg?width=890&button=false""þ/></a>þþIf you'd also like to help make jrnl better, please see our [contributingþdocumentation](CONTRIBUTING.md).þþ### Financial BackersþþAnother way show support is through direct financial contributions. These fundsþgo to covering our costs, and are a quick way to show your appreciation forþjrnl.þþ[Become a financial contributor](https://opencollective.com/jrnl/contribute)þand help us sustain our community.þþ<a href=""https://opencollective.com/jrnl""><imgþsrc=""https://opencollective.com/jrnl/individuals.svg?width=890""></a>",
jeffgerickson/algorithms,,False,False,False,100622,72,6644,320,898,0,0,0,0,"[375, 392, 423, 457, 458, 539, 548, 558, 561, 562]",User,"Bug-tracking for Jeff's algorithms book, notes, etc.","{'md': 5, 'pdf': 67}",,,,30,1,0,1,4,840,True,74,137,19,0,1,0,0,0,29,4,0,0,,,516,"## _Algorithms_ by [Jeff Erickson](http://jeffe.cs.illinois.edu)þþ### **1st paperback edition** — June 13, 2019 — Now available from [Amazon](https://www.amazon.com/dp/1792644833)þþThis is a bug-reporting site for my _Algorithms_ textbook and other related course materials.  Thanks for visiting!þþ**Thanks to everyone who reported bugs in the 0th and &frac12;th editions!**þþ**To report an error, please [post an issue](https://github.com/jeffgerickson/algorithms/issues).**  þ* Before submitting, please check that your error hasn't already been fixed in the most recent revision.þ* For an error in the book, please include the chapter, section, and page numbers.þ* For an error in the non-book lecture notes, please include the title and *the complete URL* of the note in question.  (There are _lots_ of old revisions floating around the web, with inconsistent titling and numbering, so just the title or the file name may not be enough.)þ* For an error in **this** semester's homework, labs, exams, or solutions, please post on the course's Piazza site for extra credit, **not** here.þ* For an error in a *past* semester's homework, labs, exams, or solutions, please post here, but again with *the complete URL* of the work in question.þþPlease also feel free to submit feature requests and other feedback.þþWhile you're here, please feel free to download a complete copy of the most recent revision of the entire book or any of the individual chapters.  (The individual chapters are extracted from the book pdf file to keep page numbers consistent; unfortunately, hyperlinks don’t work.)þþA black and white electronic version of the entire manuscript is also available, which should more closely reflect the appearance of the printed volume.  I won’t update that quite as often.þþ---þ### Publication HistoryþþThe most up-to-date version of the book and individual chapters is in the top-level directory.  Archival snapshots of official releases (“editions” or “printings”) are in corresponding subdirectories.  See the [Errata](ERRATA.md) for a list of updates since the most recent official release.þþ- **0th edition** (prepublication draft) — December 29, 2018þ- **&frac12;th edition** (prepublication draft) — April 9, 2019þ- **1st paperback edition** — June 13, 2019 — Amazon links:þ [US](https://www.amazon.com/dp/1792644833),þ [UK](https://www.amazon.co.uk/dp/1792644833),þ [DE](https://www.amazon.de/dp/1792644833),þ [ES](https://www.amazon.es/dp/1792644833),þ [FR](https://www.amazon.fr/dp/1792644833),þ [IT](https://www.amazon.it/dp/1792644833),þ [JP](https://www.amazon.co.jp/dp/1792644833)þþ---þ### Additional MaterialsþþThe book contains only a small subset of my course materials; you can find hundreds more pages of lecture notes, lab handouts, and past homeworks and exams at  http://jeffe.cs.illinois.edu/teaching/algorithms, or at the mnemonic shortcut http://algorithms.wtf.  You can see the material in context at the web sites for my most recent offerings of [CS 374](https://courses.engr.illinois.edu/cs374/sp2018/A) and [CS 473](https://courses.engr.illinois.edu/cs473/sp2017) at Illinois.þþAt some future date, I am likely to incorporate more (but definitely not all) of these lecture notes into a future edition.  (I haven't decided whether I'm going to call it a ""director's cut"" or an ""extended dance remix"".)  One step at a time.þþ---þ### CopyrightþþCopyright 2019 Jeff EricksonþþEverything _on this site_ is available under a Creative Commons Attribution 4.0 International License.þFor license details, see http://creativecommons.org/licenses/by/4.0/.",
dennybritz/deeplearning-papernotes,,False,False,False,411,101,4233,788,903,0,0,0,0,"[879, 880, 895, 896, 910, 912, 931, 933, 942, 943]",User,Summaries and notes on Deep Learning research papers,"{'': 1, 'md': 100}",,,,444,1,0,7,0,1666,True,5,2,0,0,0,33,0,0,7,0,0,0,,,8,"#### 2018-02þþ- The Matrix Calculus You Need For Deep Learning [[arXiv](https://arxiv.org/abs/1802.01528v2)]þ- Regularized Evolution for Image Classifier Architecture Search [[arXiv](https://arxiv.org/abs/1802.01548)]þ- Online Learning: A Comprehensive Survey [[arXiv](https://arxiv.org/abs/1802.02871)]þ- Visual Interpretability for Deep Learning: a Survey [[arXiv](https://arxiv.org/abs/1802.00614)]þ- Behavior is Everything – Towards Representing Concepts with Sensorimotor Contingencies [[paper](https://www.vicarious.com/wp-content/uploads/2018/01/AAAI18-pixelworld.pdf)] [[article](https://www.vicarious.com/2018/02/07/learning-concepts-through-sensorimotor-interactions/)] [[code](https://github.com/vicariousinc/pixelworld)]þ- IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures [[arXiv](https://arxiv.org/abs/1802.01561)] [[article](https://deepmind.com/blog/impala-scalable-distributed-deeprl-dmlab-30/)] [[code](https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/dmlab30)]þ- DeepType: Multilingual Entity Linking by Neural Type System Evolution [[arXiv](https://arxiv.org/abs/1802.01021)] [[article](https://blog.openai.com/discovering-types-for-entity-disambiguation/)] [[code](https://github.com/openai/deeptype)]þ- DensePose: Dense Human Pose Estimation In The Wild [[arXiv](https://arxiv.org/abs/1802.00434)] [[article](http://densepose.org/)]þþ#### 2018-01þþ- Nested LSTMs [[arXiv](https://arxiv.org/abs/1801.10308)]þ- Generating Wikipedia by Summarizing Long Sequences [[arXiv](https://arxiv.org/abs/1801.10198)]þ- Scalable and accurate deep learning for electronic health records [[arXiv](https://arxiv.org/abs/1801.07860)]þ- Kernel Feature Selection via Conditional Covariance Minimization [[NIPS paper](https://papers.nips.cc/paper/7270-kernel-feature-selection-via-conditional-covariance-minimization.pdf)] [[article](http://bair.berkeley.edu/blog/2018/01/23/kernels/)] [[code](https://github.com/Jianbo-Lab/CCM)]þ- Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents [[arXiv](https://arxiv.org/abs/1801.08116)] [[article](https://deepmind.com/blog/open-sourcing-psychlab/)] [[code](https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/psychlab)]þ- Fine-tuned Language Models for Text Classification [[arXiv](https://arxiv.org/abs/1801.06146)] [[code]()] (soon)þ- Deep Learning: An Introduction for Applied Mathematicians [[arXiv](https://arxiv.org/abs/1801.05894v1)]þ- Innateness, AlphaZero, and Artificial Intelligence [[arXiv](https://arxiv.org/abs/1801.05667)]þ- Can Computers Create Art? [[arXiv](https://arxiv.org/abs/1801.04486)]þ- eCommerceGAN : A Generative Adversarial Network for E-commerce [[arXiv](https://arxiv.org/abs/1801.03244)]þ- Expected Policy Gradients for Reinforcement Learning [[arXiv](https://arxiv.org/abs/1801.03326)]þ- DroNet: Learning to Fly by Driving [[UZH docs](http://rpg.ifi.uzh.ch/docs/RAL18_Loquercio.pdf)] [[article](http://rpg.ifi.uzh.ch/dronet.html)] [[code](https://github.com/uzh-rpg/rpg_public_dronet)]þ- Symmetric Decomposition of Asymmetric Games [[Scientific Reports](https://www.nature.com/articles/s41598-018-19194-4)] [[article](https://deepmind.com/blog/game-theory-insights-asymmetric-multi-agent-games/)]þ- Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor [[arXiv](https://arxiv.org/abs/1801.01290)] [[code](https://github.com/haarnoja/sac)]þ- SBNet: Sparse Blocks Network for Fast Inference [[arXiv](https://arxiv.org/pdf/1801.02108.pdf)] [[article](https://eng.uber.com/sbnet/)] [[code](https://github.com/uber/sbnet)]þ- DeepMind Control Suite [[arXiv](https://arxiv.org/abs/1801.00690)] [[code](https://github.com/deepmind/dm_control)]þ- Deep Learning: A Critical Appraisal [[arXiv](https://arxiv.org/abs/1801.00631)]þþþ#### 2017-12þþ- Adversarial Patch [[arXiv](https://arxiv.org/abs/1712.09665)]þ- CNN Is All You Need [[arXiv](https://arxiv.org/abs/1712.09662)]þ- Learning Robot Objectives from Physical Human Interaction [[paper](http://proceedings.mlr.press/v78/bajcsy17a/bajcsy17a.pdf)] [[article](http://bair.berkeley.edu/blog/2018/02/06/phri/)]þ- The NarrativeQA Reading Comprehension Challenge [[arXiv](https://arxiv.org/abs/1712.07040v1)] [[dataset](https://github.com/deepmind/narrativeqa)]þ- Objects that Sound [[arXiv](https://arxiv.org/abs/1712.06651)]þ- Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions [[arXiv](https://arxiv.org/abs/1712.05884)] [[article](https://research.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html)] [[article2](https://google.github.io/tacotron/publications/tacotron2/index.html)]þ- Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning [[arXiv](https://arxiv.org/abs/1712.06567)] [[article](https://eng.uber.com/deep-neuroevolution/)] [[code](https://github.com/uber-common/deep-neuroevolution)]þ- Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents [[arXiv](https://arxiv.org/abs/1712.06560)] [[article](https://eng.uber.com/deep-neuroevolution/)] [[code](https://github.com/uber-common/deep-neuroevolution)]þ- Superhuman AI for heads-up no-limit poker: Libratus beats top professionals [[Science](http://science.sciencemag.org/content/early/2017/12/15/science.aao1733)]þ- Mathematics of Deep Learning [[arXiv](https://arxiv.org/abs/1712.04741)]þ- State-of-the-art Speech Recognition With Sequence-to-Sequence Models [[arXiv](https://arxiv.org/abs/1712.01769)] [[article](https://research.googleblog.com/2017/12/improving-end-to-end-models-for-speech.html)]þ- Peephole: Predicting Network Performance Before Training [[arXiv](https://arxiv.org/abs/1712.03351)]þ- Deliberation Network: Pushing the frontiers of neural machine translation [[Research at Microsoft](https://www.microsoft.com/en-us/research/publication/deliberation-networks-sequence-generation-beyond-one-pass-decoding/)] [[article](https://www.microsoft.com/en-us/research/blog/deliberation-networks/)]þ- GPU Kernels for Block-Sparse Weights [[Research at OpenAI](https://s3-us-west-2.amazonaws.com/openai-assets/blocksparse/blocksparsepaper.pdf)] [[article](https://blog.openai.com/block-sparse-gpu-kernels/)] [[code](https://github.com/openai/blocksparse)]þ- Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm [[arXiv](https://arxiv.org/abs/1712.01815)]þ- Deep Learning Scaling is Predictable, Empirically [[arXiv](https://arxiv.org/abs/1712.00409)] [[article](http://research.baidu.com/deep-learning-scaling-predictable-empirically/)]þþ#### 2017-11þþ- High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs [[arXiv](https://arxiv.org/abs/1711.11585)] [[article](https://tcwang0509.github.io/pix2pixHD/)] [[code](https://github.com/NVIDIA/pix2pixHD)]þ- StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation [[arXiv](https://arxiv.org/abs/1711.09020)] [[code](https://github.com/yunjey/StarGAN/)]þ- Population Based Training of Neural Networks [[arXiv](https://arxiv.org/abs/1711.09846)] [[article](https://deepmind.com/blog/population-based-training-neural-networks/)]þ- Distilling a Neural Network Into a Soft Decision Tree [[arXiv](https://arxiv.org/abs/1711.09784)]þ- Neural Text Generation: A Practical Guide [[arXiv](https://arxiv.org/abs/1711.09534)]þ- Parallel WaveNet: Fast High-Fidelity Speech Synthesis [[DeepMind documents](https://deepmind.com/documents/131/Distilling_WaveNet.pdf)] [[article](https://deepmind.com/blog/high-fidelity-speech-synthesis-wavenet/)]þ- CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning [[arXiv](https://arxiv.org/abs/1711.05225)] [[article](https://stanfordmlgroup.github.io/projects/chexnet/)]þ- Non-local Neural Networks [[arXiv](https://arxiv.org/abs/1711.07971)]þ- Deep Image Prior [[paper](https://sites.skoltech.ru/app/data/uploads/sites/25/2017/11/deep_image_prior.pdf)] [[article](https://dmitryulyanov.github.io/deep_image_prior)] [[code](https://github.com/DmitryUlyanov/deep-image-prior)]þ- Online Deep Learning: Learning Deep Neural Networks on the Fly [[arXiv](https://arxiv.org/abs/1711.03705)]þ- Learning Explanatory Rules from Noisy Data [[arXiv](https://arxiv.org/abs/1711.04574)]þ- Improving Palliative Care with Deep Learning [[arXiv](https://arxiv.org/abs/1711.06402)] [[article](https://stanfordmlgroup.github.io/projects/improving-palliative-care/)]þ- VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection [[arXiv](https://arxiv.org/abs/1711.06396)]þ- Weighted Transformer Network for Machine Translation [[arXiv](https://arxiv.org/abs/1711.02132)] [[article](https://einstein.ai/research/weighted-transformer)]þ- Non-Autoregressive Neural Machine Translation [[arXiv](https://arxiv.org/abs/1711.02281)] [[article](https://einstein.ai/research/non-autoregressive-neural-machine-translation)]þ- Block-Sparse Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1711.02782)]þ- A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning [[arXiv](https://arxiv.org/abs/1711.00832)]þ- Neural Discrete Representation Learning [[arXiv](https://arxiv.org/abs/1711.00937)] [[article](https://avdnoord.github.io/homepage/vqvae/)]þ- Don't Decay the Learning Rate, Increase the Batch Size [[arXiv](https://arxiv.org/abs/1711.00489)]þ- Hierarchical Representations for Efficient Architecture Search [[arXiv](https://arxiv.org/abs/1711.00436)]þþ#### 2017-10þþ- Unsupervised Machine Translation Using Monolingual Corpora Only [[arXiv](https://arxiv.org/abs/1711.00043)]þ- Dynamic Routing Between Capsules [[arXiv](https://arxiv.org/abs/1710.09829)]þ- A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs [[Science](http://science.sciencemag.org/content/early/2017/10/26/science.aag2612.full)] [[article](https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/)] [[code](https://github.com/vicariousinc/science_rcn)]þ- Understanding Grounded Language Learning Agents [[arXiv](https://arxiv.org/abs/1710.09867)]þ- Planning, Fast and Slow: A Framework for Adaptive Real-Time Safe Trajectory Planning [[arXiv](https://arxiv.org/abs/1710.04731)] [[article](http://bair.berkeley.edu/blog/2017/12/05/fastrack/)] [[code](https://github.com/HJReachability)] (soon)þ- Malware Detection by Eating a Whole EXE [[arXiv](https://arxiv.org/abs/1710.09435)] [[article](https://devblogs.nvidia.com/malware-detection-neural-networks/)]þ- Progressive Growing of GANs for Improved Quality, Stability, and Variation [[Research at Nvidia](http://research.nvidia.com/sites/default/files/pubs/2017-10_Progressive-Growing-of//karras2017gan-paper.pdf)] [[article](http://research.nvidia.com/publication/2017-10_Progressive-Growing-of)] [[code](https://github.com/tkarras/progressive_growing_of_gans)]þ- Meta Learning Shared Hierarchies [[arXiv](https://arxiv.org/abs/1710.09767)] [[article](https://blog.openai.com/learning-a-hierarchy/)] [[code](https://github.com/openai/mlsh)]þ- Deep Voice 3: 2000-Speaker Neural Text-to-Speech [[arXiv](http://research.baidu.com/deep-voice-3-2000-speaker-neural-text-speech/)] [[article](http://research.baidu.com/deep-voice-3-2000-speaker-neural-text-speech/)]þ- AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions [[arXiv](https://arxiv.org/abs/1705.08421)] [[article](https://research.googleblog.com/2017/10/announcing-ava-finely-labeled-video.html)] [[dataset](https://research.google.com/ava/)]þ-  Mastering the game of Go without Human Knowledge [[Nature](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ)] [[article](https://deepmind.com/blog/alphago-zero-learning-scratch/)]þ-  Sim-to-Real Transfer of Robotic Control with Dynamics Randomization [[arXiv](https://arxiv.org/abs/1710.06537)] [[article](https://blog.openai.com/generalizing-from-simulation/)]þ-  Asymmetric Actor Critic for Image-Based Robot Learning [[arXiv](https://arxiv.org/abs/1710.06542)] [[article](https://blog.openai.com/generalizing-from-simulation/)]þ-  A systematic study of the class imbalance problem in convolutional neural networks [[arXiv](https://arxiv.org/abs/1710.05381)]þ-  Generalization in Deep Learning [[arXiv](https://arxiv.org/abs/1710.05468)]þ- Swish: a Self-Gated Activation Function [[arXiv](https://arxiv.org/abs/1710.05941)]þ- Emergent Translation in Multi-Agent Communication [[arXiv](https://arxiv.org/abs/1710.06922)]þ- SLING: A framework for frame semantic parsing [[arXiv](https://arxiv.org/abs/1710.07032)] [[article](https://research.googleblog.com/2017/11/sling-natural-language-frame-semantic.html)] [[code](https://github.com/google/sling)]þ- Meta-Learning for Wrestling [[arXiv](https://arxiv.org/abs/1710.03641)] [[article](https://blog.openai.com/meta-learning-for-wrestling/)] [[code](https://github.com/openai/robosumo)]þ- Mixed Precision Training [[arXiv](https://arxiv.org/abs/1710.03740)] [[article](http://research.baidu.com/mixed-precision-training/)] [[article2](https://devblogs.nvidia.com/parallelforall/mixed-precision-training-deep-neural-networks/)] [[code/docs](http://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html)]þ- Generative Adversarial Networks: An Overview [[arXiv](https://arxiv.org/abs/1710.07035)]þ- Emergent Complexity via Multi-Agent Competition [[arXiv](https://arxiv.org/abs/1710.03748)] [[article](https://blog.openai.com/competitive-self-play/)] [[code](https://github.com/openai/multiagent-competition)]þ- Deep Lattice Networks and Partial Monotonic Functions [[Research at Google](https://research.google.com/pubs/pub46327.html)] [[article](https://research.googleblog.com/2017/10/tensorflow-lattice-flexibility.html)] [[code](https://github.com/tensorflow/lattice)]þ- The IIT Bombay English-Hindi Parallel Corpus [[arXiv](https://arxiv.org/abs/1710.02855)] [[article](http://www.cfilt.iitb.ac.in/iitb_parallel/)]þ- Rainbow: Combining Improvements in Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1710.02298)]þ- Lifelong Learning With Dynamically Expandable Networks [[arXiv](https://arxiv.org/abs/1708.01547)]þ- Variational Inference & Deep Learning: A New Synthesis (Thesis) [[dropbox](https://www.dropbox.com/s/v6ua3d9yt44vgb3/cover_and_thesis.pdf)]þ- Neural Task Programming: Learning to Generalize Across Hierarchical Tasks [[arXiv](https://arxiv.org/abs/1710.01813)]þ- Neural Color Transfer between Images [[arXiv](https://arxiv.org/abs/1710.00756)]þ- The hippocampus as a predictive map [[biorXiv](https://www.biorxiv.org/content/biorxiv/early/2017/07/25/097170.full.pdf)] [[article](https://deepmind.com/blog/hippocampus-predictive-map/)]þ- Scalable and accurate deep learning for electronic healthþrecords [[arXiv](https://arxiv.org/abs/1801.07860)]þþ#### 2017-09þþ- Variational Memory Addressing in Generative Models [[arXiv](https://arxiv.org/abs/1709.07116)]þ- Overcoming Exploration in Reinforcement Learning with Demonstrations [[arXiv](https://arxiv.org/abs/1709.10089)]þ- A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement [[arXiv](https://arxiv.org/abs/1709.08243)] [[article](https://people.xiph.org/~jm/demo/rnnoise/)] [[code](https://github.com/xiph/rnnoise/)]þ- ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks onþWeakly-Supervised Classification and Localization of Common Thorax Diseases [[CVF](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf)] [[article](https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community)] [[dataset](https://nihcc.app.box.com/v/ChestXray-NIHCC)]þ- NIMA: Neural Image Assessment [[arXiv](https://arxiv.org/abs/1709.05424)] [[article](https://research.googleblog.com/2017/12/introducing-nima-neural-image-assessment.html)]þ- Generating Sentences by Editing Prototypes [[arXiv](https://arxiv.org/abs/1709.08878)] [[code](https://github.com/kelvinguu/neural-editor)]þ- The Consciousness Prior [[arXiv](https://arxiv.org/abs/1709.08568)]þ- StarSpace: Embed All The Things! [[arXiv](https://arxiv.org/abs/1709.03856)] [[code](https://github.com/facebookresearch/Starspace)]þ- Neural Optimizer Search with Reinforcement Learning [[arXiv](https://arxiv.org/abs/1709.07417)]þ- Dynamic Evaluation of Neural Sequence Models [[arXiv](https://arxiv.org/abs/1709.07432)]þ- Neural Machine Translation [[arXiv](https://arxiv.org/abs/1709.07809)]þ- Matterport3D: Learning from RGB-D Data in Indoor Environments [[arXiv](https://arxiv.org/abs/1709.06158)] [[article](https://niessner.github.io/Matterport/)] [[article2](https://hackernoon.com/announcing-the-matterport3d-research-dataset-815cae932939)] [[code](https://github.com/niessner/Matterport)]þ- Deep Reinforcement Learning that Matters [[arXiv](https://arxiv.org/abs/1709.06560)] [[code](https://github.com/Breakend/DeepReinforcementLearningThatMatters)]þ- The Uncertainty Bellman Equation and Exploration [[arXiv](https://arxiv.org/abs/1709.05380)]þ- WESPE: Weakly Supervised Photo Enhancer for Digital Cameras [[arXiv](https://arxiv.org/abs/1709.01118)] [[article](http://people.ee.ethz.ch/~ihnatova/wespe.html)]þ- Globally Normalized Reader [[arXiv](https://arxiv.org/abs/1709.02828)] [[article](http://research.baidu.com/gnr/)] [[code](https://github.com/baidu-research/GloballyNormalizedReader)]þ- A Brief Introduction to Machine Learning for Engineers [[arXiv](https://arxiv.org/abs/1709.02840)]þ- Learning with Opponent-Learning Awareness [[arXiv](https://arxiv.org/abs/1709.04326)] [[article](https://blog.openai.com/learning-to-model-other-minds/)]þ- A Deep Reinforcement Learning Chatbot [[arXiv](https://arxiv.org/abs/1709.02349)]þ- Squeeze-and-Excitation Networks [[arXiv](https://arxiv.org/abs/1709.01507)]þ- Efficient Methods and Hardware for Deep Learning (Thesis) [[Stanford Digital Repository](https://purl.stanford.edu/qf934gh3708)]þþ#### 2017-08þþ- Design and Analysis of the NIPS 2016 Review Process [[arXiv](https://arxiv.org/abs/1708.09794)]þ- Fast Automated Analysis of Strong Gravitational Lenses with Convolutional Neural Networks [[arXiv](https://arxiv.org/abs/1708.08842)] [[article](http://www.symmetrymagazine.org/article/neural-networks-meet-space)]þ- TensorFlow Agents: Efficient Batched Reinforcement Learning in TensorFlow [[white paper](https://drive.google.com/file/d/0B20Yn-GSaVHGMVlPanRTRlNIRlk/view)] [[code](https://github.com/tensorflow/agents)]þ- Automated Crowdturfing Attacks and Defenses in Online Review Systems [[arXiv](https://arxiv.org/abs/1708.08151)]þ- Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning [[arXiv](https://arxiv.org/abs/1708.02596)] [[article](http://bair.berkeley.edu/blog/2017/11/30/model-based-rl/)] [[code](https://github.com/nagaban2/nn_dynamics)]þ- Deep Learning for Video Game Playing [[arXiv](https://arxiv.org/abs/1708.07902)]þ- Deep & Cross Network for Ad Click Predictions [[arXiv](https://arxiv.org/abs/1708.05123)]þ- Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms [[arXiv](https://arxiv.org/abs/1708.07747)] [[code](https://github.com/zalandoresearch/fashion-mnist)]þ- Multi-task Self-Supervised Visual Learning [[arXiv](https://arxiv.org/abs/1708.07860)]þ- Learning a Multi-View Stereo Machine [[arXiv](https://arxiv.org/abs/1708.05375)] [[article](http://bair.berkeley.edu/blog/2017/09/05/unified-3d/)] [[code]()] (soon)þ- Twin Networks: Using the Future as a Regularizer [[arXiv](https://arxiv.org/abs/1708.06742)]þ- A Brief Survey of Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1708.05866)]þ- Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation [[arXiv](https://arxiv.org/abs/1708.05144)] [[code](https://github.com/openai/baselines)]þ- On the Effectiveness of Visible Watermarks [[CVPR](http://openaccess.thecvf.com/content_cvpr_2017/papers/Dekel_On_the_Effectiveness_CVPR_2017_paper.pdf)] [[article](https://research.googleblog.com/2017/08/making-visible-watermarks-more-effective.html)]þ- Practical Network Blocks Design with Q-Learning [[arXiv](https://arxiv.org/abs/1708.05552)]þ- On Ensuring that Intelligent Machines Are Well-Behaved [[arXiv](https://arxiv.org/abs/1708.05448)]þ- Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control [[arXiv](https://arxiv.org/abs/1708.04133)] [[code](https://github.com/Breakend/ReproducibilityInContinuousPolicyGradientMethods)]þ- Training Deep AutoEncoders for Collaborative Filtering [[arXiv](https://arxiv.org/abs/1708.01715)] [[code](https://github.com/NVIDIA/DeepRecommender)]þ- Learning to Perform a Perched Landing on the GroundUsing Deep Reinforcement Learning [[nature](https://link.springer.com/epdf/10.1007/s10846-017-0696-1?author_access_token=BEvJgzY3QauUddBuQAus2ve4RwlQNchNByi7wbcMAY5xhRRqI6HVNnXt8Pgp850SnuV5ue6mUo3Jc7FIP5FgLmqk34Wob3oqyuGtkg7E_1T0dg02IYhfY-3dvb8R9zEmaGzTogYCIXm4O4vZ_tSGnA%3D%3D)]þ- Revisiting the Effectiveness of Off-the-shelf Temporal Modeling Approaches for Large-scale Video Classification [[arXiv](https://arxiv.org/abs/1708.03805)] [[article](http://research.baidu.com/spatial-temporal-modeling-framework-large-scale-video-understanding/)]þ- Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning [[arXiv](https://arxiv.org/abs/1708.02190)]þ- Neural Expectation Maximization [[arXiv](https://arxiv.org/abs/1708.03498)] [[code](https://github.com/sjoerdvansteenkiste/)]þ- Google Vizier: A Service for Black-Box Optimization [[Research at Google](https://research.google.com/pubs/pub46180.html)]þ- STARDATA: A StarCraft AI Research Dataset [[arXiv](https://arxiv.org/abs/1708.02139)] [[code](https://github.com/TorchCraft/StarData)]þ- Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm [[arXiv](https://arxiv.org/abs/1708.00524)] [[code](https://github.com/bfelbo/deepmoji)] [[article](https://www.media.mit.edu/posts/what-can-we-learn-from-emojis/)]þ- Natural Language Processing with Small Feed-Forward Networks [[arXiv](https://arxiv.org/abs/1708.00214)]þþ#### 2017-07þþ- Photographic Image Synthesis with Cascaded Refinement Networks [[arXiv](https://arxiv.org/abs/1707.09405)] [[code](https://github.com/CQFIO/PhotographicImageSynthesis)]þ- StarCraft II: A New Challenge for Reinforcement Learning [[DeepMind Documents](https://deepmind.com/documents/110/sc2le.pdf)] [[code](https://github.com/deepmind/pysc2)] [[article](https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/)]þ- Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards [[arXiv](https://arxiv.org/abs/1707.08817)]þ- Reinforcement Learning with Deep Energy-Based Policies [[arXiv](https://arxiv.org/abs/1702.08165)] [[article](http://bair.berkeley.edu/blog/2017/10/06/soft-q-learning/)] [[code](https://github.com/haarnoja/softqlearning)]þ- DARLA: Improving Zero-Shot Transfer in Reinforcement Learning [[arXiv](https://arxiv.org/abs/1707.08475)]þ- Synthesizing Robust Adversarial Examples [[arXiv](https://arxiv.org/abs/1707.07397)] [[article](http://www.labsix.org/physical-objects-that-fool-neural-nets/)] [[code]()] (Soon)þ- Voice Synthesis for in-the-Wild Speakers via a Phonological Loop [[arXiv](https://arxiv.org/abs/1707.06588)] [[code](https://github.com/facebookresearch/loop)] [[article](https://ytaigman.github.io/loop/)]þ- Eyemotion: Classifying facial expressions in VR using eye-tracking cameras [[arXiv](https://arxiv.org/abs/1707.07204)] [[article](https://research.googleblog.com/2017/07/expressions-in-virtual-reality.html)]þ- A Distributional Perspective on Reinforcement Learning [[arXiv](https://arxiv.org/abs/1707.06887)] [[article](https://deepmind.com/blog/going-beyond-average-reinforcement-learning/)] [[video](https://vimeo.com/235922311)]þ- On the State of the Art of Evaluation in Neural Language Models [[arXiv](https://arxiv.org/abs/1707.05589)]þ- Optimizing the Latent Space of Generative Networks [[arXiv](https://arxiv.org/abs/1707.05776)]þ- Neuroscience-Inspired Artificial Intelligence [[Neuron](http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3?_returnURL=http%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627317305093%3Fshowall%3Dtrue)] [[article](https://deepmind.com/blog/ai-and-neuroscience-virtuous-circle/)]þ- Learning Transferable Architectures for Scalable Image Recognition [[arXiv](https://arxiv.org/abs/1707.07012)]þ- Reverse Curriculum Generation for Reinforcement Learning [[arXiv](https://arxiv.org/abs/1707.05300)]þ- Imagination-Augmented Agents for Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1707.06203)] [[article](https://deepmind.com/blog/agents-imagine-and-plan/)]þ- Learning model-based planning from scratch [[arXiv](https://arxiv.org/abs/1707.06170)] [[article](https://deepmind.com/blog/agents-imagine-and-plan/)]þ- Proximal Policy Optimization Algorithms [[AWSS3](https://openai-public.s3-us-west-2.amazonaws.com/blog/2017-07/ppo/ppo-arxiv.pdf)] [[code](https://github.com/openai/baselines)]þ- Automatic Recognition of Deceptive Facial Expressions of Emotion [[arXiv](https://arxiv.org/abs/1707.04061)]þ- Distral: Robust Multitask Reinforcement Learning [[arXiv](https://arxiv.org/abs/1707.04175)]þ- Creatism: A deep-learning photographer capable of creating professional work [[arXiv](https://arxiv.org/abs/1707.03491)] [[article](https://research.googleblog.com/2017/07/using-deep-learning-to-create.html)]þ- SCAN: Learning Abstract Hierarchical Compositional Visual Concepts [[arXiv](https://arxiv.org/abs/1707.03389)] [[article](https://deepmind.com/blog/imagine-creating-new-visual-concepts-recombining-familiar-ones/)]þ- Revisiting Unreasonable Effectiveness of Data in Deep Learning Era [[arXiv](https://arxiv.org/abs/1707.02968)] [[article](https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html)]þ- The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously [[arXiv](https://arxiv.org/abs/1707.03300)]þ- Deep Bilateral Learning for Real-Time Image Enhancement [[arXiv](https://arxiv.org/abs/1707.02880)] [[code](https://github.com/mgharbi/hdrnet)] [[article](https://groups.csail.mit.edu/graphics/hdrnet/)]þ- Emergence of Locomotion Behaviours in Rich Environments [[arXiv](https://arxiv.org/abs/1707.02286)] [[article](https://deepmind.com/blog/producing-flexible-behaviours-simulated-environments/)]þ- Learning human behaviors from motion capture by adversarial imitation [[arXiv](https://arxiv.org/abs/1707.02201)] [[article](https://deepmind.com/blog/producing-flexible-behaviours-simulated-environments/)]þ- Robust Imitation of Diverse Behaviors [[arXiv](https://deepmind.com/documents/95/diverse_arxiv.pdf)] [[article](https://deepmind.com/blog/producing-flexible-behaviours-simulated-environments/)]þ- [Hindsight Experience Replay](notes/hindsight-ep.md) [[arXiv](https://arxiv.org/abs/1707.01495)]þ- Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks [[arXiv](https://arxiv.org/abs/1707.01836)] [[article](https://stanfordmlgroup.github.io/projects/ecg/)]þ- End-to-End Learning of Semantic Grasping [[arXiv](https://arxiv.org/abs/1707.01932)]þ- ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games [[arXiv](https://arxiv.org/abs/1707.01067)] [[code](https://github.com/facebookresearch/ELF)] [[article](https://code.facebook.com/posts/132985767285406/introducing-elf-an-extensive-lightweight-and-flexible-platform-for-game-research/)]þþ#### 2017-06þþ- [Noisy Networks for Exploration](notes/noisy-networks-4-exploration.md) [[arXiv](https://arxiv.org/abs/1706.10295)]þ- Do GANs actually learn the distribution? An empirical study [[arXiv](https://arxiv.org/abs/1706.08224)]þ- Gradient Episodic Memory for Continuum Learning [[arXiv](https://arxiv.org/abs/1706.08840)]þ- Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog [[arXiv](https://arxiv.org/abs/1706.08502)] [[code](https://github.com/batra-mlp-lab/lang-emerge)]þ- Deep Interest Network for Click-Through Rate Prediction [[arXiv](https://arxiv.org/abs/1706.06978)]þ- Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study [[arXiv](https://arxiv.org/abs/1706.08606)] [[article](https://deepmind.com/blog/cognitive-psychology/)]þ- Structure Learning in Motor Control: A Deep Reinforcement Learning Model [[arXiv](https://arxiv.org/abs/1706.06827)]þ- Programmable Agents [[arXiv](https://arxiv.org/abs/1706.06383)]þ- Grounded Language Learning in a Simulated 3D World [[arXiv](https://arxiv.org/abs/1706.06551)]þ- Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics [[arXiv](https://arxiv.org/abs/1706.04317)]þ- SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability [[arXiv](https://arxiv.org/abs/1706.05806)] [[article](https://research.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html)] [[code](https://github.com/google/svcca)]þ- One Model To Learn Them All [[arXiv](https://arxiv.org/abs/1706.05137)] [[code](https://github.com/tensorflow/tensor2tensor)] [[article](https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html)]þ- Hybrid Reward Architecture for Reinforcement Learning [[arXiv](https://arxiv.org/abs/1706.04208)]þ- Expected Policy Gradients [[arXiv](https://arxiv.org/abs/1706.05374)]þ- Variational Approaches for Auto-Encoding Generative Adversarial Networks [[arXiv](https://arxiv.org/abs/1706.04987)]þ- Deal or No Deal? End-to-End Learning for Negotiation Dialogues [[S3AWS](https://s3.amazonaws.com/end-to-end-negotiator/end-to-end-negotiator.pdf)] [[code](https://github.com/facebookresearch/end-to-end-negotiator)] [[article](https://code.facebook.com/posts/1686672014972296/deal-or-no-deal-training-ai-bots-to-negotiate/)]þ- Attention Is All You Need [[arXiv](https://arxiv.org/abs/1706.03762)] [[code](https://github.com/tensorflow/tensor2tensor)] [[article](https://research.googleblog.com/2017/08/transformer-novel-neural-network.html)]þ- Sobolev Training for Neural Networks [[arXiv](https://arxiv.org/abs/1706.04859)]þ- YellowFin and the Art of Momentum Tuning [[arXiv](https://arxiv.org/abs/1706.03471)] [[code](https://github.com/JianGoForIt/YellowFin)] [[article](http://dawn.cs.stanford.edu/2017/07/05/yellowfin/)]þ- Forward Thinking: Building and Training Neural Networks One Layer at a Time [[arXiv](https://arxiv.org/abs/1706.02480)]þ- Depthwise Separable Convolutions for Neural Machine Translation [[arXiv](https://arxiv.org/abs/1706.03059)] [[code](https://github.com/tensorflow/tensor2tensor)]þ- Parameter Space Noise for Exploration [[arXiv](https://arxiv.org/abs/1706.01905)] [[code](https://github.com/openai/baselines)] [[article](https://blog.openai.com/better-exploration-with-parameter-noise/)]þ- Deep Reinforcement Learning from human preferences [[arXiv](https://arxiv.org/abs/1706.03741)] [[article](https://blog.openai.com/deep-reinforcement-learning-from-human-preferences/)]þ- Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments [[arXiv](https://arxiv.org/abs/1706.02275)] [[code](https://github.com/openai/multiagent-particle-envs)]þ- Self-Normalizing Neural Networks [[arXiv](https://arxiv.org/abs/1706.02515)] [[code](https://github.com/bioinf-jku/SNNs)]þ- Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour [[arXiv](https://arxiv.org/abs/1706.02677)]þ- A simple neural network module for relational reasoning [[arXiv](https://arxiv.org/abs/1706.01427)] [[article](https://deepmind.com/blog/neural-approach-relational-reasoning/)]þ- Visual Interaction Networks [[arXiv](https://arxiv.org/abs/1706.01433)] [[article](https://deepmind.com/blog/neural-approach-relational-reasoning/)]þþ#### 2017-05þþ- Supervised Learning of Universal Sentence Representations from Natural Language Inference Data [[arXiv](https://arxiv.org/abs/1705.02364)]  [[code](https://github.com/facebookresearch/InferSent)]þ- pix2code: Generating Code from a Graphical User Interface Screenshot [[arXiv](https://arxiv.org/abs/1705.07962)] [[article](https://uizard.io/research#pix2code)] [[code](https://github.com/tonybeltramelli/pix2code)]þ- The Cramer Distance as a Solution to Biased Wasserstein Gradients [[arXiv](https://arxiv.org/abs/1705.10743)]þ- Reinforcement Learning with a Corrupted Reward Channel [[arXiv](https://arxiv.org/abs/1705.08417)]þ- Dilated Residual Networks [[arXiv](https://arxiv.org/abs/1705.09914)] [[code](https://github.com/fyu/drn)]þ- Bayesian GAN [[arXiv](https://arxiv.org/abs/1705.09558)] [[code](https://github.com/andrewgordonwilson/bayesgan/)]þ- Gradient Descent Can Take Exponential Time to Escape Saddle Points [[arXiv](https://arxiv.org/abs/1705.10412)] [[article](http://bair.berkeley.edu/blog/2017/08/31/saddle-efficiency/)]þ- Thinking Fast and Slow with Deep Learning and Tree Search [[arXiv]()]þ- ParlAI: A Dialog Research Software Platform [[arXiv](https://arxiv.org/abs/1705.06476)] [[code](https://github.com/facebookresearch/ParlAI)] [[article](https://code.facebook.com/posts/266433647155520/parlai-a-new-software-platform-for-dialog-research/)]þ- Semantically Decomposing the Latent Spaces of Generative Adversarial Networks [[arXiv](https://arxiv.org/abs/1705.07904)] [[article](https://aws.amazon.com/blogs/ai/combining-deep-learning-networks-gan-and-siamese-to-generate-high-quality-life-like-images/)]þ- Look, Listen and Learn [[arXiv](https://arxiv.org/abs/1705.08168)]þ- Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset [[arXiv](https://arxiv.org/abs/1705.07750)] [[code](https://github.com/deepmind/kinetics-i3d)]þ- Convolutional Sequence to Sequence Learning [[arXiv](https://arxiv.org/abs/1705.03122)] [[code](https://github.com/facebookresearch/fairseq)] [[code2](https://github.com/facebookresearch/fairseq-py)] [[article](https://code.facebook.com/posts/1978007565818999/a-novel-approach-to-neural-machine-translation/)]þ- The Kinetics Human Action Video Dataset [[arXiv](https://arxiv.org/abs/1705.06950)] [[article](https://deepmind.com/research/open-source/open-source-datasets/kinetics/)]þ- Safe and Nested Subgame Solving for Imperfect-Information Games [[arXiv](https://arxiv.org/abs/1705.02955)]þ- Discrete Sequential Prediction of Continuous Actions for Deep RL [[arXiv](https://arxiv.org/abs/1705.05035)]þ- Metacontrol for Adaptive Imagination-Based Optimization [[arXiv](https://arxiv.org/abs/1705.02670)]þ- Efficient Parallel Methods for Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1705.04862)]þ- Real-Time Adaptive Image Compression [[arXiv](https://arxiv.org/abs/1705.05823)]þþ#### 2017-04þþ- General Video Game AI: Learning from Screen Capture [[arXiv](https://arxiv.org/abs/1704.06945)]þ- Learning to Skim Text [[arXiv](https://arxiv.org/abs/1704.06877)]þ- Get To The Point: Summarization with Pointer-Generator Networks [[arXiv](https://arxiv.org/abs/1704.04368)] [[code](https://github.com/abisee/pointer-generator)] [[article](http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html)]þ- Adversarial Neural Machine Translation [[arXiv](https://arxiv.org/abs/1704.06933)]þ- [Deep Q-learning from Demonstrations](notes/dqn-demonstrations.md) [[arXiv](https://arxiv.org/abs/1704.03732)]þ- Learning from Demonstrations for Real World Reinforcement Learning [[arXiv](https://arxiv.org/abs/1704.03732)]þ- DSLR-Quality Photos on Mobile Devices with Deep Convolutional Networks [[arXiv](https://arxiv.org/abs/1704.02470)] [[article](http://people.ee.ethz.ch/~ihnatova/)] [[code](https://github.com/aiff22/DPED)]þ- A Neural Representation of Sketch Drawings [[arXiv](https://arxiv.org/abs/1704.03477)] [[code](https://github.com/tensorflow/magenta/tree/master/magenta/models/sketch_rnn)] [[article](https://research.googleblog.com/2017/04/teaching-machines-to-draw.html)]þ- Automated Curriculum Learning for Neural Networks [[arXiv](https://arxiv.org/abs/1704.03003)]þ- Hierarchical Surface Prediction for 3D Object Reconstruction [[arXiv](https://arxiv.org/abs/1704.00710)] [[article](http://bair.berkeley.edu/blog/2017/08/23/high-quality-3d-obj-reconstruction/)]þ- Neural Message Passing for Quantum Chemistry [[arXiv](https://arxiv.org/abs/1704.01212)]þ- Learning to Generate Reviews and Discovering Sentiment [[arXiv](https://arxiv.org/abs/1704.01444)] [[code](https://github.com/openai/generating-reviews-discovering-sentiment)]þ- Best Practices for Applying Deep Learning to Novel Applications [[arXiv](https://arxiv.org/abs/1704.01568)]þþ#### 2017-03þþ- Improved Training of Wasserstein GANs [[arXiv](https://arxiv.org/abs/1704.00028)]þ- Evolution Strategies as a Scalable Alternative to Reinforcement Learning [[arXiv](https://arxiv.org/abs/1703.03864)]þ- Controllable Text Generation [[arXiv](https://arxiv.org/abs/1703.00955)]þ- Neural Episodic Control [[arXiv](https://arxiv.org/abs/1703.01988)]þ- [A Structured Self-attentive Sentence Embedding](notes/self_attention_embedding.md) [[arXiv](https://arxiv.org/abs/1703.03130)]þ- Multi-step Reinforcement Learning: A Unifying Algorithm [[arXiv](https://arxiv.org/abs/1703.01327)]þ- Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG [[arXiv](https://arxiv.org/abs/1703.05051)]þ- FaSTrack: a Modular Framework for Fast and Guaranteed Safe Motion Planning [[arXiv](https://arxiv.org/abs/1703.07373)] [[article](http://bair.berkeley.edu/blog/2017/12/05/fastrack/)] [[article2](http://sylviaherbert.com/fastrack/)]þ- Massive Exploration of Neural Machine Translation Architectures [[arXiv](https://arxiv.org/abs/1703.03906)] [[code](https://github.com/google/seq2seq)]þ- Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression [[arXiv](https://arxiv.org/abs/1703.07834)] [[article](http://aaronsplace.co.uk/papers/jackson2017recon/)] [[code](https://github.com/AaronJackson/vrn)]þ- Minimax Regret Bounds for Reinforcement Learning [[arXiv](https://arxiv.org/abs/1703.05449)]þ- Sharp Minima Can Generalize For Deep Nets [[arXiv](https://arxiv.org/abs/1703.04933)]þ- Parallel Multiscale Autoregressive Density Estimation [[arXiv](https://arxiv.org/abs/1703.03664)]þ- Neural Machine Translation and Sequence-to-sequence Models: A Tutorial [[arXiv](https://arxiv.org/abs/1703.01619)]þ- Large-Scale Evolution of Image Classifiers [[arXiv](https://arxiv.org/abs/1703.01041)]þ- FeUdal Networks for Hierarchical Reinforcement Learning [[arXiv](https://arxiv.org/abs/1703.01161)]þ- Evolving Deep Neural Networks [[arXiv](https://arxiv.org/abs/1703.00548)]þ- How to Escape Saddle Points Efficiently [[arXiv](https://arxiv.org/abs/1703.00887)] [[article](http://bair.berkeley.edu/blog/2017/08/31/saddle-efficiency/)]þ- Opening the Black Box of Deep Neural Networks via Information [[arXiv](https://arxiv.org/abs/1703.00810)] [[video](https://youtu.be/bLqJHjXihK8)]þ- Understanding Synthetic Gradients and Decoupled Neural Interfaces [[arXiv](https://arxiv.org/abs/1703.00522)]þ- Learning to Optimize Neural Nets [[arXiv](https://arxiv.org/abs/1703.00441)] [[article](http://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/)]þþþ#### 2017-02þþ- The Shattered Gradients Problem: If resnets are the answer, then what is the question? [[arXiv](https://arxiv.org/abs/1702.08591)]þ- Neural Map: Structured Memory for Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1702.08360)]þ- Bridging the Gap Between Value and Policy Based Reinforcement Learning [[arXiv](https://arxiv.org/abs/1702.08892)]þ- Deep Voice: Real-time Neural Text-to-Speech [[arXiv](https://arxiv.org/abs/1702.07825)]þ- Beating the World's Best at Super Smash Bros. with Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1702.06230)]þ- The Game Imitation: Deep Supervised Convolutional Networks for Quick Video Game AI [[arXiv](https://arxiv.org/abs/1702.05663)]þ- Learning to Parse and Translate Improves Neural Machine Translation [[arXiv](https://arxiv.org/abs/1702.03525)]þ- All-but-the-Top: Simple and Effective Postprocessing for Word Representations [[arXiv](https://arxiv.org/abs/1702.01417)]þ- Deep Learning with Dynamic Computation Graphs [[arXiv](https://arxiv.org/abs/1702.02181)]þ- Skip Connections as Effective Symmetry-Breaking [[arXiv](https://arxiv.org/abs/1701.09175)]þ- odelSemi-Supervised QA with Generative Domain-Adaptive Nets [[arXiv](https://arxiv.org/abs/1702.02206)]þþ#### 2017-01þþ- Wasserstein GAN [[arXiv](https://arxiv.org/abs/1701.07875)]þ- Deep Reinforcement Learning: An Overview [[arXiv](https://arxiv.org/abs/1701.07274)]þ- DyNet: The Dynamic Neural Network Toolkit [[arXiv](https://arxiv.org/abs/1701.03980)]þ- DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker [[arXiv](https://arxiv.org/abs/1701.01724)]þ- NIPS 2016 Tutorial: Generative Adversarial Networks [[arXiv](https://arxiv.org/abs/1701.00160)]þþ#### 2016-12þþ- [A recurrent neural network without Chaos](notes/rnn_no_chaos.md) [[arXiv](https://arxiv.org/abs/1612.06212)]þ- Language Modeling with Gated Convolutional Networks [[arXiv](https://arxiv.org/abs/1612.08083)]þ- EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis [[arXiv](https://arxiv.org/abs/1612.07919)] [[article](http://webdav.tuebingen.mpg.de/pixel/enhancenet/)]þ- Learning from Simulated and Unsupervised Images through Adversarial Training [[arXiv](https://arxiv.org/abs/1612.07828)]þ- How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs [[arXiv](https://arxiv.org/abs/1612.04629)]þ- Improving Neural Language Models with a Continuous Cache [[arXiv](https://arxiv.org/abs/1612.04426)]þ- DeepMind Lab [[arXiv](https://arxiv.org/abs/1612.03801)] [[code](https://github.com/deepmind/lab)]þ- Deep Learning of Robotic Tasks without a Simulator using Strong and Weak Human Supervision [[arXiv](https://arxiv.org/abs/1612.01086)]þ- Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning [[arXiv](https://arxiv.org/abs/1612.01887)]þ- Overcoming catastrophic forgetting in neural networks [[arXiv](https://arxiv.org/abs/1612.00796)]þþ#### 2016-11 (ICLR Edition)þþ- Image-to-Image Translation with Conditional Adversarial Networks [[arXiv](https://arxiv.org/abs/1611.07004)]þ- [Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer](notes/mixture-experts.md) [[OpenReview](https://openreview.net/forum?id=B1ckMDqlg)]þ- Learning to reinforcement learn [[arXiv](https://arxiv.org/abs/1611.05763)]þ- A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs [[arXiv](https://arxiv.org/abs/1611.05104)]þ- [Adversarial Training Methods for Semi-Supervised Text Classification](notes/adversarial-text-classification.md) [[arXiv](https://arxiv.org/abs/1605.07725)]þ- Importance Sampling with Unequal Support [[arXiv](https://arxiv.org/abs/1611.03451)]þ- Quasi-Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1611.01576)]þ- Capacity and Learnability in Recurrent Neural Networks [[OpenReview](http://openreview.net/forum?id=BydARw9ex)]þ- Unrolled Generative Adversarial Networks [[OpenReview](http://openreview.net/forum?id=BydrOIcle)]þ- Deep Information Propagation [[OpenReview](http://openreview.net/forum?id=H1W1UN9gg)]þ- Structured Attention Networks [[OpenReview](http://openreview.net/forum?id=HkE0Nvqlg)]þ- Incremental Sequence Learning [[arXiv](https://arxiv.org/abs/1611.03068)]þ- Delving into Transferable Adversarial Examples and Black-box Attacks [[arXiv](https://arxiv.org/abs/1611.02770)] [[code](https://github.com/ReDeiPirati/transferability-advdnn-pub)]þ- b-GAN: Unified Framework of Generative Adversarial Networks [[OpenReview](http://openreview.net/forum?id=S1JG13oee)]þ- A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks [[OpenReview](http://openreview.net/forum?id=SJZAb5cel)]þ- Categorical Reparameterization with Gumbel-Softmax [[arXiv](https://arxiv.org/abs/1611.01144)]þ- Lip Reading Sentences in the Wild [[arXiv](https://arxiv.org/abs/1611.05358)]þþReinforcement Learning:þþ-Learning to reinforcement learn [[arXiv](https://arxiv.org/abs/1611.05763)]þ- A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models [[arXiv](https://arxiv.org/abs/1611.03852)]þ- The Predictron: End-To-End Learning and Planning [[OpenReview](http://openreview.net/forum?id=BkJsCIcgl)]þ- [Third-Person Imitation Learning](notes/third-person-imitation-learning.md) [[OpenReview](http://openreview.net/forum?id=B16dGcqlx)]þ- Generalizing Skills with Semi-Supervised Reinforcement Learning [[OpenReview](http://openreview.net/forum?id=ryHlUtqge)]þ- Sample Efficient Actor-Critic with Experience Replay [[OpenReview](http://openreview.net/forum?id=HyM25Mqel)]þ- [Reinforcement Learning with Unsupervised Auxiliary Tasks](notes/rl-auxiliary-tasks.md) [[arXiv](https://arxiv.org/abs/1611.05397)]þ- Neural Architecture Search with Reinforcement Learning [[OpenReview](http://openreview.net/forum?id=r1Ue8Hcxg)]þ- Towards Information-Seeking Agents [[OpenReview](http://openreview.net/forum?id=SyW2QSige)]þ- Multi-Agent Cooperation and the Emergence of (Natural) Language [[OpenReview](http://openreview.net/forum?id=Hk8N3Sclg)]þ- Improving Policy Gradient by Exploring Under-appreciated Rewards [[OpenReview](http://openreview.net/forum?id=ryT4pvqll)]þ- Stochastic Neural Networks for Hierarchical Reinforcement Learning [[OpenReview](http://openreview.net/forum?id=B1oK8aoxe)]þ- Tuning Recurrent Neural Networks with Reinforcement Learning [[OpenReview](https://arxiv.org/abs/1611.02796)]þ- RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning [[arXiv](https://arxiv.org/abs/1611.02779)]þ- Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning [[OpenReview](http://openreview.net/forum?id=Hyq4yhile)]þ- Learning to Perform Physics Experiments via Deep Reinforcement Learning [[OpenReview](http://openreview.net/forum?id=r1nTpv9eg)]þ- Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU [[OpenReview](http://openreview.net/forum?id=r1VGvBcxl)]þ- Learning to Compose Words into Sentences with Reinforcement Learning[[OpenReview](http://openreview.net/forum?id=Skvgqgqxe)]þ- Deep Reinforcement Learning for Accelerating the Convergence Rate [[OpenReview](http://openreview.net/forum?id=Syg_lYixe)]þ- [#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning](notes/count-based-exploration.md) [[arXiv](https://arxiv.org/abs/1611.04717)]þ- Learning to Compose Words into Sentences with Reinforcement Learning [[OpenReview](http://openreview.net/forum?id=Skvgqgqxe)]þ- Learning to Navigate in Complex Environments [[arXiv](https://arxiv.org/abs/1611.03673)]þ- Unsupervised Perceptual Rewards for Imitation Learning [[OpenReview](http://openreview.net/forum?id=Bkul3t9ee)]þ- Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic [[OpenReview](http://openreview.net/forum?id=SJ3rcZcxl)]þþþMachine Translation & Dialogþþ- [Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation](notes/gnmt-multilingual.md) [[arXiv](https://arxiv.org/abs/1611.04558)]þ- [Neural Machine Translation with Reconstruction](notes/nmt-with-reconstruction.md) [[arXiv](https://arxiv.org/abs/1611.01874v1)]þ- Iterative Refinement for Machine Translation [[OpenReview](http://openreview.net/forum?id=r1y1aawlg)]þ- A Convolutional Encoder Model for Neural Machine Translation [[arXiv](https://arxiv.org/abs/1611.02344)]þ- Improving Neural Language Models with a Continuous Cache [[OpenReview](http://openreview.net/forum?id=B184E5qee)]þ- Vocabulary Selection Strategies for Neural Machine Translation [[OpenReview](http://openreview.net/forum?id=Bk8N0RLxx)]þ- Towards an automatic Turing test: Learning to evaluate dialogue responses [[OpenReview](http://openreview.net/forum?id=HJ5PIaseg)]þ- Dialogue Learning With Human-in-the-Loop [[OpenReview](http://openreview.net/forum?id=HJgXCV9xx)]þ- Batch Policy Gradient Methods for Improving Neural Conversation Models [[OpenReview](http://openreview.net/forum?id=rJfMusFll)]þ- Learning through Dialogue Interactions [[OpenReview](http://openreview.net/forum?id=rkE8pVcle)]þ- [Dual Learning for Machine Translation](notes/dual-learning-mt.md) [[arXiv](https://arxiv.org/abs/1611.00179)]þ- Unsupervised Pretraining for Sequence to Sequence Learning [[arXiv](https://arxiv.org/abs/1611.02683)]þþþþ#### 2016-10þþ- Hybrid computing using a neural network with dynamic external memory [[nature](https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz)] [[code](https://github.com/deepmind/dnc)]þ- Quantum Machine Learning [[arXiv](https://arxiv.org/abs/1611.09347)]þ- Understanding deep learning requires rethinking generalization [[arXiv](https://arxiv.org/abs/1611.03530)]þ- Universal adversarial perturbations [[arXiv](https://arxiv.org/abs/1610.08401)] [[code](https://github.com/LTS4/universal)]þ- [Neural Machine Translation in Linear Time](notes/nmt-linear-time.md) [[arXiv](https://arxiv.org/abs/1610.10099)] [[code](https://github.com/tensorflow/tensor2tensor)]þ- [Professor Forcing: A New Algorithm for Training Recurrent Networks](notes/professor-forcing.md) [[arXiv](https://arxiv.org/abs/1610.09038)]þ- Learning to Protect Communications with Adversarial Neural Cryptography [[arXiv](https://arxiv.org/abs/1610.06918v1)]þ- Can Active Memory Replace Attention? [[arXiv](https://arxiv.org/abs/1610.08613)]þ- [Using Fast Weights to Attend to the Recent Past](notes/fast-weight-to-attend.md) [[arXiv](https://arxiv.org/abs/1610.06258)]þ- [Fully Character-Level Neural Machine Translation without Explicit Segmentation](notes/conv-char-level-nmt.md) [[arXiv](https://arxiv.org/abs/1610.03017)]þ- [Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models](notes/diverse-beam-search.md) [[arXiv](https://arxiv.org/abs/1610.02424)]þ- Video Pixel Networks [[arXiv](https://arxiv.org/abs/1610.00527)]þ- Connecting Generative Adversarial Networks and Actor-Critic Methods [[arXiv](https://arxiv.org/abs/1610.01945)]þ- [Learning to Translate in Real-time with Neural Machine Translation](notes/learning-to-translate-real-time.md) [[arXiv](https://arxiv.org/abs/1610.00388)]þ- Xception: Deep Learning with Depthwise Separable Convolutions [[arXiv](https://arxiv.org/abs/1610.02357)]þ- Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search [[arXiv](https://arxiv.org/abs/1610.00673)]þ- [Pointer Sentinel Mixture Models](notes/pointer-sentinel-mixture.md) [[arXiv](https://arxiv.org/abs/1609.07843)]þþ#### 2016-09þþ- Towards Deep Symbolic Reinforcement Learning [[arXiv](https://arxiv.org/abs/1609.05518)]þ- HyperNetworks [[arXiv](https://arxiv.org/abs/1609.09106)]þ- Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation [[arXiv](http://arxiv.org/abs/1609.08144)]þ- Safe and Efficient Off-Policy Reinforcement Learning [[arXiv](http://arxiv.org/abs/1606.02647)]þ- Playing FPS Games with Deep Reinforcement Learning [[arXiv](http://arxiv.org/abs/1609.05521)]þ- [SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient](notes/seq-gan.md) [[arXiv](https://arxiv.org/abs/1609.05473)]þ- Episodic Exploration for Deep Deterministic Policies: An Application to StarCraft Micromanagement Tasks [[arXiv](http://arxiv.org/abs/1609.02993)]þ- Energy-based Generative Adversarial Network [[arXiv](https://arxiv.org/abs/1609.03126)]þ- Stealing Machine Learning Models via Prediction APIs [[arXiv](http://arxiv.org/abs/1609.02943)]þ- Semi-Supervised Classification with Graph Convolutional Networks [[arXiv](http://arxiv.org/abs/1609.02907)]þ- WaveNet: A Generative Model For Raw Audio [[arXiv](https://arxiv.org/abs/1609.03499)]þ- [Hierarchical Multiscale Recurrent Neural Networks](notes/hm-rnn.md) [[arXiv](https://arxiv.org/abs/1609.01704)]þ- End-to-End Reinforcement Learning of Dialogue Agents for Information Access [[arXiv](https://arxiv.org/abs/1609.00777)]þ- Deep Neural Networks for YouTube Recommendations [[paper](https://research.google.com/pubs/pub45530.html)]þþ#### 2016-08þþ- Semantics derived automatically from language corpora contain human-like biases [[arXiv](https://arxiv.org/abs/1608.07187)]þ- Why does deep and cheap learning work so well? [[arXiv](https://arxiv.org/abs/1608.08225)]þ- Machine Comprehension Using Match-LSTM and Answer Pointer [[arXiv](https://arxiv.org/abs/1608.07905)]þ- Stacked Approximated Regression Machine: A Simple Deep Learning Approach [[arXiv](http://arxiv.org/abs/1608.04062)]þ- Decoupled Neural Interfaces using Synthetic Gradients [[arXiv](http://arxiv.org/abs/1608.05343)]þ- WikiReading: A Novel Large-scale Language Understanding Task over Wikipedia [[arXiv](https://arxiv.org/abs/1608.03542)]þ- Temporal Attention Model for Neural Machine Translation [[arXiv](http://arxiv.org/abs/1608.02927)]þ- Residual Networks of Residual Networks: Multilevel Residual Networks [[arXiv](http://arxiv.org/abs/1608.02908)]þ- [Learning Online Alignments with Continuous Rewards Policy Gradient](notes/online-alignments-pg.md) [[arXiv](https://arxiv.org/abs/1608.01281)]þþ#### 2016-07þþ- [An Actor-Critic Algorithm for Sequence Prediction](notes/actor-critic-sequence.md) [[arXiv](http://arxiv.org/abs/1607.07086)]þ- Cognitive Science in the era of Artificial Intelligence: A roadmap for reverse-engineering the infant language-learner [[arXiv](http://arxiv.org/abs/1607.08723v1)]þ- [Recurrent Neural Machine Translation](notes/recurrent-nmt.md) [[arXiv](http://arxiv.org/abs/1607.08725)]þ- MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition [[arXiv](http://arxiv.org/abs/1607.08221)]þ- [Layer Normalization](notes/layer-norm.md) [[arXiv](https://arxiv.org/abs/1607.06450)]þ- [Neural Machine Translation with Recurrent Attention Modeling](notes/nmt-rec-attention.md)  [[arXiv](https://arxiv.org/abs/1607.05108)]þ- Neural Semantic Encoders [[arXiv](https://arxiv.org/abs/1607.04315)]þ- [Attention-over-Attention Neural Networks for Reading Comprehension](notes/att-over-att.md) [[arXiv](https://arxiv.org/abs/1607.04423)]þ- sk_p: a neural program corrector for MOOCs [[arXiv](http://arxiv.org/abs/1607.02902)]þ- Recurrent Highway Networks [[arXiv](https://arxiv.org/abs/1607.03474)]þ- Bag of Tricks for Efficient Text Classification [[arXiv](http://arxiv.org/abs/1607.01759)]þ- Context-Dependent Word Representation for Neural Machine Translation [[arXiv](https://arxiv.org/abs/1607.00578)]þ- Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes [[arXiv](http://arxiv.org/abs/1607.00036)]þþ#### 2016-06þþ- Sequence-to-Sequence Learning as Beam-Search Optimization [[arXiv](https://arxiv.org/abs/1606.02960)]þ- [Sequence-Level Knowledge Distillation](notes/seq-knowledge-distillation.md) [[arXiv](https://arxiv.org/abs/1606.07947)]þ- Policy Networks with Two-Stage Training for Dialogue Systems [[arXiv](http://arxiv.org/abs/1606.03152)]þ- Towards an integration of deep learning and neuroscience [[arXiv](https://arxiv.org/abs/1606.03813)]þ- On Multiplicative Integration with Recurrent Neural Networks [[arxiv](https://arxiv.org/abs/1606.06630)]þ- [Wide & Deep Learning for Recommender Systems](wide-and-deep.md) [[arXiv](https://arxiv.org/abs/1606.07792)]þ- Online and Offline Handwritten Chinese Character Recognition [[arXiv](https://arxiv.org/abs/1606.05763)]þ- Tutorial on Variational Autoencoders [[arXiv](http://arxiv.org/abs/1606.05908)]þ- Concrete Problems in AI Safety [[arXiv](https://arxiv.org/abs/1606.06565)]þ- Deep Reinforcement Learning Discovers Internal Models [[arXiv](http://arxiv.org/abs/1606.05174v1)]þ- [SQuAD: 100,000+ Questions for Machine Comprehension of Text](notes/squad.md) [[arXiv](http://arxiv.org/abs/1606.05250)]þ- Conditional Image Generation with PixelCNN Decoders [[arXiv](http://arxiv.org/abs/1606.05328)]þ- Model-Free Episodic Control [[arXiv](http://arxiv.org/abs/1606.04460)]þ- [Progressive Neural Networks](notes/progressive-nn.md) [[arXiv](http://arxiv.org/abs/1606.04671)]þ- Improved Techniques for Training GANs [[arXiv](http://arxiv.org/abs/1606.03498)] [[code](https://github.com/openai/improved-gan)]þ- Memory-Efficient Backpropagation Through Time [[arXiv](http://arxiv.org/abs/1606.03401)]þ- InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [[arXiv](http://arxiv.org/abs/1606.03657)]þ- Zero-Resource Translation with Multi-Lingual Neural Machine Translation [[arXiv](http://arxiv.org/abs/1606.04164)]þ- Key-Value Memory Networks for Directly Reading Documents [[arXiv](http://arxiv.org/abs/1606.03126)]þ- Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translatin [[arXiv](http://arxiv.org/abs/1606.04199)]þ- Learning to learn by gradient descent by gradient descent [[arXiv](http://arxiv.org/abs/1606.04474)]þ- Learning Language Games through Interaction [[arXiv](http://arxiv.org/abs/1606.02447)]þ- Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations [[arXiv](https://arxiv.org/abs/1606.01305)]þ- Smart Reply: Automated Response Suggestion for Email [[arXiv](http://arxiv.org/abs/1606.04870)]þ- Virtual Adversarial Training for Semi-Supervised Text Classification [[arXiv](https://arxiv.org/abs/1605.07725)]þ- Deep Reinforcement Learning for Dialogue Generation [[arXiv](http://arxiv.org/abs/1606.01541)]þ- Very Deep Convolutional Networks for Natural Language Processing [[arXiv](https://arxiv.org/abs/1606.01781)]þ- Neural Net Models for Open-Domain Discourse Coherence [[arXiv](https://arxiv.org/abs/1606.01545)]þ- Neural Architectures for Fine-grained Entity Type Classification [[arXiv](https://arxiv.org/abs/1606.01341)]þ- Matching Networks for One Shot Learning [[arXiv](https://arxiv.org/abs/1606.04080)]þ- Cooperative Inverse Reinforcement Learning [[arXiv](https://arxiv.org/abs/1606.03137)] [[article](http://bair.berkeley.edu/blog/2017/08/17/cooperatively-learning-human-values/)]þ- Gated-Attention Readers for Text Comprehension [[arXiv](http://arxiv.org/abs/1606.01549)]þ- [End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning](notes/e2e-dialog-control-sl-rl.md) [[arXiv](https://arxiv.org/abs/1606.01269)]þ- Iterative Alternating Neural Attention for Machine Reading [[arXiv](https://arxiv.org/abs/1606.02245)]þ- Memory-enhanced Decoder for Neural Machine Translation [[arXiv](http://arxiv.org/abs/1606.02003)]þ- Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation [[arXiv](https://arxiv.org/abs/1606.00776)]þ- Learning to Optimize [[arXiv](https://arxiv.org/abs/1606.01885)] [[article](http://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/)]þ- [Natural Language Comprehension with the EpiReader](notes/epireader.md) [[arXiv](https://arxiv.org/abs/1606.02270)]þ- Conversational Contextual Cues: The Case of Personalization and History for Response Ranking [[arXiv](https://arxiv.org/abs/1606.00372)]þ- Adversarially Learned Inference [[arXiv](https://arxiv.org/abs/1606.00704)]þ- OpenAI Gym [[arXiv](https://arxiv.org/abs/1606.01540)] [[code](https://github.com/deepmind/lab)]þ- Neural Network Translation Models for Grammatical Error Correction [[arXiv](https://arxiv.org/abs/1606.00189)]þþ#### 2016-05þþ- Hierarchical Memory Networks [[arXiv](https://arxiv.org/abs/1605.07427)]þ- Deep API Learning [[arXiv](http://arxiv.org/abs/1605.08535)]þ- Wide Residual Networks [[arXiv](http://arxiv.org/abs/1605.07146)]þ- TensorFlow: A system for large-scale machine learning [[arXiv](http://arxiv.org/abs/1605.08695)]þ- Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention [[arXiv](http://arxiv.org/abs/1605.09090)]þ- Aspect Level Sentiment Classification with Deep Memory Network [[arXiv](http://arxiv.org/abs/1605.08900)]þ- FractalNet: Ultra-Deep Neural Networks without Residuals [[arXiv](https://arxiv.org/abs/1605.07648)]þ- Learning End-to-End Goal-Oriented Dialog [[arXiv](http://arxiv.org/abs/1605.07683)]þ- One-shot Learning with Memory-Augmented Neural Networks [[arXiv](http://arxiv.org/abs/1605.06065)]þ- Deep Learning without Poor Local Minima [[arXiv](http://arxiv.org/abs/1605.07110)]þ- AVEC 2016 - Depression, Mood, and Emotion Recognition Workshop and Challenge [[arXiv](https://arxiv.org/abs/1605.01600)]þ- Data Programming: Creating Large Training Sets, Quickly [[arXiv](http://arxiv.org/abs/1605.07723)]þ- Deeply-Fused Nets [[arXiv](http://arxiv.org/abs/1605.07716)]þ- Deep Portfolio Theory [[arXiv](http://arxiv.org/abs/1605.07230)]þ- Unsupervised Learning for Physical Interaction through Video Prediction [[arXiv](http://arxiv.org/abs/1605.07157)]þ- Movie Description [[arXiv](http://arxiv.org/abs/1605.03705)]þþþ#### 2016-04þþ- Higher Order Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1605.00064)]þ- Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition [[arXiv](https://arxiv.org/abs/1604.08352)]þ- Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation [[arXiv](https://arxiv.org/abs/1604.06057)]þ- The IBM 2016 English Conversational Telephone Speech Recognition System [[arXiv](https://arxiv.org/abs/1604.08242)]þ- Dialog-based Language Learning [[arXiv](https://arxiv.org/abs/1604.06045)]þ- Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss [[arXiv](https://arxiv.org/abs/1604.05529)]þ- Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction [[arXiv](https://arxiv.org/abs/1604.04677)]þ- A Network-based End-to-End Trainable Task-oriented Dialogue System [[arXiv](http://arxiv.org/abs/1604.04562)]þ- Visual Storytelling [[arXiv](https://arxiv.org/abs/1604.03968)]þ- Improving the Robustness of Deep Neural Networks via Stability Training [[arXiv](http://arxiv.org/abs/1604.04326)]þ- [Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex](notes/bridging-gap-resnet-rnn.md) [[arXiv](https://arxiv.org/abs/1604.03640)]þ- Scan, Attend and Read: End-to-End Handwritten Paragraph Recognition with MDLSTM Attention [[arXiv](https://arxiv.org/abs/1604.03286)]þ- [Sentence Level Recurrent Topic Model: Letting Topics Speak for Themselves](notes/slrtm.md) [[arXiv](https://arxiv.org/abs/1604.02038)]þ- [Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models](notes/open-vocab-nmt-hybrid-word-character.md) [[arXiv](http://arxiv.org/abs/1604.00788)]þ- [Building Machines That Learn and Think Like People](notes/building-machines-that-learn-and-think-like-people.md) [[arXiv](http://arxiv.org/abs/1604.00289)]þ- A Semisupervised Approach for Language Identification based on Ladder Networks [[arXiv](http://arxiv.org/abs/1604.00317)]þ- [Deep Networks with Stochastic Depth](notes/stochastic-depth.md) [[arXiv](http://arxiv.org/abs/1603.09382)]þ- PHOCNet: A Deep Convolutional Neural Network for Word Spotting in Handwritten Documents [[arXiv](http://arxiv.org/abs/1604.00187)]þþþ#### 2016-03þþ- Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning [[arXiv](https://arxiv.org/abs/1603.07954)]þ- A Fast Unified Model for Parsing and Sentence Understanding [[arXiv](http://arxiv.org/abs/1603.06021)]þ- [Latent Predictor Networks for Code Generation](notes/latent-predictor-networks.md) [[arXiv](http://arxiv.org/abs/1603.06744)]þ- Attend, Infer, Repeat: Fast Scene Understanding with Generative Models [[arXiv](http://arxiv.org/abs/1603.08575)]þ- Recurrent Batch Normalization [[arXiv](http://arxiv.org/abs/1603.09025)]þ- Neural Language Correction with Character-Based Attention [[arXiv](http://arxiv.org/abs/1603.09727)]þ- [Incorporating Copying Mechanism in Sequence-to-Sequence Learning](notes/copynet.md) [[arXiv](http://arxiv.org/abs/1603.06393)]þ- How NOT To Evaluate Your Dialogue System [[arXiv](http://arxiv.org/abs/1603.08023)]þ- [Adaptive Computation Time for Recurrent Neural Networks](notes/act-rnn.md) [[arXiv](http://arxiv.org/abs/1603.08983)]þ- A guide to convolution arithmetic for deep learning [[arXiv](http://arxiv.org/abs/1603.07285)]þ- Colorful Image Colorization [[arXiv](http://arxiv.org/abs/1603.08983)]þ- Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles [[arXiv](http://arxiv.org/abs/1603.09246)]þ- Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus [[arXiv](http://arxiv.org/abs/1603.06807)]þ- A Persona-Based Neural Conversation Model [[arXiv](http://arxiv.org/abs/1603.06155)]þ- [A Character-level Decoder without Explicit Segmentation for Neural Machine Translation](notes/char-level-decoder.md) [[arXiv](http://arxiv.org/abs/1603.06147)]þ- Multi-Task Cross-Lingual Sequence Tagging from Scratch [[arXiv](http://arxiv.org/abs/1603.06270)]þ- Neural Variational Inference for Text Processing [[arXiv](http://arxiv.org/abs/1511.06038)]þ- Recurrent Dropout without Memory Loss [[arXiv](http://arxiv.org/abs/1603.05118)]þ- One-Shot Generalization in Deep Generative Models [[arXiv](http://arxiv.org/abs/1603.05106)]þ- Recursive Recurrent Nets with Attention Modeling for OCR in the Wild [[arXiv](Recursive Recurrent Nets with Attention Modeling for OCR in the Wild)]þ- A New Method to Visualize Deep Neural Networks [[arXiv](A New Method to Visualize Deep Neural Networks)]þ- Neural Architectures for Named Entity Recognition [[arXiv](http://arxiv.org/abs/1603.01360)]þ- End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF [[arXiv](http://arxiv.org/abs/1603.01354)]þ- Character-based Neural Machine Translation [[arXiv](http://arxiv.org/abs/1603.00810)]þ- Learning Word Segmentation Representations to Improve Named Entity Recognition for Chinese Social Media [[arXiv](http://arxiv.org/abs/1603.00786)]þþ#### 2016-02þþ- Architectural Complexity Measures of Recurrent Neural Networks [[arXiv](http://arxiv.org/abs/1602.08210)]þ- Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks [[arXiv](http://arxiv.org/abs/1602.07868)]þ- Recurrent Neural Network Grammars [[arXiv](http://arxiv.org/abs/1602.07776)]þ- Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations [[arXiv](http://arxiv.org/abs/1602.07332)]þ- [Contextual LSTM (CLSTM) models for Large scale NLP tasks](notes/clstm-large-scale.md) [[arXiv](http://arxiv.org/abs/1602.06291)]þ- Sequence-to-Sequence RNNs for Text Summarization [[arXiv](http://arxiv.org/abs/1602.06023)]þ- Extraction of Salient Sentences from Labelled Documents [[arXiv](http://arxiv.org/abs/1412.6815)]þ- Learning Distributed Representations of Sentences from Unlabelled Data [[arXiv](http://arxiv.org/abs/1602.03483)]þ- Benefits of depth in neural networks [[arXiv](http://arxiv.org/abs/1602.04485)]þ- [Associative Long Short-Term Memory](notes/associative-lstm.md) [[arXiv](http://arxiv.org/abs/1602.03032)]þ- Why Should I Trust You?"": Explaining the Predictions of Any Classifier [[arXiv](https://arxiv.org/abs/1602.04938)] [[code](https://github.com/marcotcr/lime)]þ- Generating images with recurrent adversarial networks [[arXiv](http://arxiv.org/abs/1602.05110)]þ- [Exploring the Limits of Language Modeling](notes/exploring-the-limits-of-lm.md) [[arXiv](http://arxiv.org/abs/1602.02410)]þ- Swivel: Improving Embeddings by Noticing What’s Missing [[arXiv](http://arxiv.org/abs/1602.02215)]þ- [WebNav: A New Large-Scale Task for Natural Language based Sequential Decision Making](notes/webnav.md) [[arXiv](http://arxiv.org/abs/1602.02261)]þ- [Efficient Character-level Document Classification by Combining Convolution and Recurrent Layers](notes/efficient-char-level-document-classification-cnn-rnn.md) [[arXiv](http://arxiv.org/abs/1602.00367)]þ- Gradient Descent Converges to Minimizers [[arXiv](https://arxiv.org/abs/1602.04915)] [[article](http://www.offconvex.org/2016/03/24/saddles-again/)]þ- BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1 [[arXiv](http://arxiv.org/abs/1602.02830)]þ- Learning Discriminative Features via Label Consistent Neural Network [[arXiv](http://arxiv.org/abs/1602.01168)]þþ#### 2016-01þþ- What’s your ML test score? A rubric for ML production systems [[Research at Google](https://research.google.com/pubs/pub45742.html)]þ- Pixel Recurrent Neural Networks [[arXiv](http://arxiv.org/abs/1601.06759)]þ- Bitwise Neural Networks [[arXiv](http://arxiv.org/abs/1601.06071)]þ- Long Short-Term Memory-Networks for Machine Reading [[arXiv](http://arxiv.org/abs/1601.06733)]þ- Coverage-based Neural Machine Translation [[arXiv](http://arxiv.org/abs/1601.04811)]þ- Understanding Deep Convolutional Networks [[arXiv](http://arxiv.org/abs/1601.04920)]þ- Training Recurrent Neural Networks by Diffusion [[arXiv](http://arxiv.org/abs/1601.04114)]þ- Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures [[arXiv](http://arxiv.org/abs/1601.03896)]þ- [Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism](notes/multi-way-nmt-shared-attention.md) [[arXiv](http://arxiv.org/abs/1601.01073)]þ- [Recurrent Memory Network for Language Modeling](notes/rmn-language-modeling.md) [[arXiv](http://arxiv.org/abs/1601.01272)]þ- Language to Logical Form with Neural Attention [[arXiv](http://arxiv.org/abs/1601.01280)]þ- Learning to Compose Neural Networks for Question Answering [[arXiv](http://arxiv.org/abs/1601.01705)]þ- The Inevitability of Probability: Probabilistic Inference in Generic Neural Networks Trained with Non-Probabilistic Feedback [[arXiv](http://arxiv.org/abs/1601.03060)]þ- COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images [[arXiv](http://arxiv.org/abs/1601.07140)]þ- Survey on the attention based RNN model and its applications in computer vision [[arXiv](http://arxiv.org/abs/1601.06823)]þþ#### 2015-12þþNLPþþ- [Strategies for Training Large Vocabulary Neural Language Models](notes/strategies-for-training-large-vocab-lm.md) [[arXiv](http://arxiv.org/abs/1512.04906)]þ- [Multilingual Language Processing From Bytes](notes/multilingual-language-processing-from-bytes.md) [[arXiv](http://arxiv.org/abs/1512.00103)]þ- [Learning Document Embeddings by Predicting N-grams for Sentiment Classification of Long Movie Reviews](notes/learning-document-embeddings-ngrams.md) [[arXiv](http://arxiv.org/abs/1512.08183)]þ- [Target-Dependent Sentiment Classification with Long Short Term Memory](notes/target-dependent-sentiment-lstm.md) [[arXiv](http://arxiv.org/abs/1512.01100)]þ- Reading Text in the Wild with Convolutional Neural Networks [[arXiv](http://arxiv.org/abs/1412.1842)]þþVisionþþ- [Deep Residual Learning for Image Recognition](notes/deep-residual-learning.md) [[arXiv](http://arxiv.org/abs/1512.03385)]þ- Rethinking the Inception Architecture for Computer Vision [[arXiv](http://arxiv.org/abs/1512.00567)]þ- Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks [[arXiv](http://arxiv.org/abs/1512.04143)]þ- Deep Speech 2: End-to-End Speech Recognition in English and Mandarin [[arXiv](http://arxiv.org/abs/1512.02595)]þþþ#### 2015-11þþNLPþþ- [Deep Reinforcement Learning with a Natural Language Action Space](notes/drl-nlp-action.md) [[arXiv](https://arxiv.org/abs/1511.04636)]þ- Sequence Level Training with Recurrent Neural Networks [[arXiv](http://arxiv.org/abs/1511.06732)]þ- [Teaching Machines to Read and Comprehend](notes/teaching-machines-to-read-and-comprehend.md) [[arxiv](http://arxiv.org/abs/1506.03340)]þ- [Semi-supervised Sequence Learning](notes/semi-supervised-sequence-learning.md) [[arXiv](http://arxiv.org/abs/1511.01432)]þ- [Multi-task Sequence to Sequence Learning](notes/multitask-seq2seq.md) [[arXiv](http://arxiv.org/abs/1511.06114)]þ- [Alternative structures for character-level RNNs](notes/alternative-structure-char-rnn.md) [[arXiv](http://arxiv.org/abs/1511.06303)]þ- [Larger-Context Language Modeling](notes/larger-context-lm.md) [[arXiv](http://arxiv.org/abs/1511.03729)]þ- [A Unified Tagging Solution: Bidirectional LSTM Recurrent Neural Network with Word Embedding](notes/unified-tagging-blstm.md) [[arXiv](http://arxiv.org/abs/1511.00215)]þ- Towards Universal Paraphrastic Sentence Embeddings [[arXiv](http://arxiv.org/abs/1511.08198)]þ- BlackOut: Speeding up Recurrent Neural Network Language Models With Very Large Vocabularies [[arXiv](http://arxiv.org/abs/1511.06909)]þ- Sequence Level Training with Recurrent Neural Networks [[arXiv](http://arxiv.org/abs/1511.06732)]þ- Natural Language Understanding with Distributed Representation [[arXiv](http://arxiv.org/abs/1511.07916)]þ- sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings [[arXiv](http://arxiv.org/abs/1511.06388)]þ- LSTM-based Deep Learning Models for non-factoid answer selection [[arXiv](http://arxiv.org/abs/1511.04108)]þþProgramsþþ- Neural Random-Access Machines [[arxiv](http://arxiv.org/abs/1511.06392)]þ- Neural Programmer: Inducing Latent Programs with Gradient Descent [[arXiv](http://arxiv.org/abs/1511.04834)]þ- Neural Programmer-Interpreters [[arXiv](http://arxiv.org/abs/1511.06279)]þ- Learning Simple Algorithms from Examples [[arXiv](http://arxiv.org/abs/1511.07275)]þ- Neural GPUs Learn Algorithms [[arXiv](http://arxiv.org/abs/1511.08228)] [[code](https://github.com/tensorflow/tensor2tensor)]þ- On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models [[arXiv](http://arxiv.org/abs/1511.09249)]þþVisionþþ- ReSeg: A Recurrent Neural Network for Object Segmentation [[arXiv](http://arxiv.org/abs/1511.07053)]þ- Deconstructing the Ladder Network Architecture [[arXiv](http://arxiv.org/abs/1511.06430)]þ- Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks [[arXiv](http://arxiv.org/abs/1511.06434)]þ- Multi-Scale Context Aggregation by Dilated Convolutions [[arXiv](https://arxiv.org/abs/1511.07122)] [[code](https://github.com/fyu/drn)]þþGeneralþþ- Towards Principled Unsupervised Learning [[arXiv](http://arxiv.org/abs/1511.06440)]þ- Dynamic Capacity Networks [[arXiv](http://arxiv.org/abs/1511.07838)]þ- [Generating Sentences from a `ous Space](notes/generating-sentences-cont-space.md) [[arXiv](http://arxiv.org/abs/1511.06349)]þ- Net2Net: Accelerating Learning via Knowledge Transfer [[arXiv](http://arxiv.org/abs/1511.05641)]þ- A Roadmap towards Machine Intelligence [[arXiv](http://arxiv.org/abs/1511.08130)]þ- Session-based Recommendations with Recurrent Neural Networks [[arXiv](http://arxiv.org/abs/1511.06939)]þ- Regularizing RNNs by Stabilizing Activations [[arXiv](http://arxiv.org/abs/1511.08400)]þþþ#### 2015-10þþ- [A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification](notes/sensitivity-analysis-cnn-sentence-classification.md) [[arXiv](http://arxiv.org/abs/1510.03820)]þ- [Attention with Intention for a Neural Network Conversation Model](notes/attention-with-intention.md) [[arXiv](http://arxiv.org/abs/1510.08565)]þ- Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Recurrent Neural Network [[arXiv](http://arxiv.org/abs/1510.06168)]þ- A Survey: Time Travel in Deep Learning Space: An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas [[arXiv](http://arxiv.org/abs/1510.04781)]þ- A Primer on Neural Network Models for Natural Language Processing [[arXiv](http://arxiv.org/abs/1510.00726)]þ- [A Diversity-Promoting Objective Function for Neural Conversation Models](notes/diversity-promoting-objective-ncm.md) [[arXiv](http://arxiv.org/abs/1510.03055)]þþþ#### 2015-09þþ- [Character-level Convolutional Networks for Text Classification](notes/character-level-cnn-for-text-classification.md) [[arXiv](http://arxiv.org/abs/1509.01626)]þ- [A Neural Attention Model for Abstractive Sentence Summarization](notes/neural-attention-model-for-abstractive-sentence-summarization.md) [[arXiv](http://arxiv.org/abs/1509.00685)]þ- Poker-CNN: A Pattern Learning Strategy for Making Draws and Bets in Poker Games [[arXiv](http://arxiv.org/abs/1509.06731)]þþ#### 2015-08þþ- [Neural Machine Translation of Rare Words with Subword Units](notes/nmt-subword.md) [[arXiv](https://arxiv.org/abs/1508.07909)] [[code](https://github.com/rsennrich/subword-nmt)]þ- Listen, Attend and Spell [[arxiv](http://arxiv.org/abs/1508.01211)]þ- [Character-Aware Neural Language Models](notes/character-aware-nlm.md) [[arXiv](http://arxiv.org/abs/1508.06615)]þ- Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs [[arXiv](http://arxiv.org/abs/1508.00657)]þ- Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation [[arXiv](http://arxiv.org/abs/1508.02096)]þ- [Effective Approaches to Attention-based Neural Machine Translation](notes/effective-approaches-nmt-attention.md) [[arXiv](https://arxiv.org/abs/1508.04025)]þþ#### 2015-07þþ- [Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models](e2e-dialog-ghnnm.md) [[arXiv](http://arxiv.org/abs/1507.04808)]þ- Semi-Supervised Learning with Ladder Networks [[arXiv](http://arxiv.org/abs/1507.02672)]þ- [Document Embedding with Paragraph Vectors](notes/document-embedding-with-pv.md) [[arXiv](http://arxiv.org/abs/1507.07998)]þ- [Training Very Deep Networks](notes/training-very-deep-networks.md) [[arXiv](http://arxiv.org/abs/1507.06228)]þþ#### 2015-06þþ- Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning [[arXiv](https://arxiv.org/abs/1506.02142)]þ- [A Neural Network Approach to Context-Sensitive Generation of Conversational Responses](notes/nn-context-sentitive-responses.md) [[arXiv](http://arxiv.org/abs/1506.06714)]þ- [Document Embedding with Paragraph Vectors](notes/document-embedding-with-pv.md) [[arXiv](http://arxiv.org/abs/1507.07998)]þ- [A Neural Conversational Model](notes/neural-conversational-model.md) [[arXiv](http://arxiv.org/abs/1506.05869)]þ- [Skip-Thought Vectors](notes/skip-thought-vectors.md) [[arXiv](http://arxiv.org/abs/1506.06726)]þ- [Pointer Networks](notes/pointer-networks.md) [[arXiv](http://arxiv.org/abs/1506.03134)]þ- [Spatial Transformer Networks](notes/spatial-transformer-networks.md) [[arXiv](http://arxiv.org/abs/1506.02025)]þ- Tree-structured composition in neural networks without tree-structured architectures [[arXiv](http://arxiv.org/abs/1506.04834)]þ- Visualizing and Understanding Neural Models in NLP [[arXiv](http://arxiv.org/abs/1506.01066)]þ- Learning to Transduce with Unbounded Memory [[arXiv](http://arxiv.org/abs/1506.02516)]þ- Ask Me Anything: Dynamic Memory Networks for Natural Language Processing [[arXiv](http://arxiv.org/abs/1506.07285)]þ- [Deep Knowledge Tracing](notes/deep-knowledge-tracing.md) [[arXiv](http://arxiv.org/abs/1506.05908)]þþ#### 2015-05þþ- [ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks](notes/renet-rnn-alternative-to-convnet.md) [[arXiv](http://arxiv.org/abs/1505.00393)]þ- Reinforcement Learning Neural Turing Machines [[arXiv](http://arxiv.org/abs/1505.00521)]þþ#### 2015-04þþ- Correlational Neural Networks [[arXiv](http://arxiv.org/abs/1504.07225)]þþ#### 2015-03þþþ- [Distilling the Knowledge in a Neural Network](notes/distilling-the-knowledge-in-a-nn.md) [[arXiv](http://arxiv.org/abs/1503.02531)]þ- [End-To-End Memory Networks](notes/end-to-end-memory-networks.md) [[arXiv](http://arxiv.org/abs/1503.08895)]þ- [Neural Responding Machine for Short-Text Conversation](notes/neural-responding-machine.md) [[arXiv](http://arxiv.org/abs/1503.02364)]þ- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](notes/batch-normalization.md) [[arXiv](http://arxiv.org/abs/1502.03167)]þ- Escaping From Saddle Points --- Online Stochastic Gradient for Tensor Decomposition [[arXiv](https://arxiv.org/abs/1503.02101)] [[article](Escaping from Saddle Points)]þþþ#### 2015-02þþ- Human-level control through deep reinforcementþlearning [[Nature](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)] [[code](https://github.com/deepmind/dqn)]þ- [Text Understanding from Scratch](notes/text-understanding-from-scratch.md) [[arXiv](http://arxiv.org/abs/1502.01710)]þ- [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](notes/show-attend-tell.md) [[arXiv](http://arxiv.org/abs/1502.03044)]þþ#### 2015-01þþ- Hidden Technical Debt in Machine Learning Systems [[NIPS](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)]þþ#### 2014-12þþ- Learning Longer Memory in Recurrent Neural Networks [[arXiv](http://arxiv.org/abs/1412.7753)]þ- [Neural Turing Machines](notes/neural-turing-machines.md) [[arxiv](http://arxiv.org/abs/1410.5401)]þ- [Grammar as a Foreign Langauage](notes/grammar-as-a-foreign-language.md) [[arXiv](http://arxiv.org/abs/1412.7449)]þ- [On Using Very Large Target Vocabulary for Neural Machine Translation](notes/on-using-very-large-target-vocabulary-for-nmt.md) [[arXiv](http://arxiv.org/abs/1412.2007)]þ- Effective Use of Word Order for Text Categorization with Convolutional Neural Networks [[arXiv](http://arxiv.org/abs/1412.1058v1)]þ- Multiple Object Recognition with Visual Attention [[arXiv](http://arxiv.org/abs/1412.7755)]þþ#### 2014-11þþ- The Loss Surfaces of Multilayer Networks [[arXiv](https://arxiv.org/abs/1412.0233)]þþ#### 2014-10þþ- [Learning to Execute](notes/learning-to-execute.md) [[arXiv](http://arxiv.org/abs/1410.4615)]þþ#### 2014-09þþ- [Sequence to Sequence Learning with Neural Networks](notes/seq2seq-with-neural-networks.md) [[arXiv](http://arxiv.org/abs/1409.3215)]þ- [Neural Machine Translation by Jointly Learning to Align and Translate](notes/nmt-jointly-learning-to-align-and-translate.md) [[arxiv](http://arxiv.org/abs/1409.0473)]þ- [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](notes/properties-of-neural-mt.md) [[arXiv](http://arxiv.org/abs/1409.1259)]þ- [Recurrent Neural Network Regularization](notes/rnn-regularization.md) [[arXiv](http://arxiv.org/abs/1409.2329)]þ- Very Deep Convolutional Networks for Large-Scale Image Recognition [[arXiv](http://arxiv.org/abs/1409.1556)]þ- Going Deeper with Convolutions [[arXiv](http://arxiv.org/abs/1409.4842)]þþ#### 2014-08þþ- Convolutional Neural Networks for Sentence Classification [[arxiv](http://arxiv.org/abs/1408.5882)]þþ#### 2014-07þþ#### 2014-06þþ- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](notes/learning-phrase-representations.md) [[arXiv](http://arxiv.org/abs/1406.1078)]þ- [Recurrent Models of Visual Attention](notes/recurrent-models-of-visual-attention.md) [[arXiv](http://arxiv.org/abs/1406.6247)]þ- Generative Adversarial Networks [[arXiv](http://arxiv.org/abs/1406.2661)]þþ#### 2014-05þþ- [Distributed Representations of Sentences and Documents](notes/distributed-representations-of-sentences-and-documents.md) [[arXiv](http://arxiv.org/abs/1405.4053)]þþ#### 2014-04þþ- A Convolutional Neural Network for Modelling Sentences [[arXiv](http://arxiv.org/abs/1404.2188)]þþ#### 2014-03þþ#### 2014-02þþ#### 2014-01þþ- Machine Learning: The High Interest Credit Card of Technical Debt [[Research at Google](https://research.google.com/pubs/pub43146.html)]þþ#### 2013þþ- Visualizing and Understanding Convolutional Networks [[arXiv](http://arxiv.org/abs/1311.2901)]þ- DeViSE: A Deep Visual-Semantic Embedding Model [[pub](http://research.google.com/pubs/pub41473.html)]þ- Maxout Networks [[arXiv](http://arxiv.org/abs/1302.4389)]þ- Exploiting Similarities among Languages for Machine Translation [[arXiv](http://arxiv.org/abs/1309.4168)]þ- Efficient Estimation of Word Representations in Vector Space [[arXiv](http://arxiv.org/abs/1301.3781)]þþþ#### 2011þþ- Natural Language Processing (almost) from Scratch [[arXiv](http://arxiv.org/abs/1103.0398)]",
lguipeng/Notes,,False,False,False,16442,244,1426,87,530,0,0,0,0,"[1286, 1618, 1661, 1679, 1758, 1763, 1777, 1778]",User,Material Design Notes App,"{'': 6, 'iml': 6, 'md': 1, 'apk': 1, 'gradle': 6, 'jar': 2, 'pro': 1, 'java': 131, 'xml': 61, 'png': 23, 'jpg': 1, 'properties': 2, 'bat': 1, 'ttf': 2}",,,Java,81,1,2,2,0,1865,True,6,18,0,0,0,1,0,0,7,0,0,0,,,183,"#Screenshotþ<img src=""./screenshot/screenshot_1.png"" width=""30%"" height=""30%"">þ<img src=""./screenshot/screenshot_2.png"" width=""30%"" height=""30%"">þ<img src=""./screenshot/screenshot_3.png"" width=""30%"" height=""30%"">þþ<img src=""./screenshot/screenshot_4.png"" width=""30%"" height=""30%"">þ<img src=""./screenshot/screenshot_5.png"" width=""30%"" height=""30%"">þ<img src=""./screenshot/screenshot_6.png"" width=""30%"" height=""30%"">þþ**应用地址:** [APK](http://fir.im/h9wj)þþþ#Develop Environmentþ- Android Studio 1.4 Beta 2þ- JDK 1.8þ- Android Buid Tool 23þ- Android Compile Sdk 22þþ#2.0.0þ- MVPþ- Dagger2.0þ- RxAndroidþ- 修复bugþþ#1.2.0þ- 将同步的方式改为绑定印象笔记þ- 增加备份到本地的功能þ- 对APP进行瘦身，安装包仅为1.57Mþ- 修改分享页面从底部弹出þ- 修复Snackbar弹出时会挡住FloatButton的问题þ- 修复一些bugþþ#1.1.2þ- 增加了多款彩色主题的选择þ- 增加了关于界面的分享功能þ- 修复了笔记过长的显示问题þ- 修复了SwipeRefreshLayout和RecyclerView的组合问题þ- 优化界面的一些细节，修复已知的小bugþþ#1.1.0þ- 增加了笔记列表的卡片式的布局，可在设置里面切换þ- 增加了下拉同步笔记的组件þ- 增加编辑笔记时点击返回询问是否保存þ- 使用了Snackbar代替了Toast的提示þ- 去除了编辑笔记内容的下划线þ- 修改了笔记列表的显示时间方式þ- 修复了小米2s 5.0上CardView的显示问题þþ#1.0.2þ- Material Design风格，采用抽屉式菜单，悬浮滑动按钮，点击控件时的水波纹效果，状态栏透明使得与应用融为一体，用户即使在Android L系统以下的手机也能感受到良好的用户体验þ- 用文字记录身边随时发生的事情，或者你的待办事项þ- 同步，同步需要你在手机设置里面添加一个邮箱，并作为你的同步账号，提交到服务器þþ#关于我þ- Email: lgpszu@163.comþþ#Licenseþ```þCopyright 2015 LiaoguipengþþLicensed under the Apache License, Version 2.0 (the ""License"");þyou may not use this file except in compliance with the License.þYou may obtain a copy of the License atþþ    http://www.apache.org/licenses/LICENSE-2.0þþUnless required by applicable law or agreed to in writing, softwareþdistributed under the License is distributed on an ""AS IS"" BASIS,þWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.þSee the License for the specific language governing permissions andþlimitations under the License.þ```",
stanfordnlp/cs224n-winter17-notes,,False,False,False,11659,117,1496,131,443,0,0,0,0,"[1205, 1216, 1217, 1220, 1221, 1224, 1230]",Organization,Course notes for CS224N Winter17,"{'': 1, 'md': 1, 'pdf': 19, 'tex': 13, 'png': 69, 'jpg': 1, 'bib': 4, 'pptx': 5, 'sty': 2, 'svg': 1, 'sh': 1}",,,TeX,44,1,0,6,0,1261,True,2,1,0,0,1,5,0,0,7,0,0,0,30,12,,# Course notes for CS224N Winter17þþSubmit pull requests / open issues to help fix typos!,
roboticcam/machine-learning-notes,,False,False,False,151608,41,3974,301,1135,6,16,5,1,"[166, 200, 204, 306, 308, 310, 311, 313, 314]",User,"My continuously updated Machine Learning, Probabilistic Models and Deep Learning notes and demos (1500+ slides)  我不间断更新的机器学习，概率模型和深度学习的讲义(1500+页)和视频链接","{'md': 1, 'pptx': 2, 'pdf': 36, 'txt': 1, 'ipynb': 1}",,,Jupyter Notebook,263,1,0,1,0,877,True,10,2,0,0,0,0,0,0,8,0,0,0,,,3,"# Sinovasinovation DeeCamp 创新工场DeeCAMP讲义þþ* ### [DeeCamp 2019：Story of Softmax](https://github.com/roboticcam/machine-learning-notes/blob/master/files/deecamp_2019.pdf) ###þþproperties of Softmax, Estimating softmax without compute denominator, Probability re-parameterization: Gumbel-Max trick and REBAR algorithmþ(softmax的故事) Softmax的属性, 估计softmax时不需计算分母, 概率重新参数化, Gumbel-Max技巧和REBAR算法þþ* ### [DeeCamp 2018：When Probabilities meet Neural Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/DeeCamp2018_Xu_final.pptx) ###þþExpectation-Maximization & Matrix Capsule Networks; Determinantal Point Process & Neural Networks compression; Kalman Filter & LSTM; Model estimation & Binary classifierþ(当概率遇到神经网络) 主题包括：EM算法和矩阵胶囊网络; 行列式点过程和神经网络压缩; 卡尔曼滤波器和LSTM; 模型估计和二分类问题关系þþ# Video Tutorial to these notes 视频资料þþ* I recorded about 20% of these notes in videos in 2015 in Mandarin (all my notes and writings are in English) You may find them on [Youtube](https://www.youtube.com/channel/UConITmGn5PFr0hxTI2tWD4Q) and [bilibili](https://space.bilibili.com/327617676) and [Youku](http://i.youku.com/i/UMzIzNDgxNTg5Ng)       þþ我在2015年用中文录制了这些课件中约20％的内容 (我目前的课件都是英文的)大家可以在[Youtube](https://www.youtube.com/channel/UConITmGn5PFr0hxTI2tWD4Q) [哔哩哔哩](https://space.bilibili.com/327617676) and [优酷](http://i.youku.com/i/UMzIzNDgxNTg5Ng) 下载þþ# 3D Geometry Computer vision 3D几何计算机视觉 þþ* ### [3D Geometry Fundamentals](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cv_3d_foundation.pdf) ###þCamera Models, Intrinsic and Extrinsic parameter estimation, Epipolar Geometry, 3D reconstruction, Depth Estimationþ相机模型，内部和外部参数估计，对极几何，三维重建，图像深度估计þþ* ### [Recent Deep 3D Geometry based Research](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cv_3d_research.pdf) ###þRecent research of the following topics: Single image to Camera Model estimation, Multi-Person 3D pose estimation from multi-view, GAN-based 3D pose estimation, Deep Structure-from-Motion, Deep Learning based Depth Estimation, 以下主题的最新研究：单图像到相机模型的估计，基于多视图的多人3D姿势估计，基于GAN的3D姿势估计，基于运动的深度结构，基于深度学习的深度估计þþThis section is co-authored with PhD student Yang Li 本部分与博士研究生李杨合写þþ# Deep Learning 深度学习课件þþ* ### [New Research on Softmax function](https://github.com/roboticcam/machine-learning-notes/blob/master/files/softmax.pdf) ###þOut-of-distribution, Neural Network Calibration, Gumbel-Max trick, Stochastic Beams Search (some of these lectures overlap with DeeCamp2019)þþ分布外、神经网络校准、Gumbel-Max 技巧、随机光束(BEAM)搜索（其中一些讲座与 DeeCamp2019 重叠）þþ* ### [Optimisation methods](https://github.com/roboticcam/machine-learning-notes/blob/master/files/optimization.pdf) ###þOptimisation methods in general. not limited to just Deep Learningþþ常用的优化方法。不仅限于深度学习þþ* ### [Neural Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/neural_networks.pdf) ###þbasic neural networks and multilayer perceptron þþ神经网络: 基本神经网络和多层感知器þþ* ### [Convolution Neural Networks: from basic to recent Research](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cnn_beyond.pdf) ###þdetailed explanation of CNN, various Loss function, Centre Loss, contrastive Loss, Residual Networks, Capsule Networks, YOLO, SSDþþ卷积神经网络：从基础到最近的研究：包括卷积神经网络的详细解释，各种损失函数，中心损失函数，对比损失函数，残差网络，胶囊网络, YOLO，SSDþþþ* ### [Word Embeddings](https://github.com/roboticcam/machine-learning-notes/blob/master/files/word_vector.pdf) ###þWord2Vec, skip-gram, GloVe, Fasttextþþ系统的介绍了自然语言处理中的“词表示”中的技巧þþ* ### [Deep Natural Language Processing](https://github.com/roboticcam/machine-learning-notes/blob/master/files/deep_nlp.pdf) ###þRNN, LSTM, Seq2Seq with Attenion, Beam search, Attention is all you need, Convolution Seq2Seq, Pointer Networksþþ深度自然语言处理：递归神经网络,LSTM,具有注意力机制的Seq2Seq，集束搜索，指针网络和 ""Attention is all you need"", 卷积Seq2Seqþþ* ### [Mathematics for Generative Adversarial Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/GAN.pdf) ###þHow GAN works, Traditional GAN, Mathematics on W-GAN, Duality and KKT conditions, Info-GAN, Bayesian GANþþGAN如何工作，传统GAN，W-GAN数学，对偶性和KKT条件，Info-GAN，贝叶斯GANþþ* ### [Restricted Boltzmann Machine](https://github.com/roboticcam/machine-learning-notes/blob/master/files/rbm_gan.pdf) ###þbasic knowledge in Restricted Boltzmann Machine (RBM)þþ受限玻尔兹曼机(RBM)中的基础知识þþ# Reinforcement Learning 强化学习þþ* ### [Reinforcement Learning Basics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dqn.pdf) ###þbasic knowledge in reinforcement learning, Markov Decision Process, Bellman Equation and move onto Deep Q-Learningþþ深度增强学习: 强化学习的基础知识，马尔可夫决策过程，贝尔曼方程，深度Q学习þþ* ### [Monto Carlo Tree Search](https://github.com/roboticcam/machine-learning-notes/blob/master/files/mcts.pdf) ###þMonto Carlo Tree Search, alphaGo learning algorithmþþ蒙托卡罗树搜索，alphaGo学习算法þþ* ### [Policy Gradient](https://github.com/roboticcam/machine-learning-notes/blob/master/files/policy_gradient.pdf) ###þPolicy Gradient Theorem, Mathematics on Trusted Region Optimization in RL, Natural Gradients on TRPO, Proximal Policy Optimization (PPO), Conjugate Gradient Algorithmþþ政策梯度定理, RL中可信区域优化的数学,TRPO自然梯度, 近似策略优化(PPO), 共轭梯度算法þþ# Data Science 数据科学课件þþ* ### [30 minutes introduction to AI and Machine Learning](https://github.com/roboticcam/machine-learning-notes/blob/master/files/30_min_AI.pptx)þAn extremely gentle 30 minutes introduction to AI and Machine Learning. Thanks to my PhD student Haodong Chang for assist editingþþ30分钟介绍人工智能和机器学习, 感谢我的学生常浩东进行协助编辑þþ* ### [Regression methods](https://github.com/roboticcam/machine-learning-notes/blob/master/files/regression.pdf) ###þClassification: Logistic and Softmax; Regression: Linear, polynomial; Mix Effect model **[[costFunction.m]](https://github.com/roboticcam/matlab_demos/blob/master/costFunction.m)** and **[[soft_max.m]](https://github.com/roboticcam/matlab_demos/blob/master/soft_max.m)** þþ分类介绍: Logistic回归和Softmax分类; 回归介绍：线性回归，多项式回归; 混合效果模型 **[[costFunction.m]](https://github.com/roboticcam/matlab_demos/blob/master/costFunction.m)** 和 **[[soft_max.m]](https://github.com/roboticcam/matlab_demos/blob/master/soft_max.m)**þþ* ### [Recommendation system](https://github.com/roboticcam/machine-learning-notes/blob/master/files/recommendation.pdf) ###þcollaborative filtering, Factorization Machines, Non-Negative Matrix factorisation, Multiplicative Update Ruleþþ推荐系统: 协同过滤，分解机，非负矩阵分解，和期中“乘法更新规则”的介绍þþ* ### [Dimension Reduction](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dimension_reduction.pdf) ###þclassic PCA and t-SNEþþ经典的PCA降维法和t-SNE降维法þþ* ### [Introduction to Data Analytics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/AI_and_machine_learning.pdf) and [associate Jupyter notebook](https://github.com/roboticcam/machine-learning-notes/blob/master/files/industry_master_class.ipynb) ###þSupervised vs Unsupervised Learning, Classification accuracyþþ数据分析简介和相关的jupyter notebook，包括监督与无监督学习，分类准确性þþ# Probability and Statistics Background 概率论与数理统计基础课件þþ* ### [Bayesian model](https://github.com/roboticcam/machine-learning-notes/blob/master/files/bayesian.pdf) ###þrevision on Bayes model include Bayesian predictive model, conditional expectationþþ复习贝叶斯模型，包括贝叶斯预测模型，条件期望等基础知识þþ* ### [Probabilistic Estimation](https://github.com/roboticcam/machine-learning-notes/blob/master/files/probability.pdf) ###þsome useful distributions, conjugacy, MLE, MAP, Exponential family and natural parametersþþ 一些常用的分布，共轭特性，最大似然估计, 最大后验估计, 指数族和自然参数þþ* ### [Statistics Properties](https://github.com/roboticcam/machine-learning-notes/blob/master/files/statistics.pdf) ###þuseful statistical properties to help us prove things, include Chebyshev and Markov inequalityþþ 一些非常有用的统计属性可以帮助我们在机器学习中的证明，包括切比雪夫和马尔科夫不等式þþ# Probabilistic Model 概率模型课件þþ* ### [Expectation Maximisation](https://github.com/roboticcam/machine-learning-notes/blob/master/files/em.pdf) ###þProof of convergence for E-M, examples of E-M through Gaussian Mixture Model, **[[gmm_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/gmm_demo.m)** and **[[kmeans_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kmeans_demo.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23901379)**þþ 最大期望E-M的收敛证明, E-M到高斯混合模型的例子, **[[gmm_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/gmm_demo.m)** 和 **[[kmeans_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kmeans_demo.m)** 和 **[[B站视频链接]](https://www.bilibili.com/video/av23901379)**þþ* ### [State Space Model (Dynamic model)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dynamic_model.pdf) ###þexplain in detail of Kalman Filter  **[[bilibili video]](https://www.bilibili.com/video/av24225243)**, **[[kalman_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kalman_demo.m)** and Hidden Markov Model **[[bilibili video]](https://www.bilibili.com/video/av24132174)** þþ状态空间模型(动态模型) 详细解释了卡尔曼滤波器þ**[[B站视频链接]](https://www.bilibili.com/video/av24225243)**, **[[kalman_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kalman_demo.m)**þ和隐马尔可夫模型 **[[B站视频链接]](https://www.bilibili.com/video/av24132174)** þþ# Inference 推断课件þþ* ### [Variational Inference](https://github.com/roboticcam/machine-learning-notes/blob/master/files/variational.pdf) ###þexplain Variational Bayes both the non-exponential and exponential family distribution plus stochastic variational inference. **[[vb_normal_gamma.m]](https://github.com/roboticcam/matlab_demos/blob/master/vb_normal_gamma.m)** and **[[bilibili video]](https://www.bilibili.com/video/av24062247)**þþ变分推导的介绍: 解释变分贝叶斯非指数和指数族分布加上随机变分推断。**[[vb_normal_gamma.m]](https://github.com/roboticcam/matlab_demos/blob/master/vb_normal_gamma.m)** 和 **[[B站视频链接]](https://www.bilibili.com/video/av24062247)** þþ* ### [Stochastic Matrices](https://github.com/roboticcam/machine-learning-notes/blob/master/files/stochastic_matrices.pdf) ###þstochastic matrix, Power Method Convergence Theorem, detailed balance and PageRank algorithmþþ随机矩阵，幂方法收敛定理，详细平衡和谷歌PageRank算法þþ* ### [Introduction to Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/files/introduction_monte_carlo.pdf) ###þinverse CDF, rejection, adaptive rejection, importance sampling **[[adaptive_rejection_sampling.m]](https://github.com/roboticcam/matlab_demos/blob/master/adaptive_rejection_sampling.m)** and **[[hybrid_gmm.m]](https://github.com/roboticcam/matlab_demos/blob/master/hybrid_gmm.m)**þþ累积分布函数逆采样, 拒绝式采样, 自适应拒绝式采样, 重要性采样 **[[adaptive_rejection_sampling.m]](https://github.com/roboticcam/matlab_demos/blob/master/adaptive_rejection_sampling.m)** 和 **[[hybrid_gmm.m]](https://github.com/roboticcam/matlab_demos/blob/master/hybrid_gmm.m)**þþ* ### [Markov Chain Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/files/markov_chain_monte_carlo.pdf) ###þM-H, Gibbs, Slice Sampling, Elliptical Slice sampling, Swendesen-Wang, demonstrate collapsed Gibbs using LDA **[[lda_gibbs_example.m]](https://github.com/roboticcam/matlab_demos/blob/master/lda_gibbs_example.m)** and **[[test_autocorrelation.m]](https://github.com/roboticcam/matlab_demos/blob/master/test_autocorrelation.m)** and **[[gibbs.m]](https://github.com/roboticcam/matlab_demos/blob/master/gibbs.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23980130)**þþ马尔可夫链蒙特卡洛的各种方法 **[[lda_gibbs_example.m]](https://github.com/roboticcam/matlab_demos/blob/master/lda_gibbs_example.m)** 和 **[[test_autocorrelation.m]](https://github.com/roboticcam/matlab_demos/blob/master/test_autocorrelation.m)** 和 **[[gibbs.m]](https://github.com/roboticcam/matlab_demos/blob/master/gibbs.m)** 和 **[[B站视频链接]](https://www.bilibili.com/video/av23980130)**þþþ* ### [Particle Filter (Sequential Monte-Carlo)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/particle_filter.pdf) ###þSequential Monte-Carlo, Condensational Filter algorithm, Auxiliary Particle Filter **[[bilibili video]](https://www.bilibili.com/video/av24285449)**þþ粒子滤波器（序列蒙特卡洛）**[[B站视频链接]](https://www.bilibili.com/video/av24285449)**þþ# Advanced Probabilistic Model 高级概率模型课件þþ* ### [Bayesian Non Parametrics (BNP) and its inference basics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/non_parametrics.pdf) ###þDircihlet Process (DP), Chinese Restaurant Process insights, Slice sampling for DP **[[dirichlet_process.m]](https://github.com/roboticcam/matlab_demos/blob/master/dirichlet_process.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23881062)** and **[[Jupyter Notebook]](https://github.com/roboticcam/python_machine_learning/blob/master/chinese_restaurant_process.ipynb)**þþ非参贝叶斯及其推导基础: 狄利克雷过程,中国餐馆过程,狄利克雷过程Slice采样 **[[dirichlet_process.m]](https://github.com/roboticcam/matlab_demos/blob/master/dirichlet_process.m)** 和 **[[B站视频链接]](https://www.bilibili.com/video/av23881062)** 和 **[[Jupyter Notebook]](https://github.com/roboticcam/python_machine_learning/blob/master/chinese_restaurant_process.ipynb)**þþ* ### [Bayesian Non Parametrics (BNP) extensions](https://github.com/roboticcam/machine-learning-notes/blob/master/files/non_parametrics_extensions.pdf) ###þHierarchical DP, HDP-HMM, Indian Buffet Process (IBP)þþ非参贝叶斯扩展: 层次狄利克雷过程，分层狄利克雷过程-隐马尔可夫模型，印度自助餐过程(IBP)þþ* ### [Completely Random Measure (early draft - written in 2015)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/random_measure.pdf) ###þLevy-Khintchine representation, Compound Poisson Process, Gamma Process, Negative Binomial ProcessþþLevy-Khintchine表示，复合Poisson过程，Gamma过程，负二项过程þþ* ### [Determinantal Point Process](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dpp.pdf) ###þexplain the details of DPP’s marginal distribution, L-ensemble, its sampling strategy, our work in time-varying DPPþþ行列式点过程解释:行列式点过程的边缘分布，L-ensemble，其抽样策略，我们在“时变行列式点过程”中的工作细节þþ# Special Thanksþ* I would like to thank my following PhD students for help me proofreading, and provide great discussions and suggestions to various topics in these notes, including (but not limited to) Hayden Chang, Shawn Jiang, Erica Huang, Deng Chen, Ember Liang; 特别感谢我的博士生团队协助我一起校对课件，以及就课件内容所提出的想法和建议，团队成员包括（但不限于）常浩东，姜帅，黄皖鸣，邓辰，梁轩。þþ* I always look for high quality PhD students in Machine Learning, both in terms of probabilistic model and Deep Learning models. Contact me on YiDa.Xu@uts.edu.auþþ如果你想加入我的机器学习博士生团队或有兴趣实习, 请通过YiDa.Xu@uts.edu.au与我联系。",
stephen/airsonos,,False,False,False,764,13,2083,141,284,0,0,0,0,"[1602, 1653, 1713, 1756, 1778, 1783, 1797, 1946, 1954, 1972]",User,:musical_note: AirPlay to Sonos,"{'': 4, 'md': 3, 'js': 5, 'json': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",JavaScript,107,3,8,5,2,2363,True,169,193,0,0,9,28,0,0,6,1,5,0,,,124,"AirSonosþ========þþAirSonos is a server that adds Apple [AirPlay](https://www.apple.com/airplay/) (iOS, OS X) support to all Sonos devices on a network.þþ[Blog post for further reading](https://medium.com/@stephencwan/hacking-airplay-into-sonos-93a41a1fcfbb)þþQuestions? Feel free to ping [@stephencwan](https://twitter.com/stephencwan)þþInstallationþ------------þþAirSonos requires [node.js](http://nodejs.org) >= v0.10.33 installed to run.þþInstall via [npm](https://www.npmjs.org)þ```þ$ npm install airsonos -gþ```þþPlatform-specific install note available from [`INSTALL.md`](https://github.com/stephen/airsonos/blob/master/INSTALL.md)þþExample usageþ-------------þ```þ$ airsonosþSearching for Sonos devices on network...þþSwan (@ 192.168.0.1:1400, RINCON_B8E9375433D201400:1)þþSearch complete. Set up 1 device tunnel.þ```þþDevelopmentþ-----------þ```þ$ git clone https://github.com/stephen/airsonos.gitþ$ cd airsonosþ$ npm installþ$ node ./bin/index.jsþ```þþInternally, AirSonos is a thin wrapper around the [nodetunes](https://github.com/stephen/nodetunes) and [nicercast](https://github.com/stephen/nicercast) packages.þþChangelogþ---------þþSee [`CHANGELOG.md`](https://github.com/stephen/airsonos/blob/master/CHANGELOG.md)",
andremion/Music-Player,,False,False,False,24772,131,3348,117,705,0,0,0,0,"[757, 778, 779, 878, 1095, 1187, 1296, 1300, 1301, 1312]",User,From UI Proposal to Code :notes::arrow_forward:,"{'': 4, 'md': 1, 'gradle': 3, 'pro': 1, 'java': 15, 'xml': 30, 'png': 56, 'jpg': 6, 'gif': 9, 'json': 2, 'properties': 2, 'jar': 1, 'bat': 1}",https://medium.com/@andremion/music-player-3a85864d6df7#.iklz50r6n,"{'key': 'apache-2.0', 'name': 'Apache License 2.0', 'spdx_id': 'Apache-2.0', 'url': 'https://api.github.com/licenses/apache-2.0', 'node_id': 'MDc6TGljZW5zZTI='}",Java,67,1,3,3,9,1527,True,0,17,0,0,0,4,0,0,8,0,0,0,,,507,"<img alt=""Icon"" src=""app/src/main/res/mipmap-xxhdpi/ic_launcher.png?raw=true"" align=""left"" hspace=""1"" vspace=""1"">þþ<a alt='Buy Me a Coffee at ko-fi.com' href='https://ko-fi.com/T6T05M4O' target='_blank' align='right'><img align='right' height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi4.png?v=0' border='0' /></a>þ<a alt='Try it on Google Play' href='https://play.google.com/store/apps/details?id=com.sample.andremion.musicplayer' target='_blank' align='right'><img align='right' height='36' style='border:0px;height:36px;' src='https://developer.android.com/images/brand/en_generic_rgb_wo_60.png' border='0' /></a>þþ# Music Player: From UI Proposal to Codeþþ> This is a prototype made for the [article](https://medium.com/@andremion/music-player-3a85864d6df7#.iklz50r6n). This is not a real music player and don't expect it is.þþSome developers have difficult to code when the UI proposal is a bit “sophisticated” or “complex”. Many of them strip a lot of significant portion of the UI or even the Motion when they are coding, and the result ends up quite different of the original proposal.þþThis article talks about how would be to code an UI proposal, skipping some basic Android details and focusing on transition and animation approach...þþRead more at [here](https://medium.com/@andremion/music-player-3a85864d6df7#.iklz50r6n)þþ#### Special thanks to [michaelizer](https://github.com/michaelizer) for the awesome logo.þþ</br>þþ[![License Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=true)](http://www.apache.org/licenses/LICENSE-2.0)þ![minSdkVersion 21](https://img.shields.io/badge/minSdkVersion-21-red.svg?style=true)þ![compileSdkVersion 27](https://img.shields.io/badge/compileSdkVersion-27-yellow.svg?style=true)þþ[![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-Music--Player-green.svg?style=true)](https://android-arsenal.com/details/3/3855)þ[![MaterialUp Music-Player](https://img.shields.io/badge/MaterialUp-Music--Player-blue.svg?style=true)](https://www.uplabs.com/posts/music-player-open-source-apps)þ[![Android Sweets #27](https://img.shields.io/badge/Android%20Sweets-%2327-ff69b4.svg?style=true)](https://androidsweets.ongoodbits.com/2016/07/14/issue-27)þ[![Awesome Android #22](https://img.shields.io/badge/Awesome%20Android-%2322-green.svg?style=true)](https://android.libhunt.com/newsletter/22)þþ[Transition](https://dribbble.com/shots/1850527-Music-Player-Transition) by [Anish Chandran](https://dribbble.com/anish_chandran) | Code by [André Mion](https://github.com/andremion)þ--- | ---þ![Transition by Anish Chandran](https://raw.githubusercontent.com/andremion/Music-Player/master/art/music_player_concept_cropped.gif) | ![Code by André Mion](https://raw.githubusercontent.com/andremion/Music-Player/master/art/music_player_code.gif)þþ## Libraries and tools used in the projectþþ* [Design Support Library](http://developer.android.com/intl/pt-br/tools/support-library/features.html#design)þThe Design package provides APIs to support adding material design components and patterns to your apps.þ* [MusicCoverView](https://github.com/andremion/Music-Cover-View)þA Subclass of ImageView that 'morphs' into a circle shape and can rotates. Useful to be used as album cover in Music apps.þ* [RecyclerView](http://developer.android.com/intl/pt-br/reference/android/support/v7/widget/RecyclerView.html)þA flexible view for providing a limited window into a large data set.þ* [PercentRelativeLayout](https://developer.android.com/reference/android/support/percent/PercentRelativeLayout.html)þSubclass of RelativeLayout that supports percentage based dimensions and margins.þþ## Licenseþþ    Copyright 2016 André Mionþþ    Licensed under the Apache License, Version 2.0 (the ""License"");þ    you may not use this file except in compliance with the License.þ    You may obtain a copy of the License atþþ        http://www.apache.org/licenses/LICENSE-2.0þþ    Unless required by applicable law or agreed to in writing, softwareþ    distributed under the License is distributed on an ""AS IS"" BASIS,þ    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.þ    See the License for the specific language governing permissions andþ    limitations under the License.",
simpulton/noterious,,False,False,False,1450,68,142,21,215,0,0,0,0,"[1121, 1396, 1406, 1776, 1933, 1935, 1936, 1937, 1938]",User,Noterio.us - AngularJS Note Board ,"{'': 1, 'md': 1, 'js': 33, 'json': 1, 'html': 12, 'css': 4, 'eot': 1, 'svg': 1, 'ttf': 1, 'woff': 1, 'jpg': 5, 'gif': 1, 'png': 5, 'ico': 1}",,,JavaScript,134,7,0,7,0,2546,True,5,1,0,0,1,4,1,0,6,0,0,0,,,889,"![Noterious](https://cloud.githubusercontent.com/assets/590361/6837796/feb3b6ca-d30d-11e4-8647-780ded6524a8.png)þþNoterious þ=========þþWelcome to the Noterious app. It is built using AngularJS with Firebase as the backend. If you would like to see it in action, visit http://noterio.us; if you want to run it locally, read on!þþPrerequisitesþ----------þBefore you start, you will need:þ* [Git](http://git-scm.com/book/en/v2/Getting-Started-Installing-Git)þ* [Node.js and Node Package Manager (NPM)](https://nodejs.org/download/)þþGet the Codeþ-------------------þNow go ahead and download the code.þ```þgit clone https://github.com/simpulton/noterious.gitþcd noteriousþ```þþSetting up Firebaseþ-------------------þTo start off, you will need to set up an account with Firebase:þ* Navigate to [firebase.com](https://www.firebase.com/) and click `Sign Up`þ* Create an app (named whatever you want)þ* Click on your new app's URLþ* Navigate to the `Login & Auth` section of your dashboard and check the `Enable Email & Password Authentication` checkbox.þ* Navigate to the data tab and then copy the URL from your address bar. It should have the form of `https://<your-app-name>.firebaseio.com`.þ* Open the `src/app/noterious.js` file and replace the `ENDPOINT_URI` constant with the URL you copied. MAKE SURE there is a trailing slash at the end of the URL.þ* Open the `src/app/common/services/auth-service.js` and modify `config` according to the template you can find on `https://console.firebase.google.com/project/<your-app-name>/settings/general/` clicking `Add Firebase to your web app` buttonþþRun the Appþ-------------------þNext, you need to install all of your dependencies.þþ`npm install`þþAnd install and run the `serve` package so you can build the app.þþ```þnpm install -g serveþserve src/þ```þþNavigate to `http://localhost:3000` and view the gloriousness that is Noterious!þþTestingþ-----------þNoterious uses [Gulp](https://github.com/gulpjs/gulp/blob/master/docs/getting-started.md) for running tests.þYou can start a [TDD](http://en.wikipedia.org/wiki/Test-driven_development) workflow with `gulp tdd`.þþ> Note: you must have `Gulp CLI` installed in order to run the tests with `gulp`. If you do not have it installed globally, run `npm install -g gulp-cli` or use the method below.þþIf you prefer to use the local installation of gulp managed by npm, you can start the TDD workflow withþþ`node ./node_modules/gulp/bin/gulp.js tdd`þþFor continuous integration, you can execute tests with `gulp test` or `npm test`.",
ethereum/pm,,False,False,False,991,91,419,199,118,30,6254,528,9,"[1, 16, 18, 19, 21, 26, 28, 29, 31, 39]",Organization,Project Management: Meeting notes and agenda items,"{'md': 90, '': 1}",,"{'key': 'other', 'name': 'Other', 'spdx_id': 'NOASSERTION', 'url': None, 'node_id': 'MDc6TGljZW5zZTA='}",,307,3,0,34,0,1379,True,2,103,2,21,3,81,3,17,7,0,0,0,235,63,,"## All Core Devs Meetingsþþ### PurposeþThe all core devs meeting is a technical meeting intended to bring together various Ethereum teams who play major roles in determining the direction of the protocol. Ethereum client and research teams provide updates to their projects, discuss various [EIPs](https://eips.ethereum.org/) to improve the protocol, and support each other as we **buidl** Web 3.0.þþ### Previous Meetingsþþ №  | Date                             | Agenda        |Notes          | Recording            |þ--- | -------------------------------- | -------------- |-------------- | -------------------- |þ89 | Friday 12 June 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/180) | [notes](All%20Core%20Devs%20Meetings/Meeting%2089.md) | [video](https://youtu.be/c_JmTqeQkU4) |þ88 | Friday 29 May 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/172) | [notes](All%20Core%20Devs%20Meetings/Meeting%2088.md) | [video](https://youtu.be/UJ1jK73rKdk) |þ87 | Friday 15 May 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/169) | [notes](All%20Core%20Devs%20Meetings/Meeting%2087.md) | [video](https://www.youtube.com/watch?v=bGgzALuyY3w) |þ86| Friday 1 May 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/165) | [notes](All%20Core%20Devs%20Meetings/Meeting%2086.md) | [video](https://www.youtube.com/watch?v=MOZ7_0Tb95M) |þ85 | Friday 17 April 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/164) | [notes](https://github.com/poojaranjan/pm/blob/ee277386af75621c48923f9740e4913ee241cd05/All%20Core%20Devs%20Meetings/Meeting%2085.md) | [video](https://www.youtube.com/watch?v=KlzwFLOj6Bw&feature=youtu.be) |þ84 | Friday 3 April 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/162) | [notes](All%20Core%20Devs%20Meetings/Meeting%2084.md) | [video](https://www.youtube.com/watch?v=JqxVvJBhTxo) |þ83 | Friday 20 March 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/159) | [notes](All%20Core%20Devs%20Meetings/Meeting%2083.md) | [video](https://www.youtube.com/watch?v=vDGj660uZE0) |þ82 | Friday 6 March 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/155) | [notes](All%20Core%20Devs%20Meetings/Meeting%2082.md) | [video](https://www.youtube.com/watch?v=kham8c0qhmw) |þ81 | Friday 21 February 2020, 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/152) | [notes](All%20Core%20Devs%20Meetings/Meeting%2081.md) | [video](https://www.youtube.com/watch?v=zSRzlC_dCx8&feature=youtu.be) |þ80 | Friday, January 24, 2020 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/150) | [notes]() | [video](https://www.youtube.com/watch?v=535tJTI0c58&feature=youtu.be) |þ79 | Friday, January 24, 2020 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/148) | [notes](All%20Core%20Devs%20Meetings/Meeting%2079.md) | [video](https://www.youtube.com/watch?v=0-Vld7GTRhQ) |þ78 | Friday, January  10, 2020 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/147) | [notes]() | [video](https://www.youtube.com/watch?v=snEdgekxJto) |þ77 | Friday, December 13, 2019, 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/142) | [notes](All%20Core%20Devs%20Meetings/Meeting%2077.md) | [video](https://www.youtube.com/watch?v=HpoBvMylPfk) |þ 76 | Friday, November 29, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/140) | [notes](All%20Core%20Devs%20Meetings/Meeting%2076.md) | [video](https://www.youtube.com/watch?v=BMMkxeH72U0) |þ 75 | Friday, November 15, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/138) | [notes](All%20Core%20Devs%20Meetings/Meeting%2075.md) | [video](https://www.youtube.com/watch?v=3qZFiETlDtk) |þ 74 | Friday, November 1, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/134) | [notes](All%20Core%20Devs%20Meetings/Meeting%2074.md) | [video](https://www.youtube.com/watch?v=aZ0S_oLSwhE) |þ 73 | Friday, October 25, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/133) | [notes](All%20Core%20Devs%20Meetings/Meeting%2073.md) | [video](https://www.youtube.com/watch?v=zT4TzlXQ6wA) |þ 72 | Friday, October 4, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/129) | [notes](All%20Core%20Devs%20Meetings/Meeting%2072.md) | [video](https://www.youtube.com/watch?v=rPD2EpDDI-0) |þ 71 | Friday, September 20, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/125) | [notes](All%20Core%20Devs%20Meetings/Meeting%2071.md) | [video](https://www.youtube.com/watch?v=OjJd2G0pmeM) |þ 70 | Friday, September 6, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/123) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2070.md) | [video](https://www.youtube.com/watch?v=6m0So81_j2Q) |þ 69 | Friday, August 23, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/121) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2069.md) | [video](https://www.youtube.com/watch?v=yO0WdT-J64w) |þ 68 | Thursday, August 15, 2019 22:00 UTC | [agenda](https://github.com/ethereum/pm/issues/119) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2068.md) | [video](https://www.youtube.com/watch?v=08eaI8JjSbw) |þ 67 | Friday, August 2, 2019 06:00 UTC | [agenda](https://github.com/ethereum/pm/issues/116) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2067.md) | [video](https://www.youtube.com/watch?v=fJd_xYnYrUU) |þ 66 | Friday, July 26, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/113) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2066.md) | [video](https://www.youtube.com/watch?v=DzmfR2P9kFk) |þ 65 | Friday, July 18, 2019 22:00 UTC | [agenda](https://github.com/ethereum/pm/issues/111) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2065.md) | [video](https://www.youtube.com/watch?v=41kiRf1E-jI) |þ 64 | Friday, July 5, 2019 06:00 UTC | [agenda](https://github.com/ethereum/pm/issues/107) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2064.md) | [video](https://www.youtube.com/watch?v=2D_DqJ8jL9Y) |þ 63 | Friday, June 21, 2019 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/102) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2063.md) | [video](https://www.youtube.com/watch?v=Cl5zGk-3Ej4) |þ 62 | Fri, May 24, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/99) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2062.md) | [video](https://youtu.be/lF_XxqxgVuA) |þ 61 | Fri, May 10, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/97) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2061.md) | [video](https://www.youtube.com/watch?v=CNcBuJ6wivE) |þ 60 | Fri, April 26, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/95) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2060.md) | [video](https://www.youtube.com/watch?v=O_DE4NwOz9A) |þ 59 | Fri, April 12, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/93) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2059.md) | [video](https://www.youtube.com/watch?v=gfC92gQKKnI) |þ 58 | Fri, March 29, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/89) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2058.md) | [video](https://www.youtube.com/watch?v=v8Psbo8zY4Y) |þ 57 | Fri, March 15, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/83) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2057.md) | [video](https://www.youtube.com/watch?v=GQ0kbH0iSfI) |þ 56 | Fri, March 1, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/82) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2056.md) | [video](https://www.youtube.com/watch?v=q3ylladkuYY) |þ 55 | Fri, February 15, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/79) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2055.md) | [video](https://www.youtube.com/watch?v=NUz9_SpG84g) |þ 54 | Fri, February 1, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/73) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2054.md) | [video](https://www.youtube.com/watch?v=qBpImOhpWFg) |þ 53 | Fri, January 18, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/70) | [notes](https://github.com/ethereum/pm/blob/master/All%20Core%20Devs%20Meetings/Meeting%2053.md) | [video](https://www.youtube.com/watch?v=45mrrVrw4x8) |þ 52 | Fri, January 4, 2019 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/66) | [notes](All%20Core%20Devs%20Meetings/Meeting%2052.md) | [video](https://youtu.be/iSc3TbjZu1k) |þ 51 | Fri, December 7, 2018 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/64) | [notes](All%20Core%20Devs%20Meetings/Meeting%2051.md) | [video](https://www.youtube.com/watch?v=V4sAl-B8yZU) |þ 1X | Fri, November 30, 2018 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/65) | [notes](All%20Core%20Devs%20Meetings/Eth1x%20Sync%201.md) | not recorded |þ 50 | Fri, November 23, 2018 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/62) | [notes](All%20Core%20Devs%20Meetings/Meeting%2050.md) | [video](https://www.youtube.com/watch?v=wfxvCEhglTM) |þ 49 | Fri, November 9, 2018 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/60) | [notes](All%20Core%20Devs%20Meetings/Meeting%2049.md) | [video](https://www.youtube.com/watch?v=DUUOCDxvKbw) |þ C2 | Fri, October 19, 2018 14:00 UTC   | [agenda](https://github.com/ethereum/pm/issues/61) | [notes](All%20Core%20Devs%20Meetings/Constantinople%20Meeting%202.md) | [video](https://www.youtube.com/watch?v=5Q67tmkZ5So) |þ 48 | Fri, October 12, 2018 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/59) | [notes](All%20Core%20Devs%20Meetings/Meeting%2048.md) | [video](https://www.youtube.com/watch?v=lz5CcpnQ1_s) |þ 47 | Fri, September 28, 2018 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/58) | [notes](All%20Core%20Devs%20Meetings/Meeting%2047.md) | [video](https://www.youtube.com/watch?v=z2mefVnZHpw) |þ 46 | Fri, September 14, 2018 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/56) | [notes](All%20Core%20Devs%20Meetings/Meeting%2046.md) | [video](https://www.youtube.com/watch?v=TafZui-DnV0) |þ C1 | Fri, August 31, 2018 14:00 UTC   | [agenda](https://github.com/ethereum/pm/issues/55) | None | [video](https://www.youtube.com/watch?v=mAs3JZHroKM) |þ 45 | Fri, August 24, 2018 14:00 UTC   | [agenda](https://github.com/ethereum/pm/issues/54) | [notes](All%20Core%20Devs%20Meetings/Meeting%2045.md) | [video](https://www.youtube.com/watch?v=6CZ1uO_WxVk) |þ 44 | Fri, August 10, 2018 14:00 UTC   | [agenda](https://github.com/ethereum/pm/issues/52) | [notes](All%20Core%20Devs%20Meetings/Meeting%2044.md) | [video](https://youtu.be/0Lyn5OryooA) |þ 43 | Fri, July 27, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/51) | [notes](All%20Core%20Devs%20Meetings/Meeting%2043.md) \| [reddit](https://www.reddit.com/r/ethereum/comments/929wgu/live_ethereum_core_devs_meeting_43_072718_starts/) | [video](https://www.youtube.com/watch?v=6I7SRa58-9M) |þ 42 | Fri, July 13, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/50) | [notes](All%20Core%20Devs%20Meetings/Meeting%2042.md) | [video](https://www.youtube.com/watch?v=TWL6QaCsl1I) |þ 41 | Fri, June 29, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/46) | [notes](All%20Core%20Devs%20Meetings/Meeting%2041.md) | [video](https://www.youtube.com/watch?v=HpCMguxraBA) |þ 40 | Fri, June 15, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/44) | [notes](All%20Core%20Devs%20Meetings/Meeting%2040.md) | [video](https://www.youtube.com/watch?v=8-AZys80RrU) |þ 39 | Fri, June 1, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/43) | [notes](All%20Core%20Devs%20Meetings/Meeting%2039.md) | [video](https://www.youtube.com/watch?v=7FNRWEQ_H7w) |þ 38 | Fri, May 18, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/40) | [notes](All%20Core%20Devs%20Meetings/Meeting%2038.md) | [video](https://www.youtube.com/watch?v=1WBuF8cMKUk) |þ 37 | Fri, April 20, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/37) | [notes](All%20Core%20Devs%20Meetings/Meeting%2037.md) | [video](https://www.youtube.com/watch?v=vKumx5CIA-k) |þ 36 | Fri, April 6, 2018 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/36) | [notes](All%20Core%20Devs%20Meetings/Meeting%2036.md) | [video](https://www.youtube.com/watch?v=SoPfoNpqG0k) |þ 35 | Fri, March 23, 2018 14:00 UTC    | [agenda](https://github.com/ethereum/pm/issues/33) | [notes](All%20Core%20Devs%20Meetings/Meeting%2035.md) | [video](https://youtu.be/HHK6xhuSyUU) |þ 34 | Fri, February 23, 2018 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/32) | [notes](All%20Core%20Devs%20Meetings/Meeting%2034.md) \| [reddit](https://www.reddit.com/r/ethereum/comments/7zpxe3/notes_from_ethereum_core_devs_meeting_34_22318/) | [video](https://youtu.be/GhUtruRZOlo) |þ 33 | Fri, February 9, 2018 14:00 UTC  | [agenda](https://github.com/ethereum/pm/issues/31) | [video](https://youtu.be/wPBzs2NBnsA) |þ 32 | Fri, January 26, 2018 14:00 UTC  | [agenda](https://github.com/ethereum/pm/issues/30) | [video](https://youtu.be/ZtPy9r0jthI) |þ 31 | Fri, January 12, 2018 14:00 UTC  | [agenda](https://github.com/ethereum/pm/issues/29) | [notes](All%20Core%20Devs%20Meetings/Meeting%2031.md) \| [reddit](https://www.reddit.com/r/ethereum/comments/7pu8hr/live_1400_utc_ethereum_core_devs_meeting_31_011218/) | [video](https://youtu.be/biNCOCQdjQ0) |þ 30 | Fri, December 15, 2017 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/28) | [notes](All%20Core%20Devs%20Meetings/Meeting%2030.md) | [video](https://youtu.be/naPA7tjrgsk) |þ 29 | Fri, December 1, 2017 14:00 UTC  | [agenda](https://github.com/ethereum/pm/issues/27) | [notes](All%20Core%20Devs%20Meetings/Meeting%2029.md) | [video](https://youtu.be/1GulA7iA-O0) |þ 28 | Fri, November 17, 2017 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/26) | [notes](All%20Core%20Devs%20Meetings/Meeting%2028.md) | [video](https://youtu.be/8S-MEGYq_CI) |þ 27 | Fri, October 20, 2017  14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/25) | None | [video](https://youtu.be/ZN-AtGgtmtA) |þ 26 | Fri, October 6, 2017 14:00 UTC   | [agenda](https://github.com/ethereum/pm/issues/24) | None | [video](https://youtu.be/AC2vL7hxu4c) |þ 25 | Fri, September 22, 2017 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/23) | [notes](All%20Core%20Devs%20Meetings/Meeting%2025.md) | [video](https://youtu.be/gxtftZB7_jA) |þ 24 | Fri, September 8, 2017 14:00 UTC | [agenda](https://github.com/ethereum/pm/issues/22) | [notes](All%20Core%20Devs%20Meetings/Meeting%2024.md) | [video](https://youtu.be/_5Tp_U1jBww) |þ 23 | Fri, August 25, 2017 14:00 UTC   | [agenda](https://github.com/ethereum/pm/issues/21) | [notes](All%20Core%20Devs%20Meetings/Meeting%2023.md) | [video](https://youtu.be/PQjeAZyL2_w) |þ 22 | Fri, August 11, 2017 14:00 UTC   | [agenda](https://github.com/ethereum/pm/issues/20) | [notes](All%20Core%20Devs%20Meetings/Meeting%2022.md) | [video](https://youtu.be/R_943As7WMg) |þ 21 | Fri, July 28, 2017 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/19) | [notes](All%20Core%20Devs%20Meetings/Meeting%2021.md) | [video](https://youtu.be/GK4a6Y5wnFY) |þ 20 | Fri, July 14, 2017 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/18) | [notes](All%20Core%20Devs%20Meetings/Meeting%2020.md) | [video](https://youtu.be/hRQg_lHEKl4) |þ 19 | Fri, June 30, 2017 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/17) | [notes](All%20Core%20Devs%20Meetings/Meeting%2019.md) | [video](https://youtu.be/wLaI7680I4w) |þ 18 | Fri, June 16, 2017 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/16) | [notes](All%20Core%20Devs%20Meetings/Meeting%2018.md) | [video](https://youtu.be/8jWhPylWros) |þ 17 | Fri, June 3, 2017 14:00 UTC      | [agenda](https://github.com/ethereum/pm/issues/15) | None | [video](https://youtu.be/E77sdcZZH0s) |þ 16 | Fri, May 19, 2017 14:00 UTC      | [agenda](https://github.com/ethereum/pm/issues/14) | [notes](All%20Core%20Devs%20Meetings/Meeting%2016.md) | [video](https://youtu.be/brhanl8T2UY) |þ 15 | Fri, May 5, 2017 14:00 UTC       | [agenda](https://github.com/ethereum/pm/issues/13) | [notes](All%20Core%20Devs%20Meetings/Meeting%2015.md) | not recorded |þ 14 | Fri, April 21, 2017 14:00 UTC    | [agenda](https://github.com/ethereum/pm/issues/12) | [notes](All%20Core%20Devs%20Meetings/Meeting%2014.md) | [video](https://youtu.be/PGi0vBxDPHY) |þ 13 | Fri, April 7, 2017 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/8) | [notes](All%20Core%20Devs%20Meetings/Meeting%2013.md) | [video](https://youtu.be/aGeGvZ5uS8s) |þ 12 | Fri, March 17, 2017 14:00 UTC    | [agenda](https://github.com/ethereum/pm/issues/7) | [notes](All%20Core%20Devs%20Meetings/Meeting%2012.md) | [video](https://youtu.be/g2gsYRlThD4) |þ 11 | Fri, March 3, 2017 14:00 UTC     | [agenda](https://github.com/ethereum/pm/issues/6) | [notes](All%20Core%20Devs%20Meetings/Meeting%2011.md) | [video](https://youtu.be/EiXwg9vjGdY) |þ 10 | Fri, February 10, 2017 14:00 UTC| [agenda](https://github.com/ethereum/pm/issues/5) | [notes](All%20Core%20Devs%20Meetings/Meeting%2010.md) | [video](https://youtu.be/huYl7eOlKJE) |þ  9 | Wed, January 25, 2017 14:00 UTC  | [agenda](https://github.com/ethereum/pm/issues/3) | [notes](All%20Core%20Devs%20Meetings/Meeting%209.md) | [video](https://youtu.be/ex51Gb3SVqo) |þ  8 | Fri, October 28, 2016 13:00 UTC  | [agenda](https://github.com/ethereum/pm/issues/1) | [notes](All%20Core%20Devs%20Meetings/Meeting%208.md) | not recorded |þ  7 | Fri, September 2, 2016           | None | [notes](Archive/EIPs%20Wiki/Notes%20for%20Core%20Dev%20Meeting%209%202.md) | not recorded |þ  ? | Mon, May 2, 2016                 | None | [notes](Archive/EIPs%20Wiki/Meeting%202016%2005%202.md) | not recorded |þ  2 | Fri, January 1, 2016             | None | [notes](Archive/EIPs%20Wiki/Notes.md) | not recorded |þ  1 | Mon, November 30, 2015           | None | [notes](Archive/EIPs%20Wiki/Notes.md) | not recorded |þ  0 | ??                               | None | [notes](Archive/EIPs%20Wiki/Notes.md) | not recorded |þþþ### Who Can AttendþLow-level protocol developers, client developers, and core Ethereum researchers are invited to attend the meetings. Generally every Ethereum client is represented as well as key members of Layer 1 research/scaling teams. Sometimes a non-core developer with particular expertise on a topic is invited on to discuss a specific agenda item. If you feel you would contribute to the meetings by your attendance please reach out to Hudson Jameson at hudson@ethereum.org.þþ### Agenda ItemsþAgenda's are posted to https://github.com/ethereum/pm/issues. Anyone is welcome to add an item to the agenda as long as it follows these guidelines:þ- The topic is technical in nature.þ- The topic involves the Ethereum protocol at a low-level. This means Dapps and ERCs are generally not allowed as topics.þ- The topic should not be philosophical. The core developer meetings are not meant to decide philosophical contentious issues that should be decided by the community. There are exceptions to this, but generally these topics distract from more productive technical discussion.þþ### Who Manages the MeetingsþIn the beginning (2015-fall 2016) George Hallam facilitated the meetings. Since the fall of 2016 Hudson Jameson has facilitated and recorded the meetings. In early 2018 Lane Rettig joined to help facilitate meetings, handle recordings, and publish notes from the meetings.þThe meetings are independent of any organization. However, Hudson Jameson is a contractor for the Ethereum Foundation and the Ethereum Foundation pays for the videoconference software used in the meetings. Livestreaming instruction for the meetings can be found [here](https://docs.google.com/document/d/1dF_Drs56ErV6wJgFmbzpdN-cINshKCsB61D92NS2JDg/edit).",
JerryLead/SparkInternals,,False,False,False,70743,193,4126,615,1640,1,9,9,1,"[88, 92, 332, 357, 444, 804, 821, 827, 833, 1235]",User,Notes talking about the design and implementation of Apache Spark,"{'': 7, 'md': 31, 'graffle': 5, 'png': 96, 'json': 1, 'pdf': 53}",,,,166,3,0,27,0,2164,True,25,4,0,0,1,43,0,1,7,0,0,0,,,882,"# Spark InternalsþþSpark Version: 1.0.2þDoc Version: 1.0.2.0þþ## Authorsþ| Weibo/Twitter ID | Name | Contributions |þ|:-----------|:-------------|:-------------|þ|[@JerryLead](http://weibo.com/jerrylead) | Lijie Xu | Author of the original Chinese version, and English version update |þ|[@juhanlol](https://twitter.com/juhanlol) | Han JU | English version and update (Chapter 0, 1, 3, 4, and 7) |þ|[@invkrh](https://twitter.com/invkrh) | Hao Ren | English version and update (Chapter 2, 5, and 6)|þ|[@AorJoa](https://twitter.com/AorJoa) | Bhuridech Sudsee | Thai version |þþ## IntroductionþþThis series discuss the design and implementation of Apache Spark, with focuses on its design principles, execution mechanisms, system architecture and performance optimization. In addition, there's some comparisons with Hadoop MapReduce in terms of design and implementation. I'm reluctant to call this document a ""code walkthrough"", because the goal is not to analyze each piece of code in the project, but to understand the whole system in a systematic way (through analyzing the execution procedure of a Spark job, from its creation to completion).þþThere're many ways to discuss a computer system. Here, We've chosen a **problem-driven** approach.  Firstly one concrete problem is introduced, then it gets analyzed step by step. We'll start from a typical Spark example job and then discuss all the related important system modules. I believe that this approach is better than diving into each module right from the beginning.þþThe target audiences of this series are geeks who want to have a deeper understanding of Apache Spark as well as other distributed computing frameworks.þþI'll try my best to keep this documentation up to date with Spark since it's a fast evolving project with an active community. The documentation's main version is in sync with Spark's version. The additional number at the end represents the documentation's update version.þþFor more academic oriented discussion, please check out Matei's PHD thesis and other related papers. You can also have a look at my blog (in Chinese) [blog](http://www.cnblogs.com/jerrylead/archive/2013/04/27/Spark.html).þþI haven't been writing such complete documentation for a while. Last time it was about three years ago when I was studying Andrew Ng's ML course. I was really motivated at that time! This time I've spent 20+ days on this document, from the summer break till now (August 2014). Most of the time is spent on debugging, drawing diagrams and thinking how to put my ideas in the right way. I hope you find this series helpful.þþ## ContentsþWe start from the creation of a Spark job, and then discuss its execution. Finally, we dive into some related system modules and features.þþ1. [Overview](https://github.com/JerryLead/SparkInternals/blob/master/EnglishVersion/1-Overview.md) Overview of Apache Sparkþ2. [Job logical plan](https://github.com/JerryLead/SparkInternals/blob/master/EnglishVersion/2-JobLogicalPlan.md) Logical plan of a job (data dependency graph)þ3. [Job physical plan](https://github.com/JerryLead/SparkInternals/blob/master/EnglishVersion/3-JobPhysicalPlan.md) Physical planþ4. [Shuffle details](https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/4-shuffleDetails.md) Shuffle processþ5. [Architecture](https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/5-Architecture.md) Coordination of system modules in job executionþ6. [Cache and Checkpoint](https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/6-CacheAndCheckpoint.md)  Cache and Checkpointþ7. [Broadcast](https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/7-Broadcast.md) Broadcast featureþ8. Job Scheduling TODOþ9. Fault-tolerance TODOþþ## Other languagesþþChinese Version is at [markdown/](https://github.com/JerryLead/SparkInternals/tree/master/markdown).þThai Version is at [markdown/thai](https://github.com/JerryLead/SparkInternals/tree/master/markdown/thai)þþ## How to read this documentþþThe documentation is written in markdown. The pdf version is also available [here](https://github.com/JerryLead/SparkInternals/tree/master/pdf).þþIf you're under Mac OS X, I recommand [MacDown](http://macdown.uranusjr.com/) with a github theme for reading.þþ## Gitbook (Chinese version)þþThanks [@Yourtion](https://github.com/yourtion) for creating the gitbook version.þþOnline reading  http://spark-internals.books.yourtion.com/þþDownloadsþþ- PDF https://www.gitbook.com/download/pdf/book/yourtion/sparkinternalsþ- EPUB https://www.gitbook.com/download/epub/book/yourtion/sparkinternalsþ- MOBI https://www.gitbook.com/download/mobi/book/yourtion/sparkinternalsþþ## ExamplesþI've created some examples to debug the system during the writing, they are avaible under [SparkLearning/src/internals](https://github.com/JerryLead/SparkLearning/tree/master/src/internals).þþ## AcknowledgementþþI appreciate the help from the following in providing solutions and ideas for some detailed issues:þþ- [@Andrew-Xia](http://weibo.com/u/1410938285) Participated in the discussion of BlockManager's implemetation's impact on broadcast(rdd).þþ- [@CrazyJVM](http://weibo.com/476691290) Participated in the discussion of BlockManager's implementation.þþ- [@王联辉](http://weibo.com/u/1685831233) Participated in the discussion of BlockManager's implementation.þþThanks to the following for complementing the document:þþ| Weibo ID | Chapter | Content | Revision status |þ|:-----------|:-------------|:-------------|:-------------|þ| [@OopsOutOfMemory](http://weibo.com/oopsoom) | Overview | Relation between workers and executors and [Summary on Spark Executor Driver's Resouce Management](http://blog.csdn.net/oopsoom/article/details/38763985) (in Chinese) | There's not yet a conclusion on this subject since its implementation is still changing, a link to the blog is added |þþThanks to the following for finding errors:þþ| Weibo Id | Chapter | Error/Issue | Revision status |þ|:-----------|:-------------|:-------------|:-------------|þ| [@Joshuawangzj](http://weibo.com/u/1619689670) | Overview | When multiple applications are running, multiple Backend process will be created | Corrected, but need to be confirmed. No idea on how to control the number of Backend processes |þ| [@\_cs\_cm](http://weibo.com/u/1551746393) | Overview | Latest groupByKey() has removed the mapValues() operation, there's no MapValuesRDD generated | Fixed groupByKey() related diagrams and text |þ| [@染染生起](http://weibo.com/u/2859927402) | JobLogicalPlan | N:N relation in FullDepedency N:N is a NarrowDependency | Modified the description of NarrowDependency into 3 different cases with detaild explaination, clearer than the 2 cases explaination before |þ| [@zzl0](https://github.com/zzl0) | Fisrt four chapters | Lots of typos，such as ""groupByKey has generated the 3 following RDDs""，should be 2. Check [pull request](https://github.com/JerryLead/SparkInternals/pull/3/files)。 | All fixed |þ| [@左手牵右手TEL](http://weibo.com/w397090770) | Cache and Broadcast chapter | Lots of typos | All fixed |þ| [@cloud-fan](https://github.com/cloud-fan) | JobLogicalPlan | Some arrows in the Cogroup() diagram should be colored red | All fixed |þ| [@CrazyJvm](http://weibo.com/476691290) | Shuffle details | Starting from Spark 1.1, the default value for spark.shuffle.file.buffer.kb is 32k, not 100k | All fixed |þþSpecial thanks to [@明风Andy](http://weibo.com/mingfengandy) for his great support.þþSpecial thanks to the rockers (including researchers, developers and users) who participate in the design, implementation and discussion of big data systems.",
sbrissen/android_device_samsung_l900,,False,False,False,616,79,0,1,25,0,0,0,0,"[2740, 2749, 2752, 2753, 2761, 2763, 2766, 2767, 2769, 2770]",User,Sprint Galaxy Note 2,"{'mk': 8, 'xml': 31, 'png': 1, 'java': 11, 'dependencies': 1, '': 4, 'db': 1, 'conf': 5, 'dat': 1, 'smdk4x12': 1, 'rc': 5, 'c': 4, 'h': 3, 'sh': 1, 'fstab': 1, 'prop': 1}",,,Java,25,2,0,2,0,2777,True,0,0,0,0,0,1,0,0,6,0,0,0,,,51,,
OpenFlutter/Flutter-Notebook,,False,False,False,52496,3496,5816,418,968,11,303,82,3,"[45, 102, 103, 104, 106, 158, 160, 161, 194, 221]",Organization,FlutterDemo合集，今天你fu了吗,"{'': 219, 'yml': 1, 'md': 99, 'png': 1233, 'gif': 3, 'xml': 417, 'gradle': 144, 'java': 47, 'properties': 96, 'jar': 39, 'bat': 39, 'iml': 80, 'plist': 96, 'xcconfig': 96, 'pbxproj': 48, 'xcworkspacedata': 96, 'xcscheme': 48, 'h': 49, 'm': 94, 'json': 96, 'storyboard': 96, 'dart': 256, 'lock': 34, 'yaml': 48, 'xcsettings': 12, 'kt': 2, 'jpg': 2, 'swift': 2, 'arb': 3, 'ttf': 1}",,"{'key': 'apache-2.0', 'name': 'Apache License 2.0', 'spdx_id': 'Apache-2.0', 'url': 'https://api.github.com/licenses/apache-2.0', 'node_id': 'MDc6TGljZW5zZTI='}",Dart,448,1,0,10,2,716,True,1,33,1,1,1,17,1,3,9,0,0,0,29,7,,### [中文版](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/README.md) | [English](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/readme_english.md)þ![](./image/logo.png)þ## flutter_notebook有什么þflutter_note_book有许多flutter相关功能demo的集合，它能够帮助您快速学习一些零碎的知识，本项目将会不定期更新。þþ如果您觉得有用的话可以Watch该项目，之后更新会自动通知您。þ## 收集更多优秀样例þ### 本项目大多为了提供一些问题的解决思路，如果您有更好的实现方式或者好的创意，欢迎提交PR!þ## 如何下载单个项目þ将单个项目下url复制粘贴到下面这个中，将会自动生成下载文件：þþ[DownGit](https://minhaskamal.github.io/DownGit/#/home) þþ## 目前包含以下demo：þ### 官方控件系列þ#### 视图þ- [BottomNavigationBar底部导航](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/flutter_bottomnavigationbar)þ- [BottomAppBar底部导航](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/bottom_appbar_demo)þ- [自定义路由样式](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/custom_router_transition)þ- [高斯模糊（毛玻璃）](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/frosted_glass_style_demo)þ- [切换页面，保持各页面状态](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/keep_alive_demo)þ- [制作一个精美的Material风格搜索框](https://github.com/Vadaski/Flutter-Notebook/tree/master/mecury_project/example/beaytiful_search_bar_demo)þ- [TextField的焦点及动作](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/mecury_project/example/textfields_focus_demo)þ- [微信九宫格效果](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/warp_demo)þ- [标签控件 chip系列](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/chip_demo)þ- [可展开控件 expansion系列](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/mecury_project/example/expansion_demo)þ- [可滑动控件Sliver系列](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/sliver_demo)þ- [使用贝塞尔二阶曲线切割图像](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/clipper_demo)þ- [用户可以通过拖动以交互方式重新排序的项目的列表](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/mecury_project/example/reorderble_listview_demo/)þþ#### 功能þ- [返回上一页时弹出提示信息](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/will_pop_scope_demo)þ- [应用开启进入闪屏页](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/splash_screen_demo)þ- [上拉加载，下拉刷新](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/pull_on_loading)þ- [json自动反序列化](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/flutter_auto_json_parsing)þ- [左滑删除ListView中Item](https://github.com/Vadaski/Flutter-Notebook/blob/master/mecury_project/example/swipe_to_dismiss)þ- [右滑返回上一页](https://github.com/Vadaski/Flutter-Notebook/tree/master/mecury_project/example/right_back_demo)þ- [在flutter中截屏](https://github.com/Vadaski/Flutter-Notebook/tree/master/mecury_project/example/widget_to_image)þ- [轻量级操作提示控件toolstip](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/mecury_project/example/tool_tips_demo)þ- [可拖动组件draggable](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/mecury_project/example/draggable_demo/)þ- [去掉点击事件的水波纹效果](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/without_splash_color)þ- [在当前页面上覆盖新的组件overlay](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/overlay)þ- [在不同页面传递事件EventBus](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/event_bus_demo)þ- [自定义 Navigator](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/navigator_example)þþþ#### 动画þ- [基本动画样例](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/animation_demo)þ- [神奇的Hero动画](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/hero_demo)þ- [AnimatedContainer](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/animated_container)þ- [AnimatedCrossFade](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/animated_cross_fade)þ- [Ripple路由转换动画](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/ripple_animation)þþ### 优秀第三方库þ- [Awesome Flutter Packages](https://github.com/leisim/awesome-flutter-packages)þ- [图表库——google charts📈](https://github.com/google/charts)þ- [闲鱼混合栈管理框架——flutter_boost](https://github.com/alibaba/flutter_boost)þ- [哈啰出行重磅开源混合栈方案——「thrio」](https://github.com/hellobike/thrio)þ- [Agora RTC SDKs 音视频通话](https://github.com/AgoraIO/Flutter-SDK)þ- [应用介绍页——slider](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/slider_screen)þ- [应用介绍页——intro_view](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/intro_views)þ- [从本地相册选取多张图片](https://github.com/Vadaski/Flutter-Notebook/blob/master/mecury_project/example/load_multi_image)þ- [使用url_launcher唤醒功能](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/url_launcher_demo)þ- [拿捏图片放大缩小](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/pinch_zoom_image_demo)þ- [一个很棒的等待动画库——Spinkit](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/spinkit_animation)þþþ### 状态管理þ- [Scoped_Model](https://github.com/Vadaski/Vadaski-flutter_note_book/tree/master/mecury_project/example/scoped_demo)þ- [Redux](https://github.com/Vadaski/Flutter-Notebook/tree/master/mecury_project/example/redux_demo)þ- [BLoC](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/bloc_demo)þ- [BLoC Provider模式](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/bloc_provider_pattern) þ- [Google-Provide](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/flutter_provide)þ- [fish-redux](https://github.com/alibaba/fish-redux)þ- [Provider](https://github.com/OpenFlutter/Flutter-Notebook/blob/master/mecury_project/example/provider_example)þþ### 其他þ- [flutter-widget-livebook 实时查看各种 widget](https://flutter-widget-livebook.blankapp.org/basics/introduction/)þ- [flutter 菜鸟 APP，包含常用 flutter 组件的中文文档与 demo 演示](https://github.com/alibaba/flutter-common-widgets-app)þ- [flutter widget of the week 每周介绍一个widget，轻松学习flutter](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/flutter_widget_of_the_week)þ- [GDD2018最新Flutter preview2 widget体验](https://github.com/Vadaski/Flutter-Notebook/tree/master/mecury_project/example/release_preview2)þ- [Flutter Challenge](https://github.com/OpenFlutter/Flutter-Notebook/tree/master/mecury_project/example/animation_challenge)【持续更新中】þ- [一个漂亮的flutter组件库](https://github.com/samarthagarwal/FlutterScreens)þ- [使用flutter实现超过100个精美的ui页面](https://github.com/nb312/flutter-ui-nice)þ- [flutter应用收集 MADE BY THE FLUTTER社区](https://itsallwidgets.com/)þ- [HistoryOfEverything ———— flutter live上展示的精美应用现已开源](https://github.com/2d-inc/HistoryOfEverything)þþ### 书þ- [Flutter in Action](https://github.com/flutterchina/flutter-in-action)þþ### 常见问题þ- [什么时候我应该使用 Key ](https://juejin.im/post/5ca2152f6fb9a05e1a7a9a26)þ- [什么是 BuildContext](https://juejin.im/post/5c665cb651882562914ec153) þþ所有demo都最简化，尽量保证只与当前功能有关。每个demo文件代码在100行左右，十分适合新手阅读。þ#### 更多请进入mecury_project/example中寻找。þ## [我的掘金主页](https://juejin.im/user/5b5d45f4e51d453526175c06/posts)þ## Stargazers over timeþ[![Stargazers over time](https://starchart.cc/OpenFlutter/Flutter-Notebook.svg)](https://starchart.cc/OpenFlutter/Flutter-Notebook),
federicoiosue/Omni-Notes,,False,False,False,42790,924,2101,156,943,18,1639,1453,2,"[36, 111, 116, 117, 153, 173, 175, 176, 180, 181]",User,Open source note-taking application for Android,"{'': 3, 'yml': 1, 'md': 3, 'txt': 11, 'xcf': 2, 'png': 462, 'scss': 1, 'svg': 4, 'xml': 215, 'gradle': 3, 'properties': 4, 'jar': 1, 'bat': 1, 'java': 196, 'ttf': 3, 'html': 1, 'sql': 12, 'jpg': 1}",https://omninotes.app,"{'key': 'gpl-3.0', 'name': 'GNU General Public License v3.0', 'spdx_id': 'GPL-3.0', 'url': 'https://api.github.com/licenses/gpl-3.0', 'node_id': 'MDc6TGljZW5zZTk='}",Java,3006,18,127,127,13,2448,True,164,481,21,5,16,77,3,1,23,3,0,0,,,224," ![icon](assets/logo.png)þþOmni-Notesþ==========þþ![SLicense](https://img.shields.io/badge/License-GPLv3-red.svg)þ[![Crowdin](https://d322cqt584bo4o.cloudfront.net/omni-notes/localized.png)](https://crowdin.com/project/omni-notes)þ[![Build Status](https://travis-ci.org/federicoiosue/Omni-Notes.svg?branch=develop)](https://travis-ci.org/federicoiosue/Omni-Notes)þ[![Codacy Badge](https://api.codacy.com/project/badge/Grade/8ade707d00ef468fa79d3f6b622444b5)](https://www.codacy.com/app/federico-iosue/Omni-Notes?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=federicoiosue/Omni-Notes&amp;utm_campaign=Badge_Grade)þ[![GitHub release](https://img.shields.io/github/release/federicoiosue/omni-notes.svg)](https://github.com/federicoiosue/Omni-Notes/releases/latest)þþNote taking <b>open-source</b> application aimed to have both a <b>simple interface</b> but keeping <b>smart</b> behavior.þþThe project was inspired by the absence of such applications compatible with old phones and old versions of Android. It aims to provide an attractive look and follow the most recent design guidelines of the Google operating system.þþ**Follow the developments and post your comments and advice on Facebook Community at https://www.facebook.com/OmniNotes**þþ*Help to keep translations updated is always welcome, if you want give a hand checkout the translation project on **https://translate.omninotes.app.** *þþ<a href=""https://f-droid.org/repository/browse/?fdid=it.feio.android.omninotes.foss"" target=""_blank"">þ<img src=""https://f-droid.org/badge/get-it-on.png"" alt=""Get it on F-Droid"" height=""90""/></a>þ<a href=""https://play.google.com/store/apps/details?id=it.feio.android.omninotes"" target=""_blank"">þ<img src=""https://play.google.com/intl/en_us/badges/images/generic/en-play-badge.png"" alt=""Get it on Google Play"" height=""90""/></a>þþ## FeaturesþþCurrently the following functions are implemented:þþ* Material Design interfaceþ  *Basic add, modify, archive, trash and delete notes actionsþ* Share, merge and search notesþ* Image, audio and generic file attachmentsþ* Manage your notes using tags and categoriesþ* To-do listþ* Sketch-note modeþ* Notes shortcut on home screenþ* Export/import notes to backupþ* Google Now integration: just tell ""write a note"" followed by the contentþ* Multiple widgets, DashClock extension, Android 4.2 lockscreen compatibilityþ* Multilanguage: 30+ languages supported: https://crowdin.com/project/omni-notesþþþFurther developments will include:þþ* Notes sychronizationþ* Web interface to manage notes ([stub project](https://github.com/federicoiosue/omni-notes-desktop))þþYou can find a complete changelog inside the application settings menu!þþIf you need some help on how to use the application you'll find everything you need in the [Help Online](assets/help/help.md) section.þþ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/02.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/03.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/04.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/05.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/06.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/07.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/08.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/09.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/10.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/11.png)þ![](https://raw.githubusercontent.com/federicoiosue/Omni-Notes/develop/assets/play_store_pics/12.png)þþ## User guideþþLook into the wiki for GIFs-based tutorials: [LINK](https://github.com/federicoiosue/Omni-Notes/wiki)þþ## BuildþþWatch the following terminal session recording on how to compile distributable filesþ[![asciicast](https://asciinema.org/a/102898.png)](https://asciinema.org/a/102898)þþ## TestþþTo execute all tests included into the project connect a device or emulator, then run the following command:þþ```shellþ./gradlew connectedAndroidTestþ```þþ## ContributingþþDue to the fact that I'm using [gitflow](https://github.com/nvie/gitflow) as code versioning methodology, you as developer should **always** start working on [develop branch](https://github.com/federicoiosue/Omni-Notes/tree/develop) that contains the most recent changes.þþThere are many features/improvements that are not on **my** roadmap but someone else could decide to work on them anyway: hunt for issues tagged as [Help Wanted](https://github.com/federicoiosue/Omni-Notes/issues?utf8=✓&q=label%3A""Help+wanted"") to find them!þþFeel free to add yourself to [contributors.md](https://github.com/federicoiosue/Omni-Notes/blob/develop/contributors.md) file.þþ### New feature or improvements contributionsþþThis kind of contributions **must** have screenshots or screencast as demonstration of the new additions.þþ### Code styleþþIf you plan to manipulate the code then you'll have to do it by following a [specific code style](https://gist.github.com/federicoiosue/dee53e882b3c70d544f8608769eb02fc).þAlso pay attention if you're using any plugin that automatically formats/cleans/rearrange your code and set it to only change that code that you touched and not the whole files.þþ### Test your code contributions!þþAll code changes and additions **must** be tested.þSee the [related section](#test) for more informations or this two pull requests comments: [one](https://github.com/federicoiosue/Omni-Notes/pull/646#pullrequestreview-187973443) and [two](https://github.com/federicoiosue/Omni-Notes/pull/683#issuecomment-506206689)þþ### Forking projectþþWhen forking the project you'll have to modify some files that are strictly dependent from my own development / build / third-party-services environment. Files that need some attention are the following:þþ  - *gradle.properties*: this is overridden by another file with the same name inside the *omniNotes* module. You can do the same or leave as it is, any missing property will let the app gracefully fallback on a default behavior.þ  - *.travis.yml*: if you use [TravisCI](https://travis-ci.org/) as continuous integration platform and a SonarQUBE instance for code quality analysis you'll have to modify this file according to your needs.þþ## Code qualityþþA public instance of SonarQube is available both to encourage other developers to improve their code contributions (and existing code obviously) and to move the project even further into transparency and openness.þþCheckout for it [here](https://sonarcloud.io/dashboard?id=omni-notes)þþPull requests will be automatically analyzed and rejected if they'll rise the code technical debt.þþ## DependenciesþþThey're all listed into the [build.gradle](https://github.com/federicoiosue/Omni-Notes/blob/develop/omniNotes/build.gradle) file but due to the fact that many of the dependences have been customized by me I'd like to say thanks here to the original developers of these great libraries:þþ* https://github.com/RobotiumTech/robotiumþ* https://github.com/flavienlaurent/datetimepickerþ* https://github.com/LarsWerkman/HoloColorPickerþ* https://github.com/keyboardsurfer/Croutonþ* https://github.com/romannurik/dashclock/wiki/APIþ* https://github.com/ACRA/acraþ* https://github.com/Shusshu/Android-RecurrencePickerþ* https://github.com/gabrielemariotti/changeloglibþ* https://github.com/greenrobot/EventBusþ* https://github.com/futuresimple/android-floating-action-buttonþ* https://github.com/keyboardsurferþ* https://github.com/nhaarman/ListViewAnimationsþ* https://github.com/bumptech/glideþ* https://github.com/neopixl/PixlUIþ* https://github.com/afollestad/material-dialogsþ* https://github.com/JakeWharton/butterknifeþ* https://github.com/ical4jþ* https://github.com/square/leakcanaryþ* https://github.com/pnikosis/materialish-progressþ* https://github.com/apl-devs/AppIntroþ* https://github.com/ReactiveX/RxAndroidþ* https://github.com/artem-zinnatullin/RxJavaProGuardRulesþ* https://github.com/tbruyelle/RxPermissionsþ* https://github.com/ocpsoft/prettytimeþ* https://github.com/piwik/piwik-sdk-androidþ* https://github.com/mrmans0n/smart-location-libþþþþ## Developed with love and passion byþþþ* Federico Iosue - [Website](https://federico.iosue.it)þ* [Other contributors](https://github.com/federicoiosue/Omni-Notes/blob/master/https://github.com/federicoiosue/Omni-Notes/blob/master/CONTRIBUTORS.md)þþþþ## Licenseþþþ    Copyright 2013-2019 Federico Iosueþ    þ    This program is free software: you can redistribute it and/or modifyþ    it under the terms of the GNU General Public License as published byþ    the Free Software Foundation, either version 3 of the License, orþ    (at your option) any later version.þ    þ    This program is distributed in the hope that it will be useful,þ    but WITHOUT ANY WARRANTY; without even the implied warranty ofþ    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theþ    GNU General Public License for more details.þ    þ    You should have received a copy of the GNU General Public Licenseþ    along with this program.  If not, see <http://www.gnu.org/licenses/>.",
MiCode/Notes,,False,False,False,3490,147,1709,210,848,0,0,0,0,"[3067, 3076, 3077, 3078, 3105, 3106, 3119]",Organization,小米便签社区开源版（Community edition of XM notepad/MIUI notes),"{'': 5, 'xml': 38, 'png': 65, 'java': 39}",http://micode.net/forum-38-1.html,,Java,21,1,0,3,0,3119,True,1,1,0,0,5,14,0,0,0,0,0,0,68,0,,"[中文]þþ1. MiCode便签是小米便签的社区开源版，由MIUI团队(www.miui.com) 发起并贡献第一批代码，遵循NOTICE文件所描述的开源协议，þ   今后为MiCode社区(www.micode.net) 拥有，并由社区发布和维护。þþ2. Bug反馈和跟踪，请访问Github,þ   https://github.com/MiCode/Notes/issues?sort=created&direction=desc&state=openþþ3. 功能建议和综合讨论，请访问MiCode,þ   http://micode.net/forum.php?mod=forumdisplay&fid=38þþþ[English]þþ1. MiCode Notes is open source edition of XM notepad, it's first initiated and sponsored by MIUI team (www.miui.com).þ   It's opened under license described by NOTICE file. It's owned by the MiCode community (www.micode.net). In future,þ   the MiCode community will release and maintain this project.þþ2. Regarding issue tracking, please visit Github,þ   https://github.com/MiCode/Notes/issues?sort=created&direction=desc&state=openþþ3. Regarding feature request and general discussion, please visit Micode forum,þ   http://micode.net/forum.php?mod=forumdisplay&fid=38",
heibaiying/BigData-Notes,,False,False,False,24065,629,7255,340,2033,18,708,410,2,"[17, 18, 32, 40, 42, 47, 61, 65, 129, 173]",User,大数据入门指南  :star:,"{'': 1, 'md': 101, 'xml': 25, 'java': 69, 'properties': 6, 'txt': 3, 'scala': 8, 'yml': 1, 'png': 380, 'psd': 1, 'jpg': 24, 'xmind': 1, 'csv': 1, 'json': 2, 'jar': 1, 'orc': 1, 'parquet': 2, 'tsv': 2}",,,Java,587,1,0,2,17,489,True,0,16,0,6,0,6,0,2,8,0,0,0,,,237,"# BigData-Notesþþþþ<div align=""center""> <img width=""444px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/bigdata-notes-icon.png""/> </div>þ<br/>þþ**大数据入门指南**þþþþ<table>þ    <tr>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/hadoop.jpg""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/hive.jpg""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/spark.jpg""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/storm.png""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/flink.png""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/hbase.png""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka.png""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/zookeeper.jpg""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/flume.png""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/sqoop.png""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/azkaban.png""></th>þ      <th><img width=""50px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/scala.jpg""></th>þ    </tr>þ    <tr>þ      <td align=""center""><a href=""#一hadoop"">Hadoop</a></td>þ      <td align=""center""><a href=""#二hive"">Hive</a></td>þ      <td align=""center""><a href=""#三spark"">Spark</a></td>þ      <td align=""center""><a href=""#四storm"">Storm</a></td>þ      <td align=""center""><a href=""#五flink"">Flink</a></td>þ      <td align=""center""><a href=""#六hbase"">HBase</a></td>þ      <td align=""center""><a href=""#七kafka"">Kafka</a></td>þ      <td align=""center""><a href=""#八zookeeper"">Zookeeper</a></td>þ      <td align=""center""><a href=""#九flume"">Flume</a></td>þ      <td align=""center""><a href=""#十sqoop"">Sqoop</a></td>þ      <td align=""center""><a href=""#十一azkaban"">Azkaban</a></td>þ      <td align=""center""><a href=""#十二scala"">Scala</a></td>þ    </tr>þ  </table>þ<br/>þþ<div align=""center"">þ <a href = ""https://github.com/heibaiying/Full-Stack-Notes""> þ <img width=""150px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/weixin.jpg""/> þ </a> þ</div>þ<div align=""center""> <strong> 如果需要离线阅读，可以在公众号上发送 “bigdata” 获取《大数据入门指南》离线阅读版！ </strong> </div>þþ<br/>þþ## :black_nib: 前  言þþ1. [大数据学习路线](notes/大数据学习路线.md)þ2. [大数据技术栈思维导图](notes/大数据技术栈思维导图.md)        þ3. [大数据常用软件安装指南](notes/大数据常用软件安装指南.md)þþ## 一、Hadoopþþ1. [分布式文件存储系统 —— HDFS](notes/Hadoop-HDFS.md)þ2. [分布式计算框架 —— MapReduce](notes/Hadoop-MapReduce.md)þ3. [集群资源管理器 —— YARN](notes/Hadoop-YARN.md)þ4. [Hadoop 单机伪集群环境搭建](notes/installation/Hadoop单机环境搭建.md)þ5. [Hadoop 集群环境搭建](notes/installation/Hadoop集群环境搭建.md)þ6. [HDFS 常用 Shell 命令](notes/HDFS常用Shell命令.md)þ7. [HDFS Java API 的使用](notes/HDFS-Java-API.md)þ8. [基于 Zookeeper 搭建 Hadoop 高可用集群](notes/installation/基于Zookeeper搭建Hadoop高可用集群.md)þþ## 二、Hiveþþ1. [Hive 简介及核心概念](notes/Hive简介及核心概念.md)þ2. [Linux 环境下 Hive 的安装部署](notes/installation/Linux环境下Hive的安装部署.md)þ4. [Hive CLI 和 Beeline 命令行的基本使用](notes/HiveCLI和Beeline命令行的基本使用.md)þ6. [Hive 常用 DDL 操作](notes/Hive常用DDL操作.md)þ7. [Hive 分区表和分桶表](notes/Hive分区表和分桶表.md)þ8. [Hive 视图和索引](notes/Hive视图和索引.md)þ9. [Hive 常用 DML 操作](notes/Hive常用DML操作.md)þ10. [Hive 数据查询详解](notes/Hive数据查询详解.md)þþ## 三、Sparkþþ**Spark Core :**þþ1. [Spark 简介](notes/Spark简介.md)þ2. [Spark 开发环境搭建](notes/installation/Spark开发环境搭建.md)þ4. [弹性式数据集 RDD](notes/Spark_RDD.md)þ5. [RDD 常用算子详解](notes/Spark_Transformation和Action算子.md)þ5. [Spark 运行模式与作业提交](notes/Spark部署模式与作业提交.md)þ6. [Spark 累加器与广播变量](notes/Spark累加器与广播变量.md)þ7. [基于 Zookeeper 搭建 Spark 高可用集群](notes/installation/Spark集群环境搭建.md)þþ**Spark SQL :**þþ1. [DateFrame 和 DataSet ](notes/SparkSQL_Dataset和DataFrame简介.md)þ2. [Structured API 的基本使用](notes/Spark_Structured_API的基本使用.md)þ3. [Spark SQL 外部数据源](notes/SparkSQL外部数据源.md)þ4. [Spark SQL 常用聚合函数](notes/SparkSQL常用聚合函数.md)þ5. [Spark SQL JOIN 操作](notes/SparkSQL联结操作.md)þþ**Spark Streaming ：**þþ1. [Spark Streaming 简介](notes/Spark_Streaming与流处理.md)þ2. [Spark Streaming 基本操作](notes/Spark_Streaming基本操作.md)þ3. [Spark Streaming 整合 Flume](notes/Spark_Streaming整合Flume.md)þ4. [Spark Streaming 整合 Kafka](notes/Spark_Streaming整合Kafka.md)þþ## 四、Stormþþ1. [Storm 和流处理简介](notes/Storm和流处理简介.md)þ2. [Storm 核心概念详解](notes/Storm核心概念详解.md)þ3. [Storm 单机环境搭建](notes/installation/Storm单机环境搭建.md)þ4. [Storm 集群环境搭建](notes/installation/Storm集群环境搭建.md)þ5. [Storm 编程模型详解](notes/Storm编程模型详解.md)þ6. [Storm 项目三种打包方式对比分析](notes/Storm三种打包方式对比分析.md)þ7. [Storm 集成 Redis 详解](notes/Storm集成Redis详解.md)þ8. [Storm 集成 HDFS/HBase](notes/Storm集成HBase和HDFS.md)þ9. [Storm 集成 Kafka](notes/Storm集成Kakfa.md)þþ## 五、Flinkþþ1. [Flink 核心概念综述](notes/Flink核心概念综述.md)þ2. [Flink 开发环境搭建](notes/Flink开发环境搭建.md)þ3. [Flink Data Source](notes/Flink_Data_Source.md)þ4. [Flink Data Transformation](notes/Flink_Data_Transformation.md)þ4. [Flink Data Sink](notes/Flink_Data_Sink.md)þ6. [Flink 窗口模型](notes/Flink_Windows.md)þ7. [Flink 状态管理与检查点机制](notes/Flink状态管理与检查点机制.md)þ8. [Flink Standalone 集群部署](notes/installation/Flink_Standalone_Cluster.md)þþþ## 六、HBaseþþ1. [Hbase 简介](notes/Hbase简介.md)þ2. [HBase 系统架构及数据结构](notes/Hbase系统架构及数据结构.md)þ3. [HBase 基本环境搭建 (Standalone /pseudo-distributed mode)](notes/installation/HBase单机环境搭建.md)þ4. [HBase 集群环境搭建](notes/installation/HBase集群环境搭建.md)þ5. [HBase 常用 Shell 命令](notes/Hbase_Shell.md)þ6. [HBase Java API](notes/Hbase_Java_API.md)þ7. [HBase 过滤器详解](notes/Hbase过滤器详解.md)þ8. [HBase 协处理器详解](notes/Hbase协处理器详解.md)þ9. [HBase 容灾与备份](notes/Hbase容灾与备份.md)þ10. [HBase的 SQL 中间层 —— Phoenix](notes/Hbase的SQL中间层_Phoenix.md)þ11. [Spring/Spring Boot 整合 Mybatis + Phoenix](notes/Spring+Mybtais+Phoenix整合.md)þþ## 七、Kafkaþþ1. [Kafka 简介](notes/Kafka简介.md)þ2. [基于 Zookeeper 搭建 Kafka 高可用集群](notes/installation/基于Zookeeper搭建Kafka高可用集群.md)þ3. [Kafka 生产者详解](notes/Kafka生产者详解.md)þ4. [Kafka 消费者详解](notes/Kafka消费者详解.md)þ5. [深入理解 Kafka 副本机制](notes/Kafka深入理解分区副本机制.md)þþ## 八、Zookeeperþþ1. [Zookeeper 简介及核心概念](notes/Zookeeper简介及核心概念.md)þ2. [Zookeeper 单机环境和集群环境搭建](notes/installation/Zookeeper单机环境和集群环境搭建.md) þ3. [Zookeeper 常用 Shell 命令](notes/Zookeeper常用Shell命令.md)þ4. [Zookeeper Java 客户端 —— Apache Curator](notes/Zookeeper_Java客户端Curator.md)þ5. [Zookeeper  ACL 权限控制](notes/Zookeeper_ACL权限控制.md)þþ## 九、Flumeþþ1. [Flume 简介及基本使用](notes/Flume简介及基本使用.md)þ2. [Linux 环境下 Flume 的安装部署](notes/installation/Linux下Flume的安装.md)þ3. [Flume 整合 Kafka](notes/Flume整合Kafka.md)þþ## 十、Sqoopþþ1. [Sqoop 简介与安装](notes/Sqoop简介与安装.md)þ2. [Sqoop 的基本使用](notes/Sqoop基本使用.md)þþ## 十一、Azkabanþþ1. [Azkaban 简介](notes/Azkaban简介.md)þ2. [Azkaban3.x 编译及部署](notes/installation/Azkaban_3.x_编译及部署.md)þ3. [Azkaban Flow 1.0 的使用](notes/Azkaban_Flow_1.0_的使用.md)þ4. [Azkaban Flow 2.0 的使用](notes/Azkaban_Flow_2.0_的使用.md)þþ## 十二、Scalaþþ1. [Scala 简介及开发环境配置](notes/Scala简介及开发环境配置.md)þ2. [基本数据类型和运算符](notes/Scala基本数据类型和运算符.md)þ3. [流程控制语句](notes/Scala流程控制语句.md)þ4. [数组 —— Array](notes/Scala数组.md)þ5. [集合类型综述](notes/Scala集合类型.md)þ6. [常用集合类型之 —— List & Set](notes/Scala列表和集.md)þ7. [常用集合类型之 —— Map & Tuple](notes/Scala映射和元组.md)þ8. [类和对象](notes/Scala类和对象.md)þ9. [继承和特质](notes/Scala继承和特质.md)þ10. [函数 & 闭包 & 柯里化](notes/Scala函数和闭包.md)þ11. [模式匹配](notes/Scala模式匹配.md)þ12. [类型参数](notes/Scala类型参数.md)þ13. [隐式转换和隐式参数](notes/Scala隐式转换和隐式参数.md)þþ## 十三、公共内容þþ1. [大数据应用常用打包方式](notes/大数据应用常用打包方式.md)þþ<br>þþ## :bookmark_tabs: 后  记þþ[资料分享与开发工具推荐](notes/资料分享与工具推荐.md)þþ<br>þþ<div align=""center"">þ <a href = ""https://blog.csdn.net/m0_37809146""> þ <img width=""200px"" src=""https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/blog-logo.png""/> þ </a> þ</div>þ<div align=""center""> <a  href = ""https://blog.csdn.net/m0_37809146""> 欢迎关注我的博客：https://blog.csdn.net/m0_37809146</a> </div>",
system-design-primer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Not Found
scalad/Note,,False,False,False,14533,270,1532,139,746,0,0,0,0,"[461, 1043, 1046, 1057, 1058, 1061, 1072, 1091, 1154, 1171]",User,常规Java工具，算法，加密，数据库，面试题，源代码分析，解决方案,"{'png': 117, 'md': 93, 'jpg': 41, 'txt': 4, 'gif': 9, 'zip': 1, '': 2, 'java': 3}",,,Java,303,1,0,3,5,1404,True,5,1,0,1,0,1,0,0,7,0,0,0,,,205,### 常规Java工具，算法，加密，数据库，面试题，源代码分析，解决方案þ<br>þþ有家杂志曾对全国60岁以上的老人进行了这样一次问卷调查:你最后悔什么?þþ列出10项人们生活中容易后悔的事情，供被调查者选择，回收有效问卷并进行统计分析后，竟得出了这样的结果。þþ**第一名:年轻时不够努力，导致一事无成(75%)**þþ![](https://github.com/silence940109/Java/blob/master/image/desktop1.jpg)þþ所谓少壮不努力，老大徒伤悲。青春岁月里，又常常碰到那么多的诱惑甚至陷阱，当你猛然醒悟时，也许白发早生，竟然一事无成。þþ趁着你还有时间、有精力、有体力，赶快制定一个切实可行的计划，然后开始百折不挠一路向前，老来回忆，少些遗憾。þþ**第二名:年轻的时候选错了职业(70%)**þþ![](https://github.com/silence940109/Java/blob/master/image/desktop2.jpg)þþ三个大学生被同时分配到某机关工作，一年后，其中一个由于不甘心整天看主管脸色，跳槽到另一家企业去了，另外两位依旧安稳地过着朝九晚五的日子。又一年后，另外一个学生决定辞职下海，剩下那个依然没有动心。þþ若干年后，三人相聚，到企业去的那位同学成了高管，下海的那位成了千万富翁，而留在机关的那位却依旧在领导的呵斥声中消磨着自己所剩无几的“大好时光”。þþ许多人在选择职业时考虑的第一因素就是稳定的收入和安稳舒适的生活，而不太愿意去面对那些具有挑战性的机会。没有了压力，自然就缺乏了动力，没有了动力，也就埋没了潜力。þþ**第三名:对子女教育不当(62%)**þþ![](https://github.com/silence940109/Java/blob/master/image/desktop13.jpg)þþ孩子是自己生命、希望的延续，许多人为了孩子可以倾尽所有，但望子成龙、盼女成凤可能只是父母单方面的良好愿望。对于儿女而言，他们也许只是想做一个简单快乐的平凡人。þþ许多父母采取了强制、监督甚至棍棒等方式来逼迫孩子按照自己设计的线路发展。可到最后，多数父母却不得不在对现实感到失望，只有极少数所谓的“成功者”例外。他们也不由地感叹孩子这些年过得太苦，没有享受到应有的快乐与阳光。þþ**第四名:没好好珍惜自己的伴侣(57%)**þþ![](https://github.com/silence940109/Java/blob/master/image/desktop4.jpg)þþ醉过方知酒浓，爱过方知情重。感情，总是拥有时不懂得珍惜，失去后才知道珍贵。人类永远发明不出的两种物质，一是忘情水，二是后悔药。年轻的时候不去珍惜、体谅和理解，待到年老时，后悔已经来不及。þþ**第五名:没有善待自己的身体(49%)**þþ![](https://github.com/silence940109/Java/blob/master/image/desktop5.jpg)þþ“身体是革命的本钱”，这句话永远都不会过时，许多人在60岁前用身体去换取一切，在60岁以后又用一切去换取身体的健康。þþ世界上没有什么东西比自己的健康更加重要，没有一个好的身体，纵有千万家产又如何?,
jesseseligman/notebook,,False,False,False,6,6,0,1,0,0,0,0,0,"[1528, 1529]",User,notes notes notes,"{'': 1, 'txt': 4, 'md': 1}",,,,12,1,0,0,0,1529,True,0,0,0,0,0,0,0,0,7,0,0,0,,,6,,
abimiller15/netart_notes,,False,False,False,29,27,0,0,0,0,0,0,0,[640],User,notes notes notes notes wooo,"{'md': 6, 'txt': 5, 'bmp': 1, 'raw': 1, 'xml': 1, 'html': 2, 'png': 1, 'css': 1, 'out': 1, 'c': 1, 'php': 1, 'py': 1, 'js': 4, '': 1}",,,JavaScript,2,1,0,0,0,640,True,0,0,0,0,0,0,0,0,8,0,0,0,,,0,# netart_notesþnotes notes notes notes wooo,
Hvass-Labs/TensorFlow-Tutoria,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Not Found
enoch11/hello-world,,False,False,False,1,1,0,1,0,0,0,0,0,[1515],User,notes on notes on notes,{'md': 1},,,,4,2,0,0,0,1515,True,0,0,0,0,0,1,0,0,7,0,0,0,,,0,"# hello-worldþnotes on notes on notesþthis is some stuff about myself, I'm trying to get better at flying.",
lijin-THU/notes-python,,False,False,False,11695,174,5642,543,2756,0,0,0,0,"[58, 225, 226, 765, 771, 799, 816, 831, 833, 834]",User,中文 Python 笔记,"{'': 2, 'ipynb': 144, 'txt': 4, 'sqlite': 1, 'png': 8, 'zip': 5, 'c': 1, 'html': 1, 'pyx': 1, 'py': 4, 'md': 2, 'jpeg': 1}",,,Jupyter Notebook,101,1,0,2,6,1738,True,9,9,2,0,2,4,0,0,7,0,0,0,,,1,"[![Analytics](https://ga-beacon.appspot.com/UA-80121379-2/notes-python)](https://github.com/lijin-thu/notes-python)þþ# 中文 Python 笔记þþ> 版本：0.0.1<br>þ> 作者：李金<br>þ> 邮件：lijinwithyou@gmail.com<br>þþ由于涉及著作权的问题，对基于本笔记所做的修订、改编，目前不做任何正式授权。þþ笔记内容仅供学习参考，未经允许，请勿用于任何商业用途。þþ`Github` 加载 `.ipynb` 的速度较慢，建议在 [Nbviewer](http://nbviewer.ipython.org/github/lijin-THU/notes-python/blob/master/index.ipynb) 中查看该项目。þþ基于本笔记的实体书：《自学Python——编程基础、科学计算及数据分析》已经出版。þþ京东自营链接：þhttps://item.jd.com/12328920.htmlþþ天猫、亚马逊、当当均有销售。þþ**打赏一下意思意思？**þþ![](payment.jpeg)þþ---þþ## 简介þþ大部分内容来自网络。þþ默认安装了 `Python 2.7`，以及相关的第三方包 `ipython`， `numpy`， `scipy`，`pandas`。þþ> life is short. use python.þþ推荐使用 [Anaconda](http://www.continuum.io/downloads)，这个IDE集成了大部分常用的包。þþ笔记内容使用 `jupyter notebook` 来展示。þþ安装好 `Python` 和相应的包之后，可以在命令行下输入：þþ```þ$ jupyter notebookþ```þ来进入 `jupyter notebook`。þþ----þþ## 基本环境配置þþ- 安装 [Anaconda](http://www.continuum.io/downloads) 或者 [Miniconda](http://conda.pydata.org/miniconda.html)þþ- 更新环境þ``` þconda update condaþconda update anacondaþ```þþ---þþ## 参考þþ- [Enthought Training on Demand](https://training.enthought.com/)þ- [Computational Statistics in Python](http://people.duke.edu/~ccc14/sta-663/index.html#rd)þ- [Scipy.org](http://scipy.org/)þ- [Deep Learning Tutorials](http://deeplearning.net/tutorial/)þ- [High Performance Scientific Computing](http://faculty.washington.edu/rjl/uwhpsc-coursera/index.html)þ- [Scipy Lectures](http://www.scipy-lectures.org/)þ- [Pandas.org](http://pandas.pydata.org/pandas-docs/stable/index.html)þþ----þþ## 目录þþ可以在 Notebook 中打开 `generate static files.ipynb`，或者命令行中运行代码 `generate_static_files.py` 来生成静态的 HTML 文件。þþ---þþ- [01. **Python 工具**](01-python-tools)þ  - [01.01 Python 简介](01-python-tools/01.01-python-overview.ipynb)þ  - [01.02 Ipython 解释器](01-python-tools/01.02-ipython-interpreter.ipynb)þ  - [01.03 Ipython notebook](01-python-tools/01.03-ipython-notebook.ipynb)þ  - [01.04 使用 Anaconda](01-python-tools/01.04-use-anaconda.ipynb)þ- [02. **Python 基础**](02-python-essentials)þ  - [02.01 Python 入门演示](02-python-essentials/02.01-a-tour-of-python.ipynb)þ  - [02.02 Python 数据类型](02-python-essentials/02.02-python-data-types.ipynb)þ  - [02.03 数字](02-python-essentials/02.03-numbers.ipynb)þ  - [02.04 字符串](02-python-essentials/02.04-strings.ipynb)þ  - [02.05 索引和分片](02-python-essentials/02.05-indexing-and-slicing.ipynb)þ  - [02.06 列表](02-python-essentials/02.06-lists.ipynb)þ  - [02.07 可变和不可变类型](02-python-essentials/02.07-mutable-and-immutable-data-types.ipynb)þ  - [02.08 元组](02-python-essentials/02.08-tuples.ipynb)þ  - [02.09 列表与元组的速度比较](02-python-essentials/02.09-speed-comparison-between-list-&-tuple.ipynb)þ  - [02.10 字典](02-python-essentials/02.10-dictionaries.ipynb)þ  - [02.11 集合](02-python-essentials/02.11-sets.ipynb)þ  - [02.12 不可变集合](02-python-essentials/02.12-frozen-sets.ipynb)þ  - [02.13 Python 赋值机制](02-python-essentials/02.13-how-python-assignment-works.ipynb)þ  - [02.14 判断语句](02-python-essentials/02.14-if-statement.ipynb)þ  - [02.15 循环](02-python-essentials/02.15-loops.ipynb)þ  - [02.16 列表推导式](02-python-essentials/02.16-list-comprehension.ipynb)þ  - [02.17 函数](02-python-essentials/02.17-functions.ipynb)þ  - [02.18 模块和包](02-python-essentials/02.18-modules-and-packages.ipynb)þ  - [02.19 异常](02-python-essentials/02.19-exceptions.ipynb)þ  - [02.20 警告](02-python-essentials/02.20-warnings.ipynb)þ  - [02.21 文件读写](02-python-essentials/02.21-file-IO.ipynb)þ- [03. **Numpy**](03-numpy)þ  - [03.01 Numpy 简介](03-numpy/03.01-numpy-overview.ipynb)þ  - [03.02 Matplotlib 基础](03-numpy/03.02-matplotlib-basics.ipynb)þ  - [03.03 Numpy 数组及其索引](03-numpy/03.03-numpy-arrays.ipynb)þ  - [03.04 数组类型](03-numpy/03.04-array-types.ipynb)þ  - [03.05 数组方法](03-numpy/03.05-array-calculation-method.ipynb)þ  - [03.06 数组排序](03-numpy/03.06-sorting-numpy-arrays.ipynb)þ  - [03.07 数组形状](03-numpy/03.07-array-shapes.ipynb)þ  - [03.08 对角线](03-numpy/03.08-diagonals.ipynb)þ  - [03.09 数组与字符串的转换](03-numpy/03.09-data-to-&-from-string.ipynb)þ  - [03.10 数组属性方法总结](03-numpy/03.10-array-attribute-&-method-overview-.ipynb)þ  - [03.11 生成数组的函数](03-numpy/03.11-array-creation-functions.ipynb)þ  - [03.12 矩阵](03-numpy/03.12-matrix-object.ipynb)þ  - [03.13 一般函数](03-numpy/03.13-general-functions.ipynb)þ  - [03.14 向量化函数](03-numpy/03.14-vectorizing-functions.ipynb)þ  - [03.15 二元运算](03-numpy/03.15-binary-operators.ipynb)þ  - [03.16 ufunc 对象](03-numpy/03.16-universal-functions.ipynb)þ  - [03.17 choose 函数实现条件筛选](03-numpy/03.17-choose.ipynb)þ  - [03.18 数组广播机制](03-numpy/03.18-array-broadcasting.ipynb)þ  - [03.19 数组读写](03-numpy/03.19-reading-and-writing-arrays.ipynb)þ  - [03.20 结构化数组](03-numpy/03.20-structured-arrays.ipynb)þ  - [03.21 记录数组](03-numpy/03.21-record-arrays.ipynb)þ  - [03.22 内存映射](03-numpy/03.22-memory-maps.ipynb)þ  - [03.23 从 Matlab 到 Numpy](03-numpy/03.23-from-matlab-to-numpy.ipynb)þ- [04. **Scipy**](04-scipy)þ  - [04.01 SCIentific PYthon 简介](04-scipy/04.01-scienticfic-python-overview.ipynb)þ  - [04.02 插值](04-scipy/04.02-interpolation-with-scipy.ipynb)þ  - [04.03 概率统计方法](04-scipy/04.03-statistics-with-scipy.ipynb)þ  - [04.04 曲线拟合](04-scipy/04.04-curve-fitting.ipynb)þ  - [04.05 最小化函数](04-scipy/04.05-minimization-in-python.ipynb)þ  - [04.06 积分](04-scipy/04.06-integration-in-python.ipynb)þ  - [04.07 解微分方程](04-scipy/04.07-ODEs.ipynb)þ  - [04.08 稀疏矩阵](04-scipy/04.08-sparse-matrix.ipynb)þ  - [04.09 线性代数](04-scipy/04.09-linear-algbra.ipynb)þ  - [04.10 稀疏矩阵的线性代数](04-scipy/04.10-sparse-linear-algebra.ipynb)þ- [05. **Python 进阶**](05-advanced-python)þ  - [05.01 sys 模块简介](05-advanced-python/05.01-overview-of-the-sys-module.ipynb)þ  - [05.02 与操作系统进行交互：os 模块](05-advanced-python/05.02-interacting-with-the-OS---os.ipynb)þ  - [05.03 CSV 文件和 csv 模块](05-advanced-python/05.03-comma-separated-values.ipynb)þ  - [05.04 正则表达式和 re 模块](05-advanced-python/05.04-regular-expression.ipynb)þ  - [05.05 datetime 模块](05-advanced-python/05.05-datetime.ipynb)þ  - [05.06 SQL 数据库](05-advanced-python/05.06-sql-databases.ipynb)þ  - [05.07 对象关系映射](05-advanced-python/05.07-object-relational-mappers.ipynb)þ  - [05.08 函数进阶：参数传递，高阶函数，lambda 匿名函数，global 变量，递归](05-advanced-python/05.08-functions.ipynb)þ  - [05.09 迭代器](05-advanced-python/05.09-iterators.ipynb)þ  - [05.10 生成器](05-advanced-python/05.10-generators.ipynb)þ  - [05.11 with 语句和上下文管理器](05-advanced-python/05.11-context-managers-and-the-with-statement.ipynb)þ  - [05.12 修饰符](05-advanced-python/05.12-decorators.ipynb)þ  - [05.13 修饰符的使用](05-advanced-python/05.13-decorator-usage.ipynb)þ  - [05.14 operator, functools, itertools, toolz, fn, funcy 模块](05-advanced-python/05.14-the-operator-functools-itertools-toolz-fn-funcy-module.ipynb)þ  - [05.15 作用域](05-advanced-python/05.15-scope.ipynb)þ  - [05.16 动态编译](05-advanced-python/05.16-dynamic-code-execution.ipynb)þ- [06. **Matplotlib**](06-matplotlib)þ  - [06.01 Pyplot 教程](06-matplotlib/06.01-pyplot-tutorial.ipynb)þ  - [06.02 使用 style 来配置 pyplot 风格](06-matplotlib/06.02-customizing-plots-with-style-sheets.ipynb)þ  - [06.03 处理文本（基础）](06-matplotlib/06.03-working-with-text---basic.ipynb)þ  - [06.04 处理文本（数学表达式）](06-matplotlib/06.04-working-with-text---math-expression.ipynb)þ  - [06.05 图像基础](06-matplotlib/06.05-image-tutorial.ipynb)þ  - [06.06 注释](06-matplotlib/06.06-annotating-axes.ipynb)þ  - [06.07 标签](06-matplotlib/06.07-legend.ipynb)þ  - [06.08 figures, subplots, axes 和 ticks 对象](06-matplotlib/06.08-figures,-subplots,-axes-and-ticks.ipynb)þ  - [06.09 不要迷信默认设置](06-matplotlib/06.09-do-not-trust-the-defaults.ipynb)þ  - [06.10 各种绘图实例](06-matplotlib/06.10-different-plots.ipynb)þ- [07. **使用其他语言进行扩展**](07-interfacing-with-other-languages)þ  - [07.01 简介](07-interfacing-with-other-languages/07.01-introduction.ipynb)þ  - [07.02 Python 扩展模块](07-interfacing-with-other-languages/07.02-python-extension-modules.ipynb)þ  - [07.03 Cython：Cython 基础，将源代码转换成扩展模块](07-interfacing-with-other-languages/07.03-cython-part-1.ipynb)þ  - [07.04 Cython：Cython 语法，调用其他C库](07-interfacing-with-other-languages/07.04-cython-part-2.ipynb)þ  - [07.05 Cython：class 和 cdef class，使用 C++](07-interfacing-with-other-languages/07.05-cython-part-3.ipynb)þ  - [07.06 Cython：Typed memoryviews](07-interfacing-with-other-languages/07.06-cython-part-4.ipynb)þ  - [07.07 生成编译注释](07-interfacing-with-other-languages/07.07-profiling-with-annotations.ipynb)þ  - [07.08 ctypes](07-interfacing-with-other-languages/07.08-ctypes.ipynb)þ- [08. **面向对象编程**](08-object-oriented-programming)þ  - [08.01 简介](08-object-oriented-programming/08.01-oop-introduction.ipynb)þ  - [08.02 使用 OOP 对森林火灾建模](08-object-oriented-programming/08.02-using-oop-model-a-forest-fire.ipynb)þ  - [08.03 什么是对象？](08-object-oriented-programming/08.03-what-is-a-object.ipynb)þ  - [08.04 定义 class](08-object-oriented-programming/08.04-writing-classes.ipynb)þ  - [08.05 特殊方法](08-object-oriented-programming/08.05-special-method.ipynb)þ  - [08.06 属性](08-object-oriented-programming/08.06-properties.ipynb)þ  - [08.07 森林火灾模拟](08-object-oriented-programming/08.07-forest-fire-simulation.ipynb)þ  - [08.08 继承](08-object-oriented-programming/08.08-inheritance.ipynb)þ  - [08.09 super() 函数](08-object-oriented-programming/08.09-super.ipynb)þ  - [08.10 重定义森林火灾模拟](08-object-oriented-programming/08.10-refactoring-the-forest-fire-simutation.ipynb)þ  - [08.11 接口](08-object-oriented-programming/08.11-interfaces.ipynb)þ  - [08.12 共有，私有和特殊方法和属性](08-object-oriented-programming/08.12-public-private-special-in-python.ipynb)þ  - [08.13 多重继承](08-object-oriented-programming/08.13-multiple-inheritance.ipynb)þ- [09. **Theano 基础**](09-theano)þ  - [09.01 Theano 简介及其安装](09-theano/09.01-introduction-and-installation.ipynb)þ  - [09.02 Theano 基础](09-theano/09.02-theano-basics.ipynb)þ  - [09.03 Theano 在 Windows 上的配置](09-theano/09.03-gpu-on-windows.ipynb)þ  - [09.04 Theano 符号图结构](09-theano/09.04-graph-structures.ipynb)þ  - [09.05 Theano 配置和编译模式](09-theano/09.05-configuration-settings-and-compiling-modes.ipynb)þ  - [09.06 Theano 条件语句](09-theano/09.06-conditions-in-theano.ipynb)þ  - [09.07 Theano 循环：scan（详解）](09-theano/09.07-loop-with-scan.ipynb)þ  - [09.08 Theano 实例：线性回归](09-theano/09.08-linear-regression.ipynb)þ  - [09.09 Theano 实例：Logistic 回归](09-theano/09.09-logistic-regression-.ipynb)þ  - [09.10 Theano 实例：Softmax 回归](09-theano/09.10-softmax-on-mnist.ipynb)þ  - [09.11 Theano 实例：人工神经网络](09-theano/09.11-net-on-mnist.ipynb)þ  - [09.12 Theano 随机数流变量](09-theano/09.12-random-streams.ipynb)þ  - [09.13 Theano 实例：更复杂的网络](09-theano/09.13-modern-net-on-mnist.ipynb)þ  - [09.14 Theano 实例：卷积神经网络](09-theano/09.14-convolutional-net-on-mnist.ipynb)þ  - [09.15 Theano tensor 模块：基础](09-theano/09.15-tensor-basics.ipynb)þ  - [09.16 Theano tensor 模块：索引](09-theano/09.16-tensor-indexing.ipynb)þ  - [09.17 Theano tensor 模块：操作符和逐元素操作](09-theano/09.17-tensor-operator-and-elementwise-operations.ipynb)þ  - [09.18 Theano tensor 模块：nnet 子模块](09-theano/09.18-tensor-nnet-.ipynb)þ  - [09.19 Theano tensor 模块：conv 子模块](09-theano/09.19-tensor-conv.ipynb)þ- [10. **有趣的第三方模块**](10-something-interesting)þ  - [10.01 使用 basemap 画地图](10-something-interesting/10.01-maps-using-basemap.ipynb)þ  - [10.02 使用 cartopy 画地图](10-something-interesting/10.02-maps-using-cartopy.ipynb)þ  - [10.03 探索 NBA 数据](10-something-interesting/10.03-nba-data.ipynb)þ  - [10.04 金庸的武侠世界](10-something-interesting/10.04-louis-cha's-kungfu-world.ipynb)þ- [11. **有用的工具**](11-useful-tools)þ  - [11.01 pprint 模块：打印 Python 对象](11-useful-tools/11.01-pprint.ipynb)þ  - [11.02 pickle, cPickle 模块：序列化 Python 对象](11-useful-tools/11.02-pickle-and-cPickle.ipynb)þ  - [11.03 json 模块：处理 JSON 数据](11-useful-tools/11.03-json.ipynb)þ  - [11.04 glob 模块：文件模式匹配](11-useful-tools/11.04-glob.ipynb)þ  - [11.05 shutil 模块：高级文件操作](11-useful-tools/11.05-shutil.ipynb)þ  - [11.06 gzip, zipfile, tarfile 模块：处理压缩文件](11-useful-tools/11.06-gzip,-zipfile,-tarfile.ipynb)þ  - [11.07 logging 模块：记录日志](11-useful-tools/11.07-logging.ipynb)þ  - [11.08 string 模块：字符串处理](11-useful-tools/11.08-string.ipynb)þ  - [11.09 collections 模块：更多数据结构](11-useful-tools/11.09-collections.ipynb)þ  - [11.10 requests 模块：HTTP for Human](11-useful-tools/11.10-requests.ipynb)þ- [12. **Pandas**](12-pandas)þ  - [12.01 十分钟上手 Pandas](12-pandas/12.01-ten-minutes-to-pandas.ipynb)þ  - [12.02 一维数据结构：Series](12-pandas/12.02-series-in-pandas.ipynb)þ  - [12.03 二维数据结构：DataFrame](12-pandas/12.03-dataframe-in-pandas.ipynb)",
notepad-plus-plus/notepad-plus-plus,,False,False,False,184885,1138,11201,604,2792,201,10538,6610,35,"[3, 4, 7, 9, 11, 13, 18, 19, 20, 21]",Organization,Notepad++ official repository,"{'': 32, 'md': 4, 'result': 18, 'xsd': 1, 'ps1': 1, 'lastcodeanalysissucceeded': 1, 'dll': 2, 'log': 1, 'xml': 148, 'txt': 14, 'h': 248, 'rc': 29, 'exe': 1, 'psd': 1, 'bmp': 62, 'ico': 97, 'nsi': 1, 'nsh': 10, 'bat': 3, 'png': 13, 'eps': 1, '7z': 1, 'cpp': 131, 'cur': 4, 'manifest': 2, 'old': 3, 'hpp': 2, 'cbp': 1, 'sln': 1, 'vcproj': 2, 'def': 2, 'tab': 5, 'vcxproj': 3, 'yml': 1, 'asc': 1, 'cxx': 179, 'mak': 6, 'mm': 5, 'plist': 3, 'pbxproj': 2, 'xcworkspacedata': 2, 'pch': 2, 'strings': 2, 'modulemap': 1, 'sql': 1, 'xib': 1, 'm': 1, 'sh': 1, 'html': 14, 'jpg': 3, 'py': 29, 'c': 1, 'list': 1, 'iface': 1, 'template': 4, 'pro': 3, 'properties': 3, 'pl': 3, 'styled': 14, 'asp': 1, 'lua': 1, 'nim': 1, 'php': 1, 'rb': 1, 'tcl': 1, 'vb': 1, 'good': 1, 'natvis': 1}",https://notepad-plus-plus.org/,"{'key': 'other', 'name': 'Other', 'spdx_id': 'NOASSERTION', 'url': None, 'node_id': 'MDc6TGljZW5zZTA='}",C++,3521,1,178,178,4,4722,True,1236,4525,259,250,32,1856,12,171,30,3,0,0,5,2,,"What is Notepad++ ?þ===================þþ[![GitHub release](https://img.shields.io/github/release/notepad-plus-plus/notepad-plus-plus.svg)](../../releases/latest)þ&nbsp;&nbsp;&nbsp;&nbsp;[![Appveyor build status](https://ci.appveyor.com/api/projects/status/github/notepad-plus-plus/notepad-plus-plus?branch=master&svg=true)](https://ci.appveyor.com/project/donho/notepad-plus-plus)þ&nbsp;&nbsp;&nbsp;&nbsp;[![Join the disscussions at https://community.notepad-plus-plus.org/](https://notepad-plus-plus.org/assets/images/NppCommunityBadge.svg)](https://community.notepad-plus-plus.org/)þ&nbsp;&nbsp;&nbsp;&nbsp;[![Join the chat at https://gitter.im/notepad-plus-plus/notepad-plus-plus](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/notepad-plus-plus/notepad-plus-plus?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)þþNotepad++ is a free (free as in both ""free speech"" and ""free beer"") source codeþeditor and Notepad replacement that supports several programming languages andþnatural languages. Running in the MS Windows environment, its use is governed byþ[GPL License](LICENSE).þþSee the [Notepad++ official site](https://notepad-plus-plus.org/) for more information.þþNotepad++ Release Keyþ---------------------þ_Since the release of version 7.6.5 Notepad++ is signed using GPG with the following key:_þþ- **Signer:** Notepad++þ- **E-mail:** don.h@free.frþ- **Key ID:** 0x8D84F46Eþ- **Key fingerprint:** 14BC E436 2749 B2B5 1F8C 7122 6C42 9F1D 8D84 F46Eþ- **Key type:** RSA 4096/4096þ- **Created:** 2019-03-11þ- **Expiries:** 2021-03-10þþhttps://github.com/notepad-plus-plus/notepad-plus-plus/blob/master/nppGpgPub.ascþþþBuild Notepad++þ---------------þþPlease follow [build guide](BUILD.md) to build Notepad++ from source.þþþContributionþ------------þþCode contribution is welcome. Here are some [rules](CONTRIBUTING.md) that your should follow to make your contribution accepted easily. þþ[Notepad++ Contributors](https://github.com/notepad-plus-plus/notepad-plus-plus/graphs/contributors)",
yunjey/pytorch-tutorial,,False,False,False,13110,45,17344,562,5566,6,6,11,1,"[5, 25, 40, 75, 166, 300, 319, 453, 486, 503]",User,PyTorch Tutorial for Deep Learning Researchers,"{'': 2, 'md': 4, 'png': 11, 'svg': 1, 'py': 21, 'txt': 4, 'sh': 1, 'gif': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",Python,173,1,0,27,4,1219,True,49,109,7,1,16,39,5,0,7,0,0,0,,,2,"<p align=""center""><img width=""40%"" src=""logo/pytorch_logo_2018.svg"" /></p>þþ--------------------------------------------------------------------------------þþThis repository provides tutorial code for deep learning researchers to learn [PyTorch](https://github.com/pytorch/pytorch). In the tutorial, most of the models were implemented with less than 30 lines of code. Before starting this tutorial, it is recommended to finish [Official Pytorch Tutorial](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).þþþ<br/>þþ## Table of Contentsþþ#### 1. Basicsþ* [PyTorch Basics](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/pytorch_basics/main.py)þ* [Linear Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/linear_regression/main.py#L22-L23)þ* [Logistic Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/logistic_regression/main.py#L33-L34)þ* [Feedforward Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49)þþ#### 2. Intermediateþ* [Convolutional Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/convolutional_neural_network/main.py#L35-L56)þ* [Deep Residual Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/deep_residual_network/main.py#L76-L113)þ* [Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L39-L58)þ* [Bidirectional Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/bidirectional_recurrent_neural_network/main.py#L39-L58)þ* [Language Model (RNN-LM)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model/main.py#L30-L50)þþ#### 3. Advancedþ* [Generative Adversarial Networks](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.py#L41-L57)þ* [Variational Auto-Encoder](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65)þ* [Neural Style Transfer](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/neural_style_transfer)þ* [Image Captioning (CNN-RNN)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning)þþ#### 4. Utilitiesþ* [TensorBoard in PyTorch](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard)þþþ<br/>þþ## Getting Startedþ```bashþ$ git clone https://github.com/yunjey/pytorch-tutorial.gitþ$ cd pytorch-tutorial/tutorials/PATH_TO_PROJECTþ$ python main.pyþ```þþ<br/>þþ## Dependenciesþ* [Python 2.7 or 3.5+](https://www.continuum.io/downloads)þ* [PyTorch 0.4.0+](http://pytorch.org/)",
futurepress/epub.js,,False,False,False,26266,184,3795,189,774,31,15167,18664,8,"[10, 11, 14, 20, 23, 24, 32, 35, 36, 38]",Organization,Enhanced eBooks in the browser.,"{'json': 6, 'js': 53, '': 7, 'yml': 2, 'md': 2, 'gif': 1, 'html': 27, 'css': 4, 'epub': 2, 'xml': 1, 'xhtml': 17, 'jpg': 28, 'opf': 1, 'ts': 33}",http://futurepress.org,"{'key': 'other', 'name': 'Other', 'spdx_id': 'NOASSERTION', 'url': None, 'node_id': 'MDc6TGljZW5zZTA='}",JavaScript,1239,39,31,31,1,2814,True,300,523,42,19,0,276,0,20,26,1,969,30,21,1,,"# Epub.js v0.3þþ![FuturePress Views](http://fchasen.com/futurepress/fp.png)þþEpub.js is a JavaScript library for rendering ePub documents in the browser, across many devices.þþEpub.js provides an interface for common ebook functions (such as rendering, persistence and pagination) without the need to develop a dedicated application or plugin. Importantly, it has an incredibly permissive [Free BSD](http://en.wikipedia.org/wiki/BSD_licenses) license.þþ[Try it while reading Moby Dick](https://futurepress.github.io/epubjs-reader/)þþ## Why EPUBþþ![Why EPUB](http://fchasen.com/futurepress/whyepub.png)þþThe [EPUB standard](http://www.idpf.org/epub/30/spec/epub30-overview.html) is a widely used and easily convertible format. Many books are currently in this format, and it is convertible to many other formats (such as PDF, Mobi and iBooks).þþAn unzipped EPUB3 is a collection of HTML5 files, CSS, images and other media – just like any other website. However, it enforces a schema of book components, which allows us to render a book and its parts based on a controlled vocabulary.þþMore specifically, the EPUB schema standardizes the table of contents, provides a manifest that enables the caching of the entire book, and separates the storage of the content from how it’s displayed.þþ## Getting StartedþþGet the minified code from the build folder:þþ```htmlþ<script src=""../dist/epub.min.js""></script>þ```þþIf using archived `.epub` files include JSZip:þþ```htmlþ<script src=""https://cdnjs.cloudflare.com/ajax/libs/jszip/3.1.5/jszip.min.js""></script>þ```þþSet up a element to render to:þþ```htmlþ<div id=""area""></div>þ```þþCreate the new ePub, and then render it to that element:þþ```htmlþ<script>þ  var book = ePub(""url/to/book/package.opf"");þ  var rendition = book.renderTo(""area"", {width: 600, height: 400});þ  var displayed = rendition.display();þ</script>þ```þþ## Render Methodsþþ### Defaultþþ```jsþbook.renderTo(""area"", { method: ""default"", width: ""100%"", height: ""100%"" });þ```þþ[View example](http://futurepress.github.io/epub.js/examples/spreads.html)þþThe default manager only displays a single section at a time.þþ### Continuousþþ```jsþbook.renderTo(""area"", { method: ""continuous"", width: ""100%"", height: ""100%"" });þ```þ[View example](http://futurepress.github.io/epub.js/examples/continuous-scrolled.html)þþThe continuous manager will display as many sections as need to fill the screen, and preload the next section offscreen. This enables seamless swiping / scrolling between pages on mobile and desktop, but is less performant than the default method.þþ## Flow Overridesþþ### Auto (Default)þ`book.renderTo(""area"", { flow: ""auto"", width: ""900"", height: ""600"" });`þþFlow will be based on the settings in the OPF, defaults to `paginated`.þþ### Paginatedþþ```jsþbook.renderTo(""area"", { flow: ""paginated"", width: ""900"", height: ""600"" });þ```þþ[View example](http://futurepress.github.io/epub.js/examples/spreads.html)þþScrolled: `book.renderTo(""area"", { flow: ""scrolled-doc"" });`þþ[View example](http://futurepress.github.io/epub.js/examples/scrolled.html)þþ## DocumentationþþAPI documentation is available at [epubjs.org/documentation/0.3/](http://epubjs.org/documentation/0.3/)þþA Markdown version is included in the repo at [documentation/API.md](https://github.com/futurepress/epub.js/blob/master/documentation/md/API.md)þþ## Running Locallyþþinstall [node.js](http://nodejs.org/)þþThen install the project dependences with npmþþ```javascriptþnpm installþ```þþYou can run the reader locally with the commandþþ```javascriptþnpm startþ```þþ## Examplesþþ+ [Spreads](http://futurepress.github.io/epub.js/examples/spreads.html)þ+ [Scrolled](http://futurepress.github.io/epub.js/examples/scrolled.html)þ+ [Swipe](http://futurepress.github.io/epub.js/examples/swipe.html)þ+ [Input](http://futurepress.github.io/epub.js/examples/input.html)þ+ [Highlights](http://futurepress.github.io/epub.js/examples/highlights.html)þþ[View All Examples](http://futurepress.github.io/epub.js/examples/)þþ## TestingþþTest can be run by Karma from NPMþþ```jsþnpm testþ```þþ## Building for DistributionþþBuilds are concatenated and minified using [webpack](https://webpack.js.org/) and [babel](https://babeljs.io/)þþTo generate a new build runþþ```javascriptþnpm run prepareþ```þþor to continuously build runþþ```javascriptþnpm run watchþ```þþ## HooksþþSimilar to a plugins, Epub.js implements events that can be ""hooked"" into. Thus you can interact with and manipulate the contents of the book.þþExamples of this functionality is loading videos from YouTube links before displaying a chapter's contents or implementing annotation.þþHooks require an event to register to and a can return a promise to block until they are finished.þþExample hook:þþ```javascriptþrendition.hooks.content.register(function(contents, view) {þþ    var elements = contents.document.querySelectorAll('[video]');þ    var items = Array.prototype.slice.call(elements);þþ    items.forEach(function(item){þ      // do something with the video itemþ    });þþ})þ```þþThe parts of the rendering process that can be hooked into are below.þþ```jsþbook.spine.hooks.serialize // Section is being converted to textþbook.spine.hooks.content // Section has been loaded and parsedþrendition.hooks.render // Section is rendered to the screenþrendition.hooks.content // Section contents have been loadedþrendition.hooks.unloaded // Section contents are being unloadedþ```þþ## ReaderþThe reader has moved to its own repo at: https://github.com/futurepress/epubjs-reader/þþ## Additional Resourcesþþ[![Gitter Chat](https://badges.gitter.im/futurepress/epub.js.png)](https://gitter.im/futurepress/epub.js ""Gitter Chat"")þþ[Epub.js Developer Mailing List](https://groups.google.com/forum/#!forum/epubjs)þþIRC Server: freenode.net Channel: #epub.jsþþFollow us on twitter: @Epubjsþþ+ http://twitter.com/#!/Epubjsþþ## OtherþþEPUB is a registered trademark of the [IDPF](http://idpf.org/).",
docker/labs,,False,False,False,221580,2760,9092,557,4438,0,0,0,0,"[242, 305, 333, 521, 523, 634, 650, 663, 669, 683]",Organization,This is a collection of tutorials for learning how to use Docker with various tools. Contributions welcome.,"{'': 49, 'md': 129, 'py': 2, 'txt': 22, 'html': 11, 'png': 521, 'xml': 7, 'java': 7, 'properties': 1, 'jsp': 5, 'css': 195, 'eot': 13, 'svg': 19, 'ttf': 13, 'woff': 13, 'js': 479, 'less': 1, 'yml': 10, 'sql': 15, 'jar': 1, 'sh': 3, 'adoc': 20, 'swp': 1, 'json': 7, 'gif': 70, 'jpg': 3, 'ps1': 24, 'cs': 245, 'csproj': 46, 'config': 91, 'feature': 5, 'aspx': 27, 'asax': 7, 'map': 5, 'master': 10, 'ascx': 5, 'ico': 5, 'sln': 8, 'msi': 4, 'pdf': 7, 'php': 615, 'scss': 10, 'pot': 3, 'otf': 2, 'crt': 1, 'swf': 4, 'xap': 2, 'gz': 1, 'ini': 1, 'woff2': 1, 'key': 2, 'bat': 1, 'exe': 1, 'wxs': 1, 'wixproj': 1, 'builder': 2, 'v1': 1, 'v2': 1, 'refactorlog': 2, 'sqlproj': 2}",,"{'key': 'apache-2.0', 'name': 'Apache License 2.0', 'spdx_id': 'Apache-2.0', 'url': 'https://api.github.com/licenses/apache-2.0', 'node_id': 'MDc6TGljZW5zZTI='}",PHP,708,3,0,114,12,1542,True,35,115,3,1,49,302,15,1,13,0,0,0,82,14,,"# Docker Tutorials and Labsþþ> At this time we are not actively adding labs to this repository. Our focus is on [training.play-with-docker.com](https://training.play-with-docker.com) where new lab and workshop oriented content is being added. We welcome fixes to existing content. For any new content you wish to contribute, please use this repository:[https://github.com/play-with-docker/play-with-docker.github.io](https://github.com/play-with-docker/play-with-docker.github.io).þþþThis repo contains [Docker](https://docker.com) labs and tutorials authored both by Docker, and by members of the community. We welcome contributions and want to grow the repo.þþ#### Docker tutorials:þ* [Docker for beginners](beginner/readme.md)þ* [Docker Swarm Mode](swarm-mode/README.md)þ* [Configuring developer tools and programming languages](developer-tools/README.md)þ  * Javaþ    * [Live Debugging Java with Docker](developer-tools/java-debugging)þ    * [Docker for Java Developers](developer-tools/java/)þ  * Node.jsþ    * [Live Debugging a Node.js application in Docker](developer-tools/nodejs-debugging)þ    * [Dockerizing a Node.js application](developer-tools/nodejs/porting/)þ* [Docker for ASP.NET and Windows containers](windows/readme.md)þ* [Building a 12 Factor app with Docker](12factor/README.md)þ* [Docker Security](security/README.md)þ* [Docker Networking](networking/)þ* [Hands-on Labs from DockerCon US 2017](dockercon-us-2017/)þþþ#### Community tutorialsþ* [Docker Tutorials from the Community](https://github.com/docker/community/blob/master/curated-content.md) - links to a different repositoryþ* [Advanced Docker orchestration workshop](https://github.com/docker/labs/tree/master/Docker-Orchestration) - links to a different repositoryþþ#### ContributingþþWe want to see this repo grow, so if you have a tutorial to submit, or contributions to existing tutorials, please see this guide:þþ[Guide to submitting your own tutorial](contribute.md)",
taichi-dev/taichi,,False,False,False,33843,611,11532,313,1231,1187,127442,124216,26,"[-1, 0, 1, 2, 3, 4, 5, 6]",Organization,"Productive & portable programming language for high-performance, sparse & differentiable computing","{'': 18, 'md': 5, 'yml': 6, 'sh': 1, 'txt': 5, 'py': 224, 'cmake': 4, 'css': 1, 'rst': 37, 'jpg': 1, 'png': 2, 'bat': 1, 'bc': 1, 'hpp': 2, 'h': 148, 'yapf': 1, 'cu': 11, 'cpp': 139, 'json': 1, 'in': 1, 'cfg': 1, 'c': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",C++,6370,12,32,32,5,1325,True,183,514,137,220,18,755,18,719,43,3,0,0,12,11,,"<div align=""center"">þ  <img width=""500px"" src=""https://github.com/taichi-dev/taichi/raw/master/misc/logo.png"">þ  <h3> <a href=""https://taichi.readthedocs.io/en/stable/hello.html""> Tutorial </a> | <a href=""https://github.com/taichi-dev/taichi/tree/master/examples""> Examples </a> | <a href=""https://taichi.readthedocs.io/en/stable/contributor_guide.html""> Contributor Guidelines </a> | <a href=""https://forum.taichi.graphics/""> Forum </a> </h3>þ  <h3> <a href=""https://taichi.readthedocs.io/en/stable/""> Documentation </a> | <a href=""https://taichi.readthedocs.io/zh_CN/latest/""> 简体中文文档 </a> </h3>þ</div>þþ[![Travis CI Status](https://img.shields.io/travis/taichi-dev/taichi?logo=Travis&branch=master&label=Travis%20CI)](https://travis-ci.com/taichi-dev/taichi)þ[![AppVeyor Status](https://img.shields.io/appveyor/build/yuanming-hu/taichi?logo=AppVeyor&label=AppVeyor)](https://ci.appveyor.com/project/yuanming-hu/taichi/branch/master)þ[![Docker Cloud Build Status](https://img.shields.io/docker/cloud/build/taichidev/taichi?label=Docker%20Image&logo=docker)](https://hub.docker.com/r/taichidev/taichi)þ[![Python Codecov Status](https://img.shields.io/codecov/c/github/taichi-dev/taichi?label=Python%20Coverage&logo=codecov)](https://codecov.io/gh/taichi-dev/taichi/src/master)þ[![Latest Release](https://img.shields.io/github/v/release/taichi-dev/taichi?color=blue&label=Latest%20Release)](https://github.com/taichi-dev/taichi/releases/latest)þþ## Overviewþþ**Taichi** (太极) is a programming language designed for *high-performance computer graphics*. It is deeply embedded in **Python**, and its **just-in-time compiler** offloads compute-intensive tasks to multi-core CPUs and massively parallel GPUs.þþ<a href=""https://github.com/taichi-dev/taichi/blob/master/examples/fractal.py#L1-L31""> <img src=""https://github.com/yuanming-hu/public_files/raw/master/graphics/taichi/fractal_code.png"" height=""270px""></a>  <img src=""https://raw.githubusercontent.com/yuanming-hu/public_files/master/graphics/taichi/fractal_small.gif"" height=""270px"">þþþAdvanced features of Taichi include [spatially sparse computing](https://taichi.readthedocs.io/en/latest/sparse.html) and [differentiable programming](https://taichi.readthedocs.io/en/latest/differentiable_programming.html) [[examples]](https://github.com/yuanming-hu/difftaichi).þþ## Galleryþþ<a href=""https://github.com/taichi-dev/taichi/blob/master/examples/mpm128.py""><img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/mpm128.gif"" height=""192px""></a> <a href=""https://github.com/taichi-dev/taichi/blob/master/examples/stable_fluid.py""> <img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/stable_fluids.gif"" height=""192px""></a> <a href=""https://github.com/taichi-dev/taichi/blob/master/examples/sdf_renderer.py""><img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/sdf_renderer.jpg"" height=""192px""></a> <a href=""https://github.com/taichi-dev/taichi/blob/master/examples/taichi_sparse.py""><img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/sparse_grids.gif"" height=""192px""></a>þþ<a href=""https://github.com/taichi-dev/taichi/blob/master/examples/mpm_lagrangian_forces.py""><img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/lagrangian.gif"" height=""192px""></a> <a href=""https://github.com/taichi-dev/taichi/blob/master/examples/pbf2d.py""><img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/pbf.gif"" height=""192px""></a> <a href=""https://github.com/taichi-dev/taichi/blob/master/examples/game_of_life.py""><img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/game_of_life.gif"" height=""192px""></a> <a href=""https://github.com/taichi-dev/taichi/blob/master/examples/euler.py""><img src=""https://github.com/taichi-dev/public_files/blob/6bd234694270c83baf97ba32e0c6278b8cf37e6e/taichi/euler.gif"" height=""192px""></a>þþ## Installation [![Downloads](https://pepy.tech/badge/taichi/month)](https://pepy.tech/project/taichi/month)þþ```bashþpython3 -m pip install taichiþ```þþ**Supported OS**: Windows, Linux, Mac OS X; **Python**: 3.6/3.7/3.8 (64-bit only); **Backends**: x64 CPUs, CUDA, Apple Metal, OpenGL Compute Shaders.þþPlease build from source for other configurations (e.g., your CPU is ARM).þþ**Note:**þ - Starting April 13 2020 (v0.5.12), we release the Python package [`taichi`](https://pypi.org/project/taichi/) instead of [`taichi-nightly`](https://pypi.org/project/taichi-nightly/). Now this PyPI package includes CPU, CUDA 10/11, Metal and OpenGL support.þ - On Ubuntu 19.04+, please `sudo apt install libtinfo5`.þ - On Windows, please install [Microsoft Visual C++ Redistributable](https://aka.ms/vs/16/release/vc_redist.x64.exe) if you haven't.þ - [[All releases]](https://github.com/taichi-dev/taichi/releases)þþ|| **Linux (CUDA)** | **OS X (10.14+)** | **Windows** | **Documentation**|þ|:------|:-----|:-----|:-----|:-----|þ|**Build**|[![Build Status](http://f11.csail.mit.edu:8080/job/taichi/badge/icon)](http://f11.csail.mit.edu:8080/job/taichi/)| [![Build Status](https://travis-ci.com/taichi-dev/taichi.svg?branch=master)](https://travis-ci.com/taichi-dev/taichi) | [![Build status](https://ci.appveyor.com/api/projects/status/yxm0uniin8xty4j7/branch/master?svg=true)](https://ci.appveyor.com/project/yuanming-hu/taichi/branch/master)| [![Documentation Status](https://readthedocs.org/projects/taichi/badge/?version=latest)](http://taichi.readthedocs.io/en/latest/?badge=latest)|þ|**PyPI**|[![Build Status](https://travis-ci.com/yuanming-hu/taichi-wheels-test.svg?branch=master)](https://travis-ci.com/yuanming-hu/taichi-wheels-test)|[![Build Status](https://travis-ci.com/yuanming-hu/taichi-wheels-test.svg?branch=master)](https://travis-ci.com/yuanming-hu/taichi-wheels-test)|[![Build status](https://ci.appveyor.com/api/projects/status/39ar9wa8yd49je7o?svg=true)](https://ci.appveyor.com/project/yuanming-hu/taichi-wheels-test) |þþ## Linksþþ- [Taichi Forum](https://forum.taichi.graphics): Powered by Discourse, Taichi offical forum for discussing issues and sharing ideas.þ- [Taichi Simplified Chinese Documentation](https://github.com/taichi-dev/taichi-docs-zh-cn): Translated by the Taichi community, welcome contribution!þ- [Taichi Conference](https://github.com/taichi-dev/taichicon): Taichi Online Virtual Conference available in both Chinese and English, approximately per-month.þ- [GAMES 201 Lectures](https://github.com/taichi-dev/games201): (Chinese) A hands-on tutorial on advanced physics engines based on Taichi, per-week.þþ---þþ- [Taichi GLSL](https://github.com/taichi-dev/taichi_glsl): A Taichi extension library providing a set of GLSL-alike helper functions.þ- [Taichi THREE](https://github.com/taichi-dev/taichi_three): A 3D rendering library based on Taichi (work in progress).þ- [Taichi Elements](https://github.com/taichi-dev/taichi_elements): A High-Performance Multi-Material Continuum Physics Engine based on Taichi (work in progress).þþ---þþ- [LBM Taichi](https://github.com/hietwll/LBM_Taichi): Fluid solver based on Lattice Boltzmann method implemented by Taichi programming language, by [Zhuo Wang (hietwll)](https://github.com/hietwll).þ- [Shadertoy reproduced by Taichi](https://github.com/Phonicavi/Shadertoy-taichi): Some prevalent shadertoys implemented in Taichi, by [QIU Feng (Phonicavi)](https://github.com/Phonicavi).þ- [DiffTaichi](https://github.com/yuanming-hu/difftaichi): 10 differentiable physical simulators built with Taichi differentiable programming, by [Yuanming Hu (yuanming-hu)](https://github.com/yuanming-hu).þþ## DevelopersþþThe Taichi project was created by [Yuanming Hu (yuanming-hu)](https://github.com/yuanming-hu). Significant contributions are made by:þ - [Ye Kuang (k-ye)](https://github.com/k-ye) (Apple Metal backend)þ - [彭于斌 (archibate)](https://github.com/archibate) (OpenGL Compute Shader backend)þ - [Mingkuan Xu (xumingkuan)](https://github.com/xumingkuan) (IR optimization & standardization)þþ[Kenneth Lozes (KLozes)](https://github.com/KLozes) and [Yu Fang (squarefk)](https://github.com/squarefk) have also made notable contributions.þþ[[List of all contributors to Taichi]](https://github.com/taichi-dev/taichi/graphs/contributors)þþ-------------------------------þþThe Simplified Chinese documentation (简体中文文档) was created by [Ark (StephenArk30)](https://github.com/StephenArk30). Significant contributions are made by:þ  - [彭于斌 (archibate)](https://github.com/archibate)þ  - [Danni Li (isdanni)](https://github.com/isdanni)þ  - [Chengchen Wang (rexwangcc)](https://github.com/rexwangcc)þ  - [万健洲 (ArkhamWJZ)](https://github.com/ArkhamWJZ)þþ[[List of all contributors to the Simplified Chinese documentation of Taichi]](https://github.com/taichi-dev/taichi-docs-zh-cn/graphs/contributors)þþ-------------------------------þþWe welcome feedback and comments. If you would like to contribute to Taichi, please check out our [Contributor Guidelines](https://taichi.readthedocs.io/en/latest/contributor_guide.html).þþIf you use Taichi in your research, please cite our papers:þþ- [**(SIGGRAPH Asia 2019) Taichi: High-Performance Computation on Sparse Data Structures**](http://taichi.graphics/wp-content/uploads/2019/09/taichi_lang.pdf) [[Video]](https://youtu.be/wKw8LMF3Djo) [[BibTex]](https://raw.githubusercontent.com/taichi-dev/taichi/master/misc/taichi_bibtex.txt) [[Code]](https://github.com/taichi-dev/taichi)þ- [**(ICLR 2020) DiffTaichi: Differentiable Programming for Physical Simulation**](https://arxiv.org/abs/1910.00935) [[Video]](https://www.youtube.com/watch?v=Z1xvAZve9aE) [[BibTex]](https://raw.githubusercontent.com/taichi-dev/taichi/master/misc/difftaichi_bibtex.txt) [[Code]](https://github.com/yuanming-hu/difftaichi)",
dvdhrm/docs,,False,False,False,29,6,198,28,107,0,0,0,0,"[1123, 1188, 2064, 2732, 2759, 2858]",User,"API Documentations, HowTos and Tutorials","{'': 3, 'c': 3}",,,C,9,1,0,3,0,2858,True,3,3,0,0,2,2,1,0,6,0,0,0,,,200,,
Taeung/git-training,,False,False,False,1646,10,295,10,1798,0,0,0,0,"[1479, 1552, 1568]",User,":octocat:  Don't think about git, just do git","{'md': 1, 'png': 1, 'py': 2, 'pdf': 2, 'c': 2, 'sh': 2}",,,C,12,2,0,1,3,1568,True,3,0,1,0,1546,130,193,3,7,0,0,0,,,128,"## Git Trainingþþ##### Don't think about git, just do git !þ##### (Based on a scenario; c programming with Git (Report card, Knapsack problem))þ### Training Environmentþþ1. Download tutorialþ    - [tutorial v3](https://www.dropbox.com/s/jwpkfn5c8d1z74y/Git-training-v3.pdf?dl=1&pv=1)þ    - [tutorial v2](https://www.dropbox.com/s/6o5sfs1iyd9cxdq/Git-training-v2.pdf?dl=1&pv=1) & [example code v2](https://www.dropbox.com/sh/3ywkargf9xzcfoi/AAC63uvN4eQBQhT_1m4GmCMLa?dl=1&pv=1)þ    - [tutorial v1](https://www.dropbox.com/s/0bplreunw6vf69p/Git-training.pdf?dl=1&pv=1) & [example code v1](https://www.dropbox.com/sh/9q2emkhxmyckoj6/AAA_H55BVhfRvGHOs9j7l9N2a?dl=1&pv=1)þ2. Install Git ([git](https://git-scm.com/downloads), [source tree](https://www.sourcetreeapp.com))þ3. Editor ([atom](https://atom.io/), [sublime text](https://www.sublimetext.com/3))þ4. Github account ([sign up](https://github.com/join))þ5. Download [the courage](https://www.dropbox.com/s/36ifeasvhhshqj8/you_can_do_git?dl=1&pv=1)þþ### Stageþ1. New version (v2)þ    - Basic : Stage 1 ~ 7þ    - Advanced : Stage 8 ~ 11þþ2. Old version (v1)þ    - Basic : Stage 1 ~ 10þ    - Advanced : Stage 11 ~ 14þþ### The results (v1)þ![screenshot](img/results_20160327.png)þ[git-training.docs.google](https://docs.google.com/spreadsheets/d/1uPMCOKISMgj_svsoxG1LF1RbozA9RMKfx7h9vT80Atc/edit#gid=0)",
Moskize91/TaolanTutorial,,False,False,False,43,58,173,19,49,0,0,0,0,"[1054, 1614]",User,,"{'md': 1, 'java': 53, 't': 4}",,,Java,3,1,0,2,0,1614,True,0,3,0,0,0,0,0,0,7,0,0,0,,,57,# 从零开始写个编译器吧系列þþ这是《从零开始写个编译器吧系列》中出现的 Taolan，如果你安装了 JDK 1.8，并把这个项目 pull 到本地，你就可以用它编译并运行用 tao 语言写的代码了。þþ更多内容请参考 [知乎专栏－从零开始写个编译器吧](https://zhuanlan.zhihu.com/p/19878087),
MorvanZhou/tutorials,,False,False,False,50482,140,8233,630,4923,0,0,0,0,"[855, 857, 924, 925, 938, 954, 955, 959, 960, 980]",User,机器学习相关教程,"{'': 2, 'md': 7, 'py': 115, 'ipynb': 1, 'zip': 8, 'csv': 1, 'jpeg': 1, 'gif': 4, 'png': 1}",https://morvanzhou.github.io/tutorials,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",Python,538,1,0,6,9,1504,True,12,53,1,3,1,23,1,1,7,0,0,0,,,15,"<p align=""center"">þ    <a href=""https://morvanzhou.github.io/tutorials/"" target=""_blank"">þ    <img width=""60%"" src=""https://github.com/MorvanZhou/tutorials/blob/master/%E7%89%87%E5%A4%B4.png"" style=""max-width:100%;"">þ    </a>þ</p>þþþ<br>þþ我是 周沫凡, [莫烦Python](https://morvanzhou.github.io/) 只是谐音, 我喜欢制作,þ分享所学的东西, 所以你能在这里找到很多有用的东西, 少走弯路. 你能在[这里](https://morvanzhou.github.io/about/)找到关于我的所有东西.þþ## 这个 Python tutorial 的一些内容:þþ* [Python 基础](https://morvanzhou.github.io/tutorials/python-basic/)þ  * [基础](https://morvanzhou.github.io/tutorials/python-basic/basic/)þ  * [多线程 threading](https://morvanzhou.github.io/tutorials/python-basic/threading/)þ  * [多进程 multiprocessing](https://morvanzhou.github.io/tutorials/python-basic/multiprocessing/)þ  * [简单窗口 tkinter](https://morvanzhou.github.io/tutorials/python-basic/tkinter/)þ* [机器学习](https://morvanzhou.github.io/tutorials/machine-learning/)þ  * [有趣的机器学习](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/)þ  * [强化学习 (Reinforcement Learning)](https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/)þ  * [进化算法 (Evolutionary Algorithm) 如遗传算法等](https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/)þ  * [Tensorflow (神经网络)](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/)þ  * [PyTorch (神经网络)](https://morvanzhou.github.io/tutorials/machine-learning/torch/)þ  * [Theano (神经网络)](https://morvanzhou.github.io/tutorials/machine-learning/theano/)þ  * [Keras (快速神经网络)](https://morvanzhou.github.io/tutorials/machine-learning/keras/)þ  * [Scikit-Learn (机器学习)](https://morvanzhou.github.io/tutorials/machine-learning/sklearn/)þ  * [机器学习实战](https://morvanzhou.github.io/tutorials/machine-learning/ML-practice/)þ* [数据处理](https://morvanzhou.github.io/tutorials/data-manipulation/)þ  * [Numpy & Pandas (处理数据)](https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/)þ  * [Matplotlib (绘图)](https://morvanzhou.github.io/tutorials/data-manipulation/plt/)þ  * [爬虫](https://morvanzhou.github.io/tutorials/data-manipulation/scraping/)þ* [其他](https://morvanzhou.github.io/tutorials/others/)þ  * [Git (版本管理)](https://morvanzhou.github.io/tutorials/others/git/)þ  * [Linux 简易教学](https://morvanzhou.github.io/tutorials/others/linux-basic/)þþ## 赞助和支持þþ这些 tutorial 都是我用业余时间写出来, 录成视频, 如果你觉得它对你很有帮助, 请你也分享给需要学习的朋友们.þ如果你看好我的经验分享, 也请考虑适当的 [赞助打赏](https://morvanzhou.github.io/support/), 让我能继续分享更好的内容给大家.",
lugolabs/tutorials,,False,False,False,292,124,32,5,67,0,0,0,0,"[777, 868, 1212, 1493, 1658, 1691, 1707, 1787, 1812, 1824]",Organization,Tutorial demos for https://www.lugolabs.com,"{'': 25, 'md': 3, 'lock': 1, 'rdoc': 1, 'js': 9, 'css': 9, 'scss': 3, 'rb': 32, 'erb': 8, 'am': 2, 'jbuilder': 2, 'ru': 1, 'yml': 4, 'html': 8, 'ico': 1, 'txt': 1, 'gif': 1, 'png': 13}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",JavaScript,26,1,0,2,7,2020,True,1,8,0,0,0,1,0,0,7,0,0,0,42,1,,Tutorialsþ=========þþDemos for [Lugolabs Blog](http://www.lugolabs.com/blog).þþ---------þþCopyright Lugo Labs. Uses [MIT-LICENSE](https://github.com/lugolabs/tutorials/blob/master/MIT-LICENSE).,
miyosuda/TensorFlowAndroidMNIST,,False,False,False,150633,6860,264,27,112,0,0,0,0,"[1370, 1384, 1542, 1557, 1568, 1607, 1635, 1636, 1637]",User,Tensorflow MNIST demo on Android,"{'': 306, 'xml': 32, 'md': 903, 'gradle': 3, 'pro': 1, 'java': 164, 'pb': 3, 'so': 1, 'png': 24, 'properties': 2, 'jar': 17, 'bat': 4, 'mk': 2, 'cc': 1300, 'h': 1337, 'sh': 100, 'proto': 124, 'txt': 134, 'srcjar': 1, 'py': 988, 'in': 16, 'cfg': 2, 'bzl': 18, 'keystore': 1, 'tpl': 14, 'tar': 3, 'ar': 7, 'bz2': 1, 'gz': 2, 'xz': 1, 'static': 1, '7': 1, 'fedora23': 1, '04': 1, '10': 1, 'dylib': 1, 'plist': 4, 'c': 23, 'mac_template': 1, 'bazel_template': 1, 'mm': 9, 'bsd': 1, 'gpl': 1, 'lgpl': 1, 'minpack': 1, 'mpl2': 1, 'readme': 1, 'cmake': 62, 'cpp': 698, 'cxxlist': 1, 'hh': 58, 'cxx': 3, 'main': 2, 'dtd': 1, 'cu': 12, 'f': 51, 'dat': 9, 'natvis': 1, 'dox': 54, 'js': 8, 'css': 3, 'entry': 1, 'evaluator': 1, 'expression': 1, 'preamble': 1, 'traits': 1, 'yml': 1, 'am': 1, 'rb': 1, 'la': 1, 'json': 50, 'ogg': 1, 'wav': 3, 'mp3': 3, 'm': 1, 'pbxproj': 2, 'jpg': 12, 'storyboard': 1, 'xib': 1, 'csv': 6, 'subr': 1, 'pbtxt': 9, 'gif': 2, 'ipynb': 10, 'dot': 1, 'html': 113, 'i': 18, 'ts': 75, 'lds': 2, 'android': 1, 'cpu': 2, 'gpu': 2, 'tensorboard': 1, 'local': 1, 'test': 1, 'devel': 1, 'devel-gpu': 1, 'lo': 3, 'a': 3}",,,C++,19,1,0,0,0,1637,True,12,1,0,0,1,0,0,0,7,0,0,0,,,270,"# TensorFlowAndroidMNIST - Android MNIST demo with TensorFlowþþThis is a demo app for Android with Tensorflow to detect handwritten digits.þþ![image](http://narr.jp/private/miyoshi/tensorflow/mnist_screen0.png)þþThis Android demo is based on Tensorflow tutorial.þþMNIST For ML Beginnersþhttps://www.tensorflow.org/versions/r0.10/tutorials/mnist/beginners/index.htmlþþDeep MNIST for Expertsþhttps://www.tensorflow.org/versions/r0.10/tutorials/mnist/pros/index.htmlþþ## How to train model.þTraining scripts for neural network model are located atþþhttps://github.com/miyosuda/TensorFlowAndroidMNIST/tree/master/trainer-scriptþþTo create model by yourself, install Tensorflow and run python scripts likeþþ    $ python beginner.pyþþorþþ    $ python expert.pyþþand locate exported .pb file to assets dir.þþTo export training model, I added some modification to original tutorial scripts.þþNow Tensorflow cannot export network graph and trained network weight Variable at the same time,þso we need to create another graph to export and convert Variable into constants.þþAfter training is finished, converted trained Variable to numpy ndarray.þþ    _W = W.eval(sess)þ    _b = b.eval(sess)þþand then convert them into constant and re-create graph for exporting.þþ    W_2 = tf.constant(_W, name=""constant_W"")þ    b_2 = tf.constant(_b, name=""constant_b"")þþAnd then use tf.train.write_graph to export graph with trained weights.þþþ## How to build JNI codesþþNative .so files are already built in this project, but if you would like toþbuild it by yourself, please install and setup NDK.þþFirst download, extract and place Android NDK.þþhttp://developer.android.com/intl/ja/ndk/downloads/index.htmlþþAnd then update your PATH environment variable. For example,þþ    export NDK_HOME=""/Users/[your-username]/Development/android/android-ndk-r11b""þ    export PATH=$PATH:$NDK_HOMEþþAnd build .so file in jni-build dir.þþ    $ cd jni-buildþ    $ makeþ    þand copy .so file into app/src/main/jniLibs/armeabi-v7a/ withþþ    $ make installþþ(Unlike original Android demo in Tensorflow, you don't need to install bazel to build this demo.þþTensorflow library files (.a files) and header files are extracted from original Tensorflow Android demo r0.10.",
appium-boneyard/tutorial,,False,False,False,4165,240,59,31,140,0,0,0,0,"[1332, 1429, 1431, 1536, 1537, 1668, 1677, 1787, 1789, 1955]",Organization,tutorials for appium,"{'': 18, 'yml': 2, 'md': 86, 'html': 4, 'css': 5, 'otf': 1, 'eot': 1, 'svg': 1, 'ttf': 1, 'woff': 1, 'rb': 24, 'png': 29, 'plist': 1, 'nib': 13, 'strings': 1, 'jpg': 5, 'iml': 4, 'bucklet': 9, 'py': 7, 'java': 15, 'apk': 2, 'xml': 2, 'zip': 2, 'lock': 2, 'txt': 4}",http://appium.io/tutorial,"{'key': 'apache-2.0', 'name': 'Apache License 2.0', 'spdx_id': 'Apache-2.0', 'url': 'https://api.github.com/licenses/apache-2.0', 'node_id': 'MDc6TGljZW5zZTI='}",Ruby,88,2,0,12,0,2283,True,0,18,0,0,0,10,0,0,7,0,0,0,43,0,,#### tutorial [![Build Status](https://travis-ci.org/appium/tutorial.svg?branch=master)](https://travis-ci.org/appium/tutorial) [![Dependency Status](https://gemnasium.com/appium/tutorial.svg)](https://gemnasium.com/appium/tutorial)þþGetting started tutorials for appiumþþ#### 4 Tracksþþ0. [Ruby Appium iOS](/modules/en/source/appium/01_native_ios_automation)þ0. [Ruby Appium Android](/modules/en/source/appium/02_native_android_automation)þþEach track is self contained.þþPublished on [GitHub Pages](https://github.com/appium/tutorial/tree/gh-pages),
buckyroberts/Source-Code-from-Tutorials,,False,False,False,36731,571,2094,387,3083,0,0,0,0,"[1464, 1473, 1478, 1503, 1578, 1583, 1597, 1598, 1599, 1603]",User,Here is the source code from all of my tutorials.,"{'': 4, 'java': 118, 'txt': 24, 'png': 10, 'gradle': 3, 'pro': 1, 'properties': 2, 'jar': 1, 'bat': 1, 'html': 82, 'css': 8, 'jpg': 3, 'cpp': 68, 'h': 2, 'c': 12, 'py': 188, 'js': 28, 'json': 10, 'fxml': 1, 'pdf': 1, 'sh': 2, 'sql': 1, 'md': 1}",https://www.youtube.com/user/thenewboston,,Python,214,2,0,16,0,1961,True,31,8,0,0,50,64,4,1,7,0,0,0,,,25,"####Source Code from thenewboston TutorialsþþWe are in the process of adding the source code from all of the tutorials to a public GitHub repository. If anyone would like to contribute, please feel free!þþ[thenewboston Videos and Tutorials](https://www.thenewboston.com/videos.php)þþLinux: https://docs.google.com/document/d/1FgMqlHYDva5--sJuR1fc-wbidpvHMFKEvK4RHqD4px0/edit?usp=sharingþþDigitalOcean: https://docs.google.com/document/d/1xOllgXRN10fWz1TsURh0OYI60TAVz0snD8HOzga5CCA/edit?usp=sharingþþ***þþ#####How to Submit Source Codeþþ1 - Download [GitHub for Windows](https://windows.github.com/) or [GitHub for Mac](https://mac.github.com/)þþ2 - On the top right of this page, click ""Fork"". This will create a copy for you.þþ![](http://i.imgur.com/UTwzOgC.png)þþ3 - Once your copy has been created, click “Clone in Desktop” to download and save it on your computer. þþ![](http://i.imgur.com/uNy5iHg.png)þþ4 - From here you can make changes, add folders, add source code files, etc... þþ5 - When you are finished with your changes, open GitHub for Windows (or Mac)þþ6 - Add a commit message and click ""Commit to master""þþ![](http://i.imgur.com/jHcjXvF.png)þþ7 - Click ""Sync"" on the top right to save the changes to your GitHub account.þþ![](http://i.imgur.com/hk9mIZS.png)þþ8 - On your GitHub page for that repo, you will now see a “Pull Request” link. Click it. þþ![](http://i.imgur.com/pogptvB.png)þþ9 - On this page, click the “Create pull request” button.þþ10 - Add a comment and click “create pull request” again button to submit.",
yiblet/tutorial,,False,False,False,1,2,0,1,47,0,0,0,0,[1036],User,A tutorial on working at scottylabs,"{'': 1, 'md': 1}",,,,1,1,0,0,0,1036,True,0,0,0,0,22,0,0,0,8,0,0,0,,,15,"# Getting StartedþþThis readme will help you get accustomed to the tools that we use at scottylabs.þOur applications primarily are built with nodejs and python, and we use gitþto collaborate together.þþHere we'll get you started with git, github, and nodejs.þþ# Getting Started With GitþþGit is a program that coders use to save versions of files as they develop code.þIt helps organize code and makes it easier to fix issues in code if they ever show up.þGo to [learngitbranching.js.org](http://learngitbranching.js.org/) Itþis a very useful website to learn git. Try doing all the lessons up to the *ramping up* section.þþ## installing gitþþ### windows and macsþThe best way to install it is using githubs own installer [here](https://desktop.github.com/)þThis will install github's visual tool to work with git as well as the git command line tool.þþ### linuxþcome talk to me.þþ## getting your own git repoþNow that you know a little bit more about git, lets start working on your own git directory.þþFirst, login/signup to github, and press the fork button on this repo. Now you should have a repo called `(yourname)/tutorial` on github.þþ### cloning that directory.þþOn your favorite terminal write:þ```þgit clone https://github.com/(yourname)/tutorial.gitþcd tutorialþ```þþThis will make a folder with all the stuff that was on this directory. We'll use that folder to work on the nodejs part of the tutorial.þþ# Getting Started With Nodejsþþ## installingþGo to [nodejs.org](https://nodejs.org/) and download the `v6.11.3` version. This will install nodejs on to your computer. Now we can get started on making your first program in node. We'll try to make a website that shows these instructions.þþ## setting up the npm directoryþ```þnpm initþ...þnpm install express express-remarkable --saveþ```þþnow in the folder make a file called `index.js` inside of it copy the following lines of code.þ```þvar express = require('express')þvar remarkable = require('express-remarkable')þvar app = express()þþapp.engine('md', remarkable(app));þapp.set('views', '.');þapp.set('view engine', 'md');þþfunction sendWebpage(request, response) {þ  response.render('README');þ}þþapp.get('/', sendWebpage)þþapp.listen('3000', () => {þ  console.log('server is now running');þ  console.log('go to http://localhost:3000 to see the output')þ})þ```þþ## running your websiteþþNow to run your website, open up this tutorial folder on the command line and run:þ```þnode index.jsþ```þIf you now go online to [http://localhost:3000/](http://localhost:3000/)þyou'll see the site set up your computer. It should show all these instructionsþin a very basic plain webpage.þþ# Showing off what you didþnow that you got your website working on your repo. Let's do some git magic and put it up on github. Make a commit (remember to `git add --all`!) and `git push` it to github.þOn github, make a pull request which lets you send your version of the repo to me letting me know that you've completed the tutorial.þþ# Congrats you're doneþIf you want to learn more about git, play around in [learngitbranching.js.org](http://learngitbranching.js.org/). You can also play around with the nodejs file to see how things worked. **don't be afraid to ask me questions if you're confused.**",
nlintz/TensorFlow-Tutorials,,False,False,False,902,28,5881,373,1591,0,0,0,0,"[1195, 1210, 1250, 1259, 1261, 1273, 1323, 1358, 1362, 1363]",User,Simple tutorials using Google's TensorFlow Framework,"{'': 2, 'yml': 1, 'ipynb': 12, 'py': 12, 'md': 1}",,,Jupyter Notebook,114,2,0,21,0,1705,True,12,25,0,0,5,58,0,0,7,0,0,0,,,286,# TensorFlow-Tutorialsþ[![Build Status](https://travis-ci.org/nlintz/TensorFlow-Tutorials.svg?branch=master)](https://travis-ci.org/nlintz/TensorFlow-Tutorials)þ[![Codacy Badge](https://api.codacy.com/project/badge/grade/2d3ed69cdbec4249ab5c2f7e4286bb8f)](https://www.codacy.com/app/hunkim/TensorFlow-Tutorials)þþIntroduction to deep learning based on Google's TensorFlow framework. These tutorials are direct ports ofþNewmu's [Theano Tutorials](https://github.com/Newmu/Theano-Tutorials).þþ***Topics***þ* [Simple Multiplication](00_multiply.py)þ* [Linear Regression](01_linear_regression.py)þ* [Logistic Regression](02_logistic_regression.py)þ* [Feedforward Neural Network (Multilayer Perceptron)](03_net.py)þ* [Deep Feedforward Neural Network (Multilayer Perceptron with 2 Hidden Layers O.o)](04_modern_net.py)þ* [Convolutional Neural Network](05_convolutional_net.py)þ* [Denoising Autoencoder](06_autoencoder.py)þ* [Recurrent Neural Network (LSTM)](07_lstm.py)þ* [Word2vec](08_word2vec.py)þ* [TensorBoard](09_tensorboard.py)þ* [Save and restore net](10_save_restore_net.py)þ* [Generative Adversarial Network](11_gan.py)þþ***Dependencies***þ* TensorFlow 1.0 alphaþ* Numpyþ* matplotlib,
praveenkarthik/tutorial,,False,False,False,252,1,0,1,0,0,0,0,0,"[2230, 2233, 2234]",User,This repo is for tutorial purpose only.,{'txt': 1},,,,15,1,0,0,0,2234,True,0,0,0,0,0,4,0,0,7,0,0,0,,,1,,
julianjjo/tutorial,,False,False,False,172,78,0,2,0,0,0,0,0,[2456],User,,"{'': 9, 'yml': 12, 'md': 4, 'php': 20, 'php~': 2, 'twig': 10, 'twig~': 1, 'dist': 2, 'yml~': 2, 'json': 1, 'lock': 1, 'xml': 1, 'css': 1, 'png': 3, 'gif': 5, 'twig ': 1, 'twig ~': 1, 'ico': 1, 'txt': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",PHP,2,1,0,0,0,2456,True,0,0,0,0,0,0,0,0,6,0,0,0,,,2,"Symfony Standard Editionþ========================þþWelcome to the Symfony Standard Edition - a fully-functional Symfony2þapplication that you can use as the skeleton for your new applications.þþThis document contains information on how to download, install, and startþusing Symfony. For a more detailed explanation, see the [Installation][1]þchapter of the Symfony Documentation.þþ1) Installing the Standard Editionþ----------------------------------þþWhen it comes to installing the Symfony Standard Edition, you have theþfollowing options.þþ### Use Composer (*recommended*)þþAs Symfony uses [Composer][2] to manage its dependencies, the recommended wayþto create a new project is to use it.þþIf you don't have Composer yet, download it following the instructions onþhttp://getcomposer.org/ or just run the following command:þþ    curl -s http://getcomposer.org/installer | phpþþThen, use the `create-project` command to generate a new Symfony application:þþ    php composer.phar create-project symfony/framework-standard-edition path/to/installþþComposer will install Symfony and all its dependencies under theþ`path/to/install` directory.þþ### Download an Archive FileþþTo quickly test Symfony, you can also download an [archive][3] of the StandardþEdition and unpack it somewhere under your web server root directory.þþIf you downloaded an archive ""without vendors"", you also need to install allþthe necessary dependencies. Download composer (see above) and run theþfollowing command:þþ    php composer.phar installþþ2) Checking your System Configurationþ-------------------------------------þþBefore starting coding, make sure that your local system is properlyþconfigured for Symfony.þþExecute the `check.php` script from the command line:þþ    php app/check.phpþþThe script returns a status code of `0` if all mandatory requirements are met,þ`1` otherwise.þþAccess the `config.php` script from a browser:þþ    http://localhost/path/to/symfony/app/web/config.phpþþIf you get any warnings or recommendations, fix them before moving on.þþ3) Browsing the Demo Applicationþ--------------------------------þþCongratulations! You're now ready to use Symfony.þþFrom the `config.php` page, click the ""Bypass configuration and go to theþWelcome page"" link to load up your first Symfony page.þþYou can also use a web-based configurator by clicking on the ""Configure yourþSymfony Application online"" link of the `config.php` page.þþTo see a real-live Symfony page in action, access the following page:þþ    web/app_dev.php/demo/hello/Fabienþþ4) Getting started with Symfonyþ-------------------------------þþThis distribution is meant to be the starting point for your Symfonyþapplications, but it also contains some sample code that you can learn fromþand play with.þþA great way to start learning Symfony is via the [Quick Tour][4], which willþtake you through all the basic features of Symfony2.þþOnce you're feeling good, you can move onto reading the officialþ[Symfony2 book][5].þþA default bundle, `AcmeDemoBundle`, shows you Symfony2 in action. Afterþplaying with it, you can remove it by following these steps:þþ  * delete the `src/Acme` directory;þþ  * remove the routing entry referencing AcmeDemoBundle in `app/config/routing_dev.yml`;þþ  * remove the AcmeDemoBundle from the registered bundles in `app/AppKernel.php`;þþ  * remove the `web/bundles/acmedemo` directory;þþ  * remove the `security.providers`, `security.firewalls.login` andþ    `security.firewalls.secured_area` entries in the `security.yml` file orþ    tweak the security configuration to fit your needs.þþWhat's inside?þ---------------þþThe Symfony Standard Edition is configured with the following defaults:þþ  * Twig is the only configured template engine;þþ  * Doctrine ORM/DBAL is configured;þþ  * Swiftmailer is configured;þþ  * Annotations for everything are enabled.þþIt comes pre-configured with the following bundles:þþ  * **FrameworkBundle** - The core Symfony framework bundleþþ  * [**SensioFrameworkExtraBundle**][6] - Adds several enhancements, includingþ    template and routing annotation capabilityþþ  * [**DoctrineBundle**][7] - Adds support for the Doctrine ORMþþ  * [**TwigBundle**][8] - Adds support for the Twig templating engineþþ  * [**SecurityBundle**][9] - Adds security by integrating Symfony's securityþ    componentþþ  * [**SwiftmailerBundle**][10] - Adds support for Swiftmailer, a library forþ    sending emailsþþ  * [**MonologBundle**][11] - Adds support for Monolog, a logging libraryþþ  * [**AsseticBundle**][12] - Adds support for Assetic, an asset processingþ    libraryþþ  * **WebProfilerBundle** (in dev/test env) - Adds profiling functionality andþ    the web debug toolbarþþ  * **SensioDistributionBundle** (in dev/test env) - Adds functionality forþ    configuring and working with Symfony distributionsþþ  * [**SensioGeneratorBundle**][13] (in dev/test env) - Adds code generationþ    capabilitiesþþ  * **AcmeDemoBundle** (in dev/test env) - A demo bundle with some exampleþ    codeþþAll libraries and bundles included in the Symfony Standard Edition areþreleased under the MIT or BSD license.þþEnjoy!þþ[1]:  http://symfony.com/doc/2.3/book/installation.htmlþ[2]:  http://getcomposer.org/þ[3]:  http://symfony.com/downloadþ[4]:  http://symfony.com/doc/2.3/quick_tour/the_big_picture.htmlþ[5]:  http://symfony.com/doc/2.3/index.htmlþ[6]:  http://symfony.com/doc/2.3/bundles/SensioFrameworkExtraBundle/index.htmlþ[7]:  http://symfony.com/doc/2.3/book/doctrine.htmlþ[8]:  http://symfony.com/doc/2.3/book/templating.htmlþ[9]:  http://symfony.com/doc/2.3/book/security.htmlþ[10]: http://symfony.com/doc/2.3/cookbook/email.htmlþ[11]: http://symfony.com/doc/2.3/cookbook/logging/monolog.htmlþ[12]: http://symfony.com/doc/2.3/cookbook/assetic/asset_management.htmlþ[13]: http://symfony.com/doc/2.3/bundles/SensioGeneratorBundle/index.html",
Debug-Orz/Tutorial,,False,False,False,524,4,0,1,0,0,0,0,0,[2089],User,,"{'': 2, 'doc': 1, 'png': 1}",,,,3,1,0,0,0,2089,True,0,0,0,0,0,0,0,0,7,0,0,0,,,4,,
MorvanZhou/Reinforcement-learning-with-tensorflow,,False,False,False,423,62,5350,271,3537,0,0,0,0,"[43, 80, 155, 411, 466, 537, 562, 593, 600, 601]",User,Simple Reinforcement learning tutorials,"{'': 2, 'md': 1, 'jpg': 1, 'py': 56, 'png': 1, 'morvan': 1}",https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",Python,107,1,0,6,20,1162,True,36,124,10,12,1,18,1,1,7,0,0,0,,,15,"<p align=""center"">þ    <a href=""https://www.youtube.com/watch?v=pieI7rOXELI&list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba"" target=""_blank"">þ    <img width=""60%"" src=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/RL_cover.jpg"" style=""max-width:100%;"">þ    </a>þ</p>þþþ<br>þþ# Reinforcement Learning Methods and TutorialsþþIn these tutorials for reinforcement learning, it covers from the basic RL algorithms to advanced algorithms developed recent years.þþ**If you speak Chinese, visit [莫烦 Python](https://morvanzhou.github.io/tutorials/) or my [Youtube channel](https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg) for more.**þþ**As many requests about making these tutorials available in English, please find them in this playlist:** ([https://www.youtube.com/playlist?list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba](https://www.youtube.com/playlist?list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba))þþ# Table of Contentsþþ* Tutorialsþ    * [Simple entry example](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/1_command_line_reinforcement_learning)þ    * [Q-learning](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/2_Q_Learning_maze)þ    * [Sarsa](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/3_Sarsa_maze)þ    * [Sarsa(lambda)](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/4_Sarsa_lambda_maze)þ    * [Deep Q Network (DQN)](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network)þ    * [Using OpenAI Gym](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/6_OpenAI_gym)þ    * [Double DQN](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN)þ    * [DQN with Prioitized Experience Replay](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.2_Prioritized_Replay_DQN)þ    * [Dueling DQN](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN)þ    * [Policy Gradients](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/7_Policy_gradient_softmax)þ    * [Actor-Critic](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage)þ    * [Deep Deterministic Policy Gradient (DDPG)](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG)þ    * [A3C](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C)þ    * [Dyna-Q](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/11_Dyna_Q)þ    * [Proximal Policy Optimization (PPO)](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization)þ    * [Curiosity Model](/contents/Curiosity_Model), [Random Network Distillation (RND)](/contents/Curiosity_Model/Random_Network_Distillation.py)þ* [Some of my experiments](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments)þ    * [2D Car](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/2D_car)þ    * [Robot arm](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Robot_arm)þ    * [BipedalWalker](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Solve_BipedalWalker)þ    * [LunarLander](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Solve_LunarLander)þþ# Some RL Networksþ### [Deep Q Network](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network)þþ<a href=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network"">þ    <img class=""course-image"" src=""https://morvanzhou.github.io/static/results/reinforcement-learning/4-3-2.png"">þ</a>þþ### [Double DQN](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN)þþ<a href=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN"">þ    <img class=""course-image"" src=""https://morvanzhou.github.io/static/results/reinforcement-learning/4-5-3.png"">þ</a>þþ### [Dueling DQN](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN)þþ<a href=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN"">þ    <img class=""course-image"" src=""https://morvanzhou.github.io/static/results/reinforcement-learning/4-7-4.png"">þ</a>þþ### [Actor Critic](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage)þþ<a href=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage"">þ    <img class=""course-image"" src=""https://morvanzhou.github.io/static/results/reinforcement-learning/6-1-1.png"">þ</a>þþ### [Deep Deterministic Policy Gradient](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG)þþ<a href=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG"">þ    <img class=""course-image"" src=""https://morvanzhou.github.io/static/results/reinforcement-learning/6-2-2.png"">þ</a>þþ### [A3C](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C)þþ<a href=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C"">þ    <img class=""course-image"" src=""https://morvanzhou.github.io/static/results/reinforcement-learning/6-3-2.png"">þ</a>þþ### [Proximal Policy Optimization (PPO)](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization)þþ<a href=""https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization"">þ    <img class=""course-image"" src=""https://morvanzhou.github.io/static/results/reinforcement-learning/6-4-3.png"">þ</a>þþ### [Curiosity Model](/contents/Curiosity_Model)þþ<a href=""/contents/Curiosity_Model"">þ    <img class=""course-image"" src=""/contents/Curiosity_Model/Curiosity.png"">þ</a>þþ# Donationþþ*If this does help you, please consider donating to support me for better tutorials. Any contribution is greatly appreciated!*þþ<div >þ  <a href=""https://www.paypal.com/cgi-bin/webscr?cmd=_donations&amp;business=morvanzhou%40gmail%2ecom&amp;lc=C2&amp;item_name=MorvanPython&amp;currency_code=AUD&amp;bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted"">þ    <img style=""border-radius: 20px;  box-shadow: 0px 0px 10px 1px  #888888;""þ         src=""https://www.paypalobjects.com/webstatic/en_US/i/btn/png/silver-pill-paypal-44px.png""þ         alt=""Paypal""þ         height=""auto"" ></a>þ</div>þþ<div>þ  <a href=""https://www.patreon.com/morvan"">þ    <img src=""https://morvanzhou.github.io/static/img/support/patreon.jpg""þ         alt=""Patreon""þ         height=120></a>þ</div>",
judasn/Linux-Tutorial,,False,False,False,19968,315,7175,637,2354,1,5,4,1,"[36, 184, 203, 280, 327, 334, 335, 340, 350, 356]",User,《Java 程序员眼中的 Linux》,"{'': 6, 'md': 125, 'json': 1, 'jpg': 118, 'png': 7, 'sh': 32, 'cnf': 4, 'ini': 1, 'conf': 2, 'xml': 1, 'yml': 8, 'js': 1, 'crt': 1, 'key': 1, 'pem': 1, 'gif': 6}",https://github.com/judasn/Linux-Tutorial,"{'key': 'gpl-2.0', 'name': 'GNU General Public License v2.0', 'spdx_id': 'GPL-2.0', 'url': 'https://api.github.com/licenses/gpl-2.0', 'node_id': 'MDc6TGljZW5zZTg='}",Shell,937,2,0,13,11,1703,True,4,15,0,0,0,32,0,0,7,0,0,0,,,2,"## 团队 DevOps 方案参考þþ<a target=""_blank"" href=""https://coding.net/?utm_source=judasn"">þ<img id=""judasn"" src=""https://upload-images.jianshu.io/upload_images/12159-e3279861ff8655c9.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"">þ</a>þþ## 只有上云才能撑住规模化后的发展þþ- 初期技术选型上尽可能寻找云支持的þ- 在公司规模小，自建服务基本都做不到 99.999% 高可用þ- 在公司规模发展变迅速时，如果云技术和已有技术契合，迁移成本会低很多很多þ- 目前暂定只选择：[阿里云服务](https://www.aliyun.com/minisite/goods?userCode=v2zozyxz)þ- 这里罗列了阿里云常用的一些：[产品](https://github.com/cdk8s/cdk8s-team-style/blob/master/ops/aliyun.md)þþ## 新的起点þþ- [Sculptor Boot：项目思维化的《代码生成器》体系（未来可期，做个朋友吧）](https://github.com/cdk8s/sculptor-boot-generator)þ- CDK8S：<https://mp.weixin.qq.com/s/fITEVy3IEhI4HOyTXRp9ig>þ- TKey：<https://www.oschina.net/p/tkey>þþ## 初衷(Original Intention)þþ- 整理下自己所学。**但是比较随意，所以很多地方不够严谨，所以请带着批评的思维阅读。**þ- 带动更多的人进入 Linux 世界，特别是做 Java 开发的人þ- Github 项目地址，欢迎 `Fork`、`Star`：<https://github.com/judasn/Linux-Tutorial>þ- 文章中用到的一些安装包归纳整理：<http://pan.baidu.com/s/1skAwrFn>þ- Gitbook 在线阅读地址：<https://youmeek.gitbooks.io/linux-tutorial/content/>þ- **学得越多越是明白一个人的力量是不够的，我只是起了一个引子，希望你能一起参与，真心希望！！！（鞠躬）**þþ## 优秀同行推荐þþ- [Linux工具快速教程](http://linuxtools-rst.readthedocs.io/zh_CN/latest/base/index.html)þþ## 目录(Contents)þþ- [Linux 介绍](markdown-file/Linux.md)þ- [Ubuntu 介绍](markdown-file/Ubuntu.md)þ- [Ubuntu 安装](markdown-file/Ubuntu-Install.md)þ- [Ubuntu 设置（目录）](markdown-file/ubuntu-settings/ubuntu-settings-toc.md)þ- [Kali Linux 介绍和设置（目录）](markdown-file/kali-linux-settings/kali-linux-toc.md)þ- [CentOS 介绍](markdown-file/CentOS.md)þ- [CentOS 6 安装](markdown-file/CentOS-Install.md)þ- [CentOS 7 安装](markdown-file/CentOS-7-Install.md)þ- [CentOS 6 和 CentOS 7 差异](markdown-file/CentOS6-and-CentOS7.md)þ- [CentOS 设置（目录）](markdown-file/centos-settings/centos-settings-toc.md)þ- [Ubuntu 安装 VMware](markdown-file/Ubuntu-Install-VMware.md)þ- [VMware 克隆 CentOS 后网卡信息修改](markdown-file/CentOS-Virtual-Machine-Copy-Settings.md)þ- [Vim 安装、配置、快捷键列表](markdown-file/Vim-Install-And-Settings.md)þ- [SSH 免密登录](markdown-file/SSH-login-without-password.md)þ- [Bash 命令](markdown-file/Bash.md)þ- [Bash 其他常用命令](markdown-file/Bash-Other-Bash.md)þ- [安装的 rm（删除）](markdown-file/shell-safe-rm.md)þ- [Sed 命令](markdown-file/Sed.md)þ- [Linux 下常用压缩文件的解压、压缩](markdown-file/File-Extract-Compress.md)þ- [Yum 下载安装包及对应依赖包](markdown-file/Off-line-Yum-Install.md)þ- [Zsh 入门](markdown-file/Zsh.md)þ- [终端测速](markdown-file/",
j4w3d/tutorial,,False,False,False,40,20,0,1,17,0,0,0,0,[1489],User,Cloudformation tutorial,"{'md': 5, 'png': 1, 'template': 14}",,,,3,1,0,0,0,1489,False,,,,,0,0,0,0,7,0,0,0,,,2,"> Credit: https://gitlab.com/cloudformation/tutorialþþ# CFN Tutorial & Best PracticesþþWelcome to the guide. This guide will attempt to quickly help you use AWS Cloudformation, define some of the best practices and caveats and then lead you to the rest of the documentation that will help you become an expert in Cloudformation usage.þþWhere possible, I will try and link to the specific pages in the document that you can read if this guide isn't making sense. þþ## BasicsþIf you're not familiar with AWS, or you haven't done this part, each AWS authored guide has a section on getting started, you might already be an expert however it might also be worth a quick read just to make sure the reader of this guide is in the same place, please have a look at:þþhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/GettingStarted.htmlþþ## What is Cloudformation?þþIt can be best described as a tool that helps deploy infrastructure as code. The specific code is JSON formatted and when fed to CloudFormation, will direct it on what resources to create. There are other tools that do this for other products, OpenStack uses Heat (Which can also interface with other platforms), VMWare use vRealize, Azure and GCE even have their own versions but they are not as mature. Users can write templates and deploy them as stacks using the Cloudformation GUI, CLI or API. One of the great benefits of using the tool is that when it comes to cleanup, you can delete the stack and all resources that were created in it will be removed.þþStacks (Created via Templates) can be very simple, maybe a single template that just brings up a few resources like an Ec2 Instance, or they can be incredibly complex and create entire environments from the ground up. In this guide, you'll see how you can start with a simple template and eventually update it to the point of being complex (which should obviously be driven by some purpose, otherwise keep them as simple as possible).þþ### Template ComponentsþþAll templates are JSON formated and consist of the following:þParametersþMappingsþConditionsþResourcesþOutputsþThe anatomy of which looks like the following:þ```shþ{þ  ""AWSTemplateFormatVersion"" : ""version date"",þþ  ""Description"" : ""JSON string"",þþ  ""Parameters"" : {þ    set of parametersþ  },þþ  ""Mappings"" : {þ    set of mappingsþ  },þþ  ""Conditions"" : {þ    set of conditionsþ  },þþ  ""Resources"" : {þ    set of resourcesþ  },þþ  ""Outputs"" : {þ    set of outputsþ  }þ}þ```þYou can view the documentation for the Template Anatomy here:þhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.htmlþþþ**NOTE:** One of the most common syntax errors in a template is a missing comma between sibling property declarations and between resources. The other one which isn't mentioned in the manuals is an extra trailing comma after the last resource in a set of braces, which will also cause it to fail.þþþ### Template LimitsþLimits are ever changing, whenever new services and updates are released to AWS, limits can change. Some limits can also be changed by asking AWS if you have a valid reason. For Cloudformation specific limits, please check here:þhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.htmlþþþ## Template DesignþThis section is probably the hardest to write becauase the ways in which Cloudformation can be consumed are very broad. What needs to be decided first is the kind of environment that's needed. Sometimes it is sufficient to use only Cloudformation to complete the configuration and deployment of a service.þA scenario here could be that we want to deploy 2 LDAP servers into the VPC that we own, in which case we could configure these purely using Cloudformation, or they could be part of a bigger management stack that would deploy multiple tiers and services, most likely from separate child templates linked together by a parent.þþThe following steps in this repo are intended as a fast track into seeing how templates and Cloudformation usage can evolve over time. At the beginning of any project most templates are a single file, however over time and with discovery of new options or services that are needed, templates split apart and operate in a Parent/Child model, or become separate entities managed by a higher level orchestration tool, maybe Jenkins.þþhttps://gitlab.com/cloudformation/tutorial/tree/master/step1þþhttps://gitlab.com/cloudformation/tutorial/tree/master/step2þþhttps://gitlab.com/cloudformation/tutorial/tree/master/step3þþhttps://gitlab.com/cloudformation/tutorial/tree/master/step4þþIf you intend to follow the guide because you can't wait to get your hands dirty, it is worth coming back and reading the rest of this page to understand some of the pitfalls and caveats of using Cloudformation as there are some activities that aren't obvious which can influence the way you deploy, or even break your existing resources.þþ# Best PracticesþþWithout repeating what has already been written by the subject matter experts, please consider this:þhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/best-practices.htmlþþI have commented on each of the segments in terms of experience that we've had and how we used the best practice.þþ## Organize Your Stacks By Lifecycle and OwnershipþIn this context, you can have various types of application, service or component that will live in an AWS environment. Initially you might just build a bastion, like in the Step1 of the tutorial above. On it's own that might be pretty useless, however if you're doing it again and again for a project and you need to deploy multiple bastion servers, (or maybe a jumpbox fo developers), then it makes sense to drive it with a template. þThe same resource here could be deployed within a larger stack, or on it's own. For example, if you had a typical dev, test and prod environmet and this bastion happened to be for various Ops people to use for administration and troubleshooting in each environment, you could integrate this into the environment so that it's deployed whenever the platform is. Alternatively, this might be a host that is supplied to each single user and therefore could be deployed by Jenkins, whereby Jenkins will interact with the Cloudformation service to deploy the template. (see this link for more of an example: http://awsbits.blogspot.co.uk/2015/01/jenkins-packer-puppet-and-aws.html)þþ## Use IAM to Control AccessþWhile this section talks about he benefits of restricting what users can do with CloudFormation, you can also use CloudFormation to provision IAM Resources. IAM Roles are used by instances as a replacement to storing credentials on the host. For example, during the deploy of your first stack (let's call it a management tier), you may have all your configuration files in S3. To access S3, you could use keys/credentials, however that isn't safe to store on your host. The safer way is to create a role that can be applied to the host when it's built. The role will contain 'GetObject' for the bucket that hosts the configuration files allowing the instance to build from config files located in S3.þþ## Verify Quotas for All Resource TypesþThere have been a few occasions where limits have been hit and CloudFormation 'CreateStack' functions have failed. It is simple enough to request limit extentions through the console, however it is also good to understand whether limit increases or architectural changes are needed to avoid this scenario. Prior to deploying anything into your VPC, work out what the limits are and whether you have enough headroom. Trusted Advisor can be used to assist with this task, making it easier to find these figures. If there is no access to Trusted Advisor, the same details can be taken from the Ec2 > Limits section of the console.þþ## Reuse Templates to Replicate Stacks in Multiple EnvironmentsþAdding Mappings, Conditions and Parameters to templates mean that you can use a single set (parent/child) of templates to deploy multiple environments in the same region, or even in different region if you make use of mappings to 'find' the correct values for the region.þHere is an example of a condition that uses a parameter to govern the type of instance that will be deployed:þþ```shþ{þ  ""AWSTemplateFormatVersion"" : ""2010-09-09"",þ  ""Description"" : ""Some stack that does some thing."",þþ  ""Parameters"" : {þ    ""StackType"" : {þ      ""Description"": ""Allowed values are 'dev', 'qa' or 'prd'. You must specify the stack type."",þ      ""Type"": ""String"",þ      ""AllowedValues"" : [""dev"", ""qa"", ""prd""]þ    }þ  },þþ  ""Conditions"" : {þ    þ    ""BuildDev"" : {þ      ""Fn::Equals"" : [ { ""Ref"" : ""StackType""}, ""dev""]þ    },þ    þ    ""BuildQa"" : {þ      ""Fn::Equals"" : [ { ""Ref"" : ""StackType""}, ""qa""]þ    },þ            þ    ""BuildPrd"" : {þ       ""Fn::Equals"" : [ { ""Ref"" : ""StackType""}, ""prd"" ]þ    }þ  þ  },þ  þ  ""Resources"": {þ    þ    ""BastionInstance"" : {þ      ""Type"" : ""AWS::EC2::Instance"",þ      ""Properties"" : {þ        ""KeyName"" : { ""Ref"" : ""KeyName"" },þ        ""InstanceType"" : þ          { ""Fn::If"" : [ ""BuildPrd"", ""m3.large"",þ           { ""Fn::If"" : [ ""BuildQa"",""m1.small"", þ             ""t1.micro"" þ           ]}þ        ]},þ        ""ImageId"" : { ""Fn::FindInMap"" : [ ""ImageMap"", { ""Ref"" : ""AWS::Region"" }, ""BastionAMI"" ]},þ        ""SecurityGroups"" : [{ ""Ref"" : ""BastionSecurityGroup"" } ],þ        ""SubnetId"" : { ""Ref"" : ""PubNet01"" },þ        ""AssociatePublicIpAddress"" : ""true"",þ      }þ    }þ  }þ  þ}þ```þHere, we're using a function that will allow us to specify the type of environment that we're going to provision, if we're making a 'prd' environment, then the bastion will get an m3.large instance because the 'BuildPrd' condition will be true ('prd'). Think of this like an IF loop, if the BuildPrd condition wasn't true, we move on to the next action, which is another IF statement that asks, 'ok, then is it QA?'. If BuildQa is true, then we get an m1.small instance type and if that condition wasn't met, for all other environments (in this case there is no parameter constraint for StackType, so it could be a value of 'dev' or 'notdev' the instance will be a t1.micro.þþObviously, this isn't necessarily a real world scenario that we'd suggest using for Bastions, but it shows how we can be dynamic about the resource provisioned using a single template for multiple regions and/or environments.þþUsing mappings in addition to this, you could also run this template in multiple regions by 'Finding' the relevant AMI ID for the region you're working in, like this:þþ```shþ{þ  ""AWSTemplateFormatVersion"" : ""2010-09-09"",þ  ""Description"" : ""Some stack that does some thing."",þþ  ""Mappings"" : {þ    þ    ""ImageMap"" : {þ      ""eu-west-1"" : { ""NatAMI"" : ""ami-14913f63"", ""BastionAMI"" : ""ami-9d23aeea"", ""JenkinsAMI"" : ""ami-9d23aeea"", ""GitLabAMI"" : ""ami-9d23aeea"", ""LdapAMI"" : ""ami-9d23aeea"" },þ      ""us-west-2"" : { ""NatAMI"" : ""ami-290f4119"", ""BastionAMI"" : ""ami-dfc39aef"", ""JenkinsAMI"" : ""ami-dfc39aef"", ""GitLabAMI"" : ""ami-dfc39aef"", ""LdapAMI"" : ""ami-dfc39aef"" }þ    }þ    þ  },þþ  ""Resources"": {þ    þ    ""BastionInstance"" : {þ      ""Type"" : ""AWS::EC2::Instance"",þ      ""Properties"" : {þ        ""KeyName"" : { ""Ref"" : ""KeyName"" },þ        ""InstanceType"" : þ          { ""Fn::If"" : [ ""BuildPrd"", ""m3.large"",þ           { ""Fn::If"" : [ ""BuildQa"",""m1.small"", þ             ""t1.micro"" þ           ]}þ        ]},þ        ""ImageId"" : { ""Fn::FindInMap"" : [ ""ImageMap"", { ""Ref"" : ""AWS::Region"" }, ""BastionAMI"" ]},þ        ""SecurityGroups"" : [{ ""Ref"" : ""BastionSecurityGroup"" } ],þ        ""SubnetId"" : { ""Ref"" : ""PubNet01"" },þ        ""AssociatePublicIpAddress"" : ""true"",þ      }þ    }þ  }þ}þ```þþIn the case above, we could have run this in us-west-2 and we'd have ended up with ami-9d23aeea as the AMI being used for the bastion, if we'd used eu-west-1, we'd have been using ami-dfc39aef. These images are identical but they are bound to the region they're in, so when you're making templates that are required to run in multiple regions the AMIs need to be replicated.þþ## Use Nested Stacks to Reuse Common Template PatternsþþRather than repeat what has already been discussed in the blog below, it's definitely beneficial to group your templates:þhttp://awsbits.blogspot.co.uk/2015/01/basic-cloudformation-template-design.htmlþþAt a high level, we've found that we can group in various ways, however the demarcation between doing it in CloudFormation or doing it in a higher level automation tool does help govern template heirarchy. The second paragraph in the AWS best practice goes further and suggests abstracting single functions into a template that is reused by multiple stacks/users, the owner of that template can then update all ELBs in the estate just by updating the single template - which of course means all users of the template will need to be notified as they'll need to update their stacks, unless they're joined in the parent/child examples given in the steps and on the blog post.þþStep 2 introduces the condept of using the AWS::CloudFormation::Stack resource:þhttps://gitlab.com/cloudformation/tutorial/tree/master/step2þþ## Do Not Embed Credentials in Your TemplatesþAbsolute no no.þEnough said!þBut as stated, where it's unavoidable use the NoEcho value to prevent people reading the credential from the CloudFormation Management Console. If a user does get a copy of the templates and you do hard code passwords, they'll be able to read them in plain text. It is far better to never set the default for these fields and only enter them at the point they're needed, whilst using the NoEcho function as well.þþ## Use Parameter ConstraintsþDrawing on best practice above, you could use something like this, which uses NoEcho as well as constraints to force the password to be complex.þþ```shþ""SomePassword"" : {þ      ""NoEcho"": ""true"",þ      ""Description"" : ""The database admin account password"",þ      ""Type"": ""String"",þ      ""MinLength"": ""8"",þ      ""MaxLength"": ""41"",þ      ""AllowedPattern"" : ""[a-zA-Z0-9]*"",þ      ""ConstraintDescription"" : ""must contain only alphanumeric characters.""þ},þ```þþNote there is no default field here. These constraints can be applied to other Paramters, like this Environment Paramter:þ```shþ""Environment"" : {þ      ""Description"" : ""Stack environment"",þ      ""Type"": ""String"",þ      ""Default"": ""test"",þ      ""AllowedValues"" : [""prod"", ""test""],þ      ""ConstraintDescription"" : ""must specify 'prod' or 'test', no other values are allowed.""þ},þ```þþ## Use AWS::CloudFormation::Init to Deploy Software Applications on Amazon EC2 InstancesþThis is a very valuable tool. Initially we attempted to do everything with it, however as time goes by, it's better to find a demarcation point between preparing a system and configuring/installing applications. Take user creation for example, or maybe LDAP database population, or maybe even configuring a Jenkins host, while it is possible to do this in CloudFormation, it can actually be easier and more fruitful if the installation and configuration are moved to more powerful tools like Puppet, Chef or Ansible. The following scenario is one we have tried and tested for an application that needs scaling:þþProvision Environment with CFN: AZs, Network Routes, Subnets, Security Groups, IAM Roles, Tags (Tags is the demarcation between the team that provisions the environment and those that provision the app)þProvision the App: Using Jenkins, run a CFN template that uses values from the environment aboveþþJenkins ties the two work flows together using tags, we can re-deploy the applicaiton again and again into multiple stacks and the only change is the DNS/LoadBalancer entry point for the applicaiton. þþ## Validate Templates Before Using ThemþThis goes without saying really. Most people usually start with the Console, which automatically verifies the template after putting in the parameters and before actually building/updating a stack. Refere to this page for the usage of the CLI:þhttp://docs.aws.amazon.com/cli/latest/reference/cloudformation/validate-template.htmlþþ## Manage All Stack Resources Through AWS CloudFormationþThis is very important!þþIf you try and delete a security group (as an example) and it has another host using it that is not controlled by CloudFormation, when you try and delete the action will fail, sometimes this is catastrophic and you will be left with the 'ROLLBACK FAILED' condition, see why that's so bad here:þhttp://awsbits.blogspot.co.uk/2014/08/the-dreaded-updaterollbackfailed.htmlþþWhenever you want to add or remove anything from a stack/environment, it is best to do it with CloudFormation. This subject looks toward your design choices for the demarcation between using CloudFormation and other higher level automation tools, such as Jenkins. As an example, if you manage security groups and subnets in CloudFormation, you shouldn't begin provisioning them in some other way (manually, or via Jenkins), unless you plan to migrate the strategy for creating them entirely.þþ## Use Stack PoliciesþUsing Stack Policies is another way to protect the environment that you have built using CloudFormation from accidental change or attempted deletion. For example, if your environment uses an RDS backend (msyql or postresql) which you need constantly available (multiple AZ) and backed up (db snapshots), which is managed by a separate team and provisioned by the Ops guys in your team, it is good to protect this from any accidental changes when you begin allowing other members of the organisation to run CloudFormation tasks using an upstream tool, such as Jenkins. Although it would take quite a bit of imagination to do damage to the underlying CloudFormation controlled environment if you have permissions set correctly for other resources, it is still possible, so these policies give it a little extra protection.þþAs per the documentation, follow the links in the best practices page and read about how to do it.þþ## Use AWS CloudTrail to Log AWS CloudFormation CallsþIn and of itself, come audit time CloudFormation templates are excellent support for providing a picture of what is and isn't installed/permitted. As CloudFormation is adopted throughout the business and it's used across all all teams in different ways, this tool will assist in tracking who makes the changes. This tied together with other audit trails will produce information on every action ever taken against a stack, which can be vital in Audit, issue troubleshooting, triage and security breach.þþ## Use Code Reviews and Revision Controls to Manage Your TemplatesþFinally, put the templates in a Revision Control System. Make sure you can check out, check in and branch the code, just like you would for any software application, that way you can operate in the same way, making smaller changes more often as well as having all previous known versions of the architecture and all changes that have been made.þþþ# TutorialsþNow you're armed with a bit of background on CloudFormation and how it can be used, it's worth following the examples to get the feel for creating stacks. Start with Step1 that creates a simple Amazon Linux Instance and allows you to connect to it via SSH.",
windiest/Front-end-tutorial,,False,False,False,616,1,4256,311,2253,0,0,0,0,"[1146, 1208, 1246, 1263, 1274, 1296, 1305, 1308, 1309, 1310]",User,":smiley_cat:猫的前端回忆录 Cat's front memory, these share data are from my usual work and learning, hoping to help you, and hoping slowly improve, if you like you can star",{'md': 1},,,,171,1,0,8,0,1766,True,7,2,0,0,3,12,1,0,7,0,0,0,,,3,":smiley_cat:_These share data are from my usual work and learning，hoping to help you，If you like you can star_þþ更多详情可关注作者:小猫[wscat](https://github.com/Wscats)和猫主人[windiest](https://github.com/windiest),谢谢~þþ## Javascriptþ| Article | Article |þ| --------- | --------- |þ|[Javascript深浅拷贝](https://github.com/Wscats/Good-text-Share/issues/57)|[Javascript中的apply和call继承](https://github.com/Wscats/Good-text-Share/issues/56)|þ|[Javascript的jsonp原理](https://github.com/Wscats/Good-text-Share/issues/55)|[Javascript监听触摸事件](https://github.com/Wscats/Good-text-Share/issues/49)|þ|[Javascript中的var self = this](https://github.com/Wscats/Good-text-Share/issues/52)|[Javascript面向对象编程](https://github.com/Wscats/Good-text-Share/issues/32)|þ|[Javascript滑屏切换场景](https://github.com/Wscats/Good-text-Share/issues/14)|[Javascript获取经纬度，关于调用百度API的问题](https://github.com/Wscats/Good-text-Share/issues/16)|þ|[妙用Javascript运算符](https://github.com/Wscats/Good-text-Share/issues/3)|[深入理解Javascript函数编程](https://github.com/Wscats/Good-text-Share/issues/1)|þ|[Javascript的setTimeout详细用例](https://github.com/Wscats/Good-text-Share/issues/4)|[sessionstorage，localstorage和cookie](https://github.com/Wscats/Good-text-Share/issues/42)|þ|[JS日期对比](https://github.com/Wscats/Good-text-Share/issues/11)|[JSONP参考文章](https://github.com/Wscats/Good-text-Share/issues/10)|þ|[Javascript的createElement](https://wscats.github.io/angular-demo/createElement.html)|[Javascript的createDocumentFragment](https://wscats.github.io/angular-demo/createDocumentFragment.html)|þ|[sessionStorage和localStorage](https://wscats.github.io/angular-demo/sessionStoragelocalStorage.html)|[像素帧动画](https://wscats.github.io/angular-demo/像素动画.html)|þ| **Reference** | **Reference** |þ|[收集最全前端学习资料](https://github.com/windiest/Front-end-tutorial)|[最全前端教程-猫的回忆录](https://github.com/Wscats/Good-text-Share)|þ|[JavaScript中的this陷阱的最全收集--没有之一](https://segmentfault.com/a/1190000002640298)|[JS函数式编程指南](https://llh911001.gitbooks.io/mostly-adequate-guide-chinese/content/ch1.html)|þ|[JavaScript Promise迷你书（中文版）](http://liubin.github.io/promises-book)|[阮一峰 Javascript](http://javascript.ruanyifeng.com)|þ|[前端 TOP 100](https://www.awesomes.cn/rank)|[小白的零基础JavaScript全栈教程](http://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000)|þþ## UIþ| Reference | Reference |þ| --------- | --------- |þ|[WeUI](https://github.com/weui/weui)|[Bootstrap](http://www.bootcss.com)|þ|[MUI-最接近原生APP体验的高性能前端框架](http://dev.dcloud.net.cn/mui/)|[Amaze UI中国首个开源HTML5跨屏前端框架](http://amazeui.org)|þ|[Frozen UI](http://frozenui.github.io/)|[Foundation](http://foundation.zurb.com/)|þ|[SUI](http://sui.taobao.org/sui/docs/)|[ZUI](https://github.com/easysoft/zui)|þ|[淘宝HTML5前端框架](http://m.sui.taobao.org)|[KISSY - 阿里前端JavaScript库](http://docs.kissyui.com)|þ|[网易Nej - Nice Easy Javascript](http://nej.netease.com)|[Kendo UI MVVM Demo](http://demos.telerik.com/kendo-ui/mvvm/index)|þ|[Smart UI](http://smartui.chinamzz.com)|[雅虎UI - CSS UI](http://developer.yahoo.com/yui/grids)|þþ## CSSþ| Article | Article |þ| --------- | --------- |þ|[CSS Flex布局](https://github.com/Wscats/Good-text-Share/issues/41)|[移动前端开发CSS3](https://github.com/Wscats/Good-text-Share/issues/38)|þ|[响应式布局 媒体查询](https://github.com/Wscats/Good-text-Share/issues/43)|[CSS图片响应式布局](https://github.com/Wscats/Good-text-Share/issues/34)|þ|[lessDemo的less文件](https://wscats.github.io/angular-demo/stylesheets/styles.less)||þ| **Reference** | **Reference** |þ|[CSS 语法参考](http://tympanus.net/codrops/css_reference)|[CSS3动画手册](http://isux.tencent.com/css3/index.html)|þ|[腾讯css3动画制作工具](http://isux.tencent.com/css3/tools.html)|[animate.css](http://daneden.github.io/animate.css)|þ|[Animated Books with CSS 3D Transforms](http://tympanus.net/Development/AnimatedBooks/)|[Browserhacks](http://browserhacks.com/)|þþ## HTMLþ| Article | Article |þ| --------- | --------- |þ[HTML5有哪些让你惊艳的demo](http://www.zhihu.com/question/24398907)|[Wallpaperbetter](http://www.wallpaperbetter.com/)|þþ## Angularþ| Article | Angular文档 |þ| --------- | --------- |þ|[Angular源码解读publishExternalAPI函数](https://github.com/Wscats/Good-text-Share/issues/26)|[Angular源码解读setupModuleLoader函数](https://github.com/Wscats/Good-text-Share/issues/25)|þ|[Angular的ng-style用法](https://github.com/Wscats/Good-text-Share/issues/35)|[Angular判断在那个浏览器下打开的服务](https://github.com/Wscats/Good-text-Share/issues/29)|þ|[Angular文字折叠展开组件的原理分析](https://github.com/Wscats/Good-text-Share/issues/28)|[Angular服务Request异步请求的详细分析](https://github.com/Wscats/Good-text-Share/issues/21)|þ|[Angular自定义service服务详解](https://github.com/Wscats/Good-text-Share/issues/24)|[Angular自定义判断上一页是否存在的服务](https://github.com/Wscats/Good-text-Share/issues/22)|þ|[Angular操作cookies方法](https://github.com/Wscats/Good-text-Share/issues/19)|[Angular打印错误的minErr函数](https://github.com/Wscats/Good-text-Share/issues/18)|þ|[Angular的fromJson与toJson方法](https://github.com/Wscats/Good-text-Share/issues/17)|[Angular用ng-repeat生成表单并绑定ng-click时的一个细节](https://github.com/Wscats/Good-text-Share/issues/12)|þ|[Angular的run方法巧妙运用](https://github.com/Wscats/Good-text-Share/issues/6)|[Angular处理Html转义问题](https://github.com/Wscats/Good-text-Share/issues/5)|þ|[ng-repeat绑定事件和嵌套](ng-repeat绑定事件和嵌套)|[Angular的post请求后台接受不了数据的解决方法](https://github.com/Wscats/angular-demo/issues/4)|þ|[ionic总结](https://github.com/Wscats/angular-demo/issues/19)|[ui-route和ng-route](https://github.com/Wscats/angular-demo/issues/17)|þ|[ng-options&&ng-switch](https://github.com/Wscats/angular-demo/issues/15)|[directive组件作用域](https://github.com/Wscats/angular-demo/issues/14)|þ|[表单认证](https://github.com/Wscats/angular-demo/issues/13)|[$broadcast,$emit and $on](https://github.com/Wscats/angular-demo/issues/11)|þ|[自定义过滤器](https://github.com/Wscats/angular-demo/issues/9)|[自定义手势指令ng-touch](https://github.com/Wscats/angular-demo/issues/8)|þ|[ng-animate](https://github.com/Wscats/angular-demo/issues/7)|[单页面应用的技术点](https://github.com/Wscats/angular-demo/issues/3)|þ| **Guess you like** |**AppDemo**|þ|[Angular商城Demo](https://wscats.github.io/angular-demo/spa/mobie-b2bdemo1/index.html)|[Angular的Cnode社区](https://wscats.github.io/angular-demo/spa/CNode/index.html)|þ|[AngularStovepipe](https://wscats.github.io/angular-demo/spa/Stovepipe/index.html)|[Angular的新闻客户端](https://wscats.github.io/angular-demo/spa/TT/index.html)|þ|[Angular商城Demo](https://wscats.github.io/angular-demo/spa/mobie-b2bdemo1/index.html)|[Angular的Cnode社区](https://wscats.github.io/angular-demo/spa/CNode/index.html)|þ|[Angular内联编辑器](https://wscats.github.io/angular-demo/angularjs5examples/inline-editor/index.html)|[Angular即时搜索](https://wscats.github.io/angular-demo/angularjs5examples/instant-search/index.html)|þ|[Angular导航菜单](https://wscats.github.io/angular-demo/angularjs5examples/navigation-menu/index.html)|[Angular订单表单](https://wscats.github.io/angular-demo/angularjs5examples/order-form/index.html)|þ|[Angular切换网格](https://wscats.github.io/angular-demo/angularjs5examples/switchable-grid/index.html)|[Angular新闻＋WEUI DEMO](https://wscats.github.io/angular-demo/spa/news/index.html) [源码](https://github.com/Wscats/angular-demo/tree/gh-pages/spa/NodeServerAndApi-Weui-News)|þ| **Controller** |**控制器**|þ|[Angular控制器demo](https://wscats.github.io/angular-demo/view/student.html)||þ| **SPA DEMO** |**单页面应用**|þ|[Angular+Weui单页面应用DEMO-每日笑话](https://wscats.github.io/angular-demo/weui每日笑话.html)||þ| **Service** |**服务**|þ|[Angular自定义服务的常用方法](https://github.com/Wscats/angular-demo/blob/gh-pages/%E5%B8%B8%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1%E6%96%B9%E6%B3%95.md)|[Angular部分服务demo](https://wscats.github.io/angular-demo/部分服务demo.html)|þ|[Angular自定义Canvas画图服务](https://wscats.github.io/angular-demo/Angular自定义Canvas画图服务.html)|[Angular自定义http服务 面向对象封装](https://wscats.github.io/angular-demo/自定义http服务.html)|þ| **Directive** |**组件与指令**|þ|[Angular自定义手势指令](https://wscats.github.io/angular-demo/自定义手势事件.html)|[Angular自定义轮播图组件](https://wscats.github.io/angular-demo/自定义directive轮播图.html)|þ|[Angular自定义下拉刷新组件1](https://wscats.github.io/angular-demo/下拉刷新.html)|[Angular自定义下拉刷新组件2](https://wscats.github.io/angular-demo/Angular自定义下拉刷新组件.html)|þ| **Router** |**路由**|þ|[Angular路由嵌套](https://wscats.github.io/angular-demo/UI路由嵌套DEMO.html)|[Angular路由单页多个ui-view](https://wscats.github.io/angular-demo/uiRoute/index.html)|þ| **Filter** |**过滤器**|þ|[Angular自带过滤器](https://wscats.github.io/angular-demo/angular自带过滤器.html)|[Angular自定义关键词检索过滤器](https://wscats.github.io/angular-demo/自定义关键词检索过滤器.html)|þ| **Animate** |**动画**|þ|[Angular ng-animate动画1](https://wscats.github.io/angular-demo/ng-animate动画.html)|[Angular ng-animate动画2](https://wscats.github.io/angular-demo/ng-animate动画2.html)|þ| **Other** |**其他**|þ|[Angular中使用iframe](https://wscats.github.io/angular-demo/iframesdemo.html)|[Angular三级联动(1)](https://wscats.github.io/angular-demo/%E4%B8%89%E7%BA%A7%E8%81%94%E5%8A%A8.html)|þ|[Angular中使用ng-switch](https://wscats.github.io/angular-demo/ngSwitch.html)|[百度定位DEMO](https://wscats.github.io/angular-demo/百度地图定位DEMO.html)|þ|[Angular三级联动(2)](https://wscats.github.io/angular-demo/三级联动改进.html)|[Angular事件监听](https://wscats.github.io/angular-demo/事件监听.html)|þ|[jQuery模拟ng-repeat](https://wscats.github.io/angular-demo/jquery模拟ng-repeat.html)|[lessDemo](https://wscats.github.io/angular-demo/lessDemo.html)|þ|[Angular自定义cookie服务和ngCookie的使用](https://wscats.github.io/angular-demo/ngCookie.html)|[图灵机器人](https://wscats.github.io/angular-demo/图灵机器人.html)|þ|[Angular利用angular.module()实现模块化](https://wscats.github.io/angular-demo/angular模块化.html)|[Angular的form表单验证](https://wscats.github.io/angular-demo/form表单验证.html)|þ|[Angular的ng-repeat嵌套](https://wscats.github.io/angular-demo/ng-repeat嵌套.html)|[Angular利用angular.module()实现模块化2](https://wscats.github.io/angular-demo/angular模块化2.html)|þ| **PHP** | **PHP** |þ|[PHP CURL请求的小细节](https://github.com/Wscats/Good-text-Share/issues/53)||þ| **Reference** | **Reference** |þ|[最流行的PHP 代码规范](https://segmentfault.com/a/1190000000443795)|[最流行的PHP 代码规范](https://github.com/hfcorriez/fig-standards/blob/zh_CN/%E6%8E%A5%E5%8F%97/PSR-2-coding-style-guide.md)|þ|[Angular.js的一些学习资源](http://blog.aijc.net/AngularLearning/)|[Angularjs中文社区](http://angularjs.cn)|þ|[一些扩展Angular UI组件](https://github.com/angular-ui)|[Angular UI](http://mgcrea.github.io/angular-strap)|þ|[AngularJS在线教程](http://each.sinaapp.com/angular)|[Angular学习笔记](http://www.zouyesheng.com/angular.html)|þþ## Reactþ| React | Reference |þ| --------- | --------- |þ|[React教程 菜鸟教程](http://www.runoob.com/react/react-tutorial.html)|[React Router 使用教程](http://www.ruanyifeng.com/blog/2016/05/react_router.html?utm_source=tool.lu)|þ|[React开发中文手册-极客学院](http://wiki.jikexueyuan.com/project/react/)|[React教程-汇智网](http://www.hubwiz.com/course/552762019964049d1872fc88/)|þ|[React.js快速开始](http://www.phperz.com/article/15/0712/140537.html#)|[Reactjs 2016最佳实践](http://www.alloyteam.com/2016/01/reactjs-best-practices-for-2016/)|þ|[React 入门教程](https://hulufei.gitbooks.io/react-tutorial/content/introduction.html)|[汇智网 React教程](http://www.hubwiz.com/course/552762019964049d1872fc88/?ch=alloyteam)|þ|[轻松入门React和Webpack](https://segmentfault.com/a/1190000002767365)|[React中文索引](http://nav.react-china.org/#docs)|þ|[Redux 中文文档](http://cn.redux.js.org/)|[React Router官方文档中文翻译](https://github.com/react-guide/react-router-cn)|þ|[React入门教程](http://www.cnblogs.com/kunyashaw/p/5619256.html)|[React介绍及实践教程](http://www.ibm.com/developerworks/cn/web/1509_dongyue_react/index.html)|þ|[React.js 官方网址](https://facebook.github.io/react/index.html)|[React.js 官方文档](https://facebook.github.io/react/docs/getting-started.html)|þ|[React.js material UI](http://material-ui.com/#)|[React.js TouchstoneJS UI](http://touchstonejs.io)|þ|[React.js amazeui UI](http://amazeui.org/react)|[React 入门实例教程 - 阮一峰](http://www.ruanyifeng.com/blog/2015/03/react.html)|þ|[React Native 中文版](http://wiki.jikexueyuan.com/project/react-native)|[Webpack 和 React 小书 - gitbook](https://fakefish.github.io/react-webpack-cookbook)|þþ## Vueþ| Vue |AppDemo|Demo|þ| --------- | --------- | --------- |þ|[NewsDemo](https://wscats.github.io/vue-demo/news/index.html)|[vue计算属性](https://wscats.github.io/vue-demo/vue计算属性.html)|[vue生命周期](https://wscats.github.io/vue-demo/vue生命周期.html)|þ| **Article** |**Vue文档**||þ|[Vue-cli脚手架](https://github.com/Wscats/vue-demo/issues/2)|[Vue组件](https://github.com/Wscats/vue-demo/issues/3)|[vue自定义指令](https://github.com/Wscats/vue-demo/issues/8)|þ|[Vue过渡动画](https://github.com/Wscats/vue-demo/issues/9)|[Vue指令](https://github.com/Wscats/vue-demo/issues/7)|[Vue api文档](https://github.com/Wscats/vue-demo/issues/6)|þ|[Vue执行ajax请求](https://github.com/Wscats/vue-demo/issues/5)|[vue实现类似angular服务的方法](https://github.com/Wscats/vue-demo/issues/4)|[Vue源码参考文档](https://github.com/Wscats/vue-demo/issues/10)|þ| **Router** |**路由**||þ|[路由demo](https://wscats.github.io/vue-demo/路由.html)|[路由demo2](https://wscats.github.io/vue-demo/路由2.html)||þ| **Directive** |**指令**||þ|[指令demo](https://wscats.github.io/vue-demo/指令.html)|[自定义指令demo](https://wscats.github.io/vue-demo/自定义指令.html)|[滑动手势demo](https://wscats.github.io/vue-demo/滑动手势指令.html)|þ| **Filter** |**过滤器**||þ|[过滤器demo](https://wscats.github.io/vue-demo/过滤器.html)|[过滤器实现分页demo](https://wscats.github.io/vue-demo/vue使用过滤器实现分页.html)|[过滤器读写数据](https://wscats.github.io/vue-demo/vue过滤器读写数据.html)|þ| **Transition** |**过渡**||þ|[过渡demo](https://wscats.github.io/vue-demo/过渡.html)|[过渡demo2](https://wscats.github.io/vue-demo/过渡2.html)||þ| **Form** |**表单**||þ|[获取表单值](https://wscats.github.io/vue-demo/vue获取表单值.html)|||þ| **Computed** |**计算**||þ|[计算属性](https://wscats.github.io/vue-demo/vue计算属性.html)|||þ| Component |组件||þ|[组件demo](https://wscats.github.io/vue-demo/组件.html)|||þ| **Reference** | **Reference** | **Reference** |þ|[Vue官网](http://cn.vuejs.org)|[Vue论坛](http://forum.vuejs.org)|[Awesome-vue](https://github.com/vuejs/awesome-vue)|þþþ## Nodeþ| Node | Article |þ| --------- | --------- |þ|[node技巧](https://github.com/Wscats/Good-text-Share/issues/44)|[NodeJs静态服务器](https://github.com/Wscats/angular-demo/tree/gh-pages/diyNodeServer)|þ| **Reference** | **Reference** |þ|[Node.js 包教不包会](https://github.com/alsotang/node-lessons)|[七天学会NodeJS](http://nqdeng.github.io/7-days-nodejs/)|þ|[从零开始nodejs系列文章](http://blog.fens.me/series-nodejs)|[Node入门](http://www.nodebeginner.org/index-zh-cn.html)|þ|[Node初学者入门，一本全面的NodeJS教程](http://ourjs.com/detail/529ca5950cb6498814000005)||þþ## Gulp þ| Gulp | Article |þ| --------- | --------- |þ|[Gulp Demo](https://github.com/Wscats/glup)||þ| **Gulp** | **Reference** |þ|[Gulp官网](http://gulpjs.com)|[Gulp中文网](http://www.gulpjs.com.cn)|þ|[Gulp资料收集](https://github.com/Platform-CUF/use-gulp)|[Gulp：任务自动管理工具 - ruanyifeng](http://javascript.ruanyifeng.com/tool/gulp.html)|þ|[Gulp插件](http://gulpjs.com/plugins])|[Gulp不完全入门教程](http://www.ido321.com/1622.html)|þ|[Gulp 入门指南](https://github.com/nimojs/gulp-book)||þþ## 其他þ| Other | Article |þ| --------- | --------- |þ|[关于Pornographic website的一些前端分析](https://github.com/Wscats/node-demo/issues/4)|[微信公众号开发](https://github.com/Wscats/Good-text-Share/issues/50)|þ|[Atom技巧总结](https://github.com/Wscats/Good-text-Share/issues/30)|[Mac小技巧](https://github.com/Wscats/Good-text-Share/issues/46)|þ|[CSDN页面内JS跳转脚本](https://github.com/Wscats/Good-text-Share/issues/9)|[CSDN博客隐藏配置](https://github.com/Wscats/Good-text-Share/issues/8)|þ|[百度设置小度机器人出现](https://github.com/Wscats/Good-text-Share/issues/7)|[前端冷知识，妙用浏览器地址栏](https://github.com/Wscats/Good-text-Share/issues/2)|þ|[Vim笔记](https://github.com/Wscats/Good-text-Share/issues/27)|[Cordova配置&&Ionic配置（WebApp混合开发环境）](https://github.com/Wscats/Good-text-Share/issues/48)|þ|[IE8及以下按钮超链接无法跳转的问题](https://github.com/Wscats/Good-text-Share/issues/33)||þþ## 分享功能þ| Share | Reference |þ| --------- | --------- |þ|[百度分享(PC)](http://share.baidu.com)|[JiaThis(PC)](http://jiathis.com)|þ|[社会化分享组件(Mobile)](http://developer.baidu.com/soc/share)|[ShareSDK轻松实现社会化功能(Mobile)](http://www.mob.com)|þ|[友盟分享(Mobile)](http://dev.umeng.com/social/android/quick-integration)||þþ## 在线演示þ| Reference | Reference |þ| --------- | --------- |þ|[js 在线编辑 - runjs](http://runjs.cn)|[js 在线编辑 - jsbin](http://jsbin.com)|þ|[js 在线编辑 - codepen](http://codepen.io)|[js 在线编辑 - jsfiddle](http://jsfiddle.net)|þ|[java 在线编辑 - runjs](http://ideone.com)|[js 在线编辑 - hcharts](http://code.hcharts.cn)|þ|[js 在线编辑 - jsdm](http://jsdm.com)|[sql 在线编辑 - sqlfiddle](http://sqlfiddle.com)|þ|[mozilla 在线编辑器](https://thimble.mozilla.org)||þþ## 富文本编辑器þ| Reference | Reference |þ| --------- | --------- |þ|[百度ueditor](http://ueditor.baidu.com/website)|[ckeditor](http://ckeditor.com)|þ|[tinymce](https://www.tinymce.com)|[kindeditor](http://kindeditor.net)|þ|[wysiwyg](http://www.bootcss.com/p/bootstrap-wysiwyg)|[BachEditor](http://integ.github.io/BachEditor)|þ|[simditor](https://github.com/mycolorway/simditor)|[summernote](https://github.com/summernote/summernote)|þ|[Squire](http://neilj.github.io/Squire)|[wangEditor](https://github.com/wangfupeng1988/wangEditor)|þþ## Chromeþ| Reference | Reference |þ| --------- | --------- |þ|[Chrome - 基础](http://www.cnblogs.com/constantince/p/4565261.html)|[Chrome - 进阶](http://www.cnblogs.com/constantince/p/4579121.html)|þ|[Chrome - 性能](http://www.cnblogs.com/constantince/p/4585983.html)|[Chrome - 性能进阶](http://www.cnblogs.com/constantince/p/4607497.html)|þ|[Chrome - 移动](http://www.cnblogs.com/constantince/p/4624241.html)|[Chrome - 使用技巧](http://www.cnblogs.com/liyunhua/p/4544738.html)|þ|[Chrome - Console控制台不完全指南](http://www.cnblogs.com/Wayou/p/chrome-console-tips-and-tricks.html)|[chrome开发工具快捷键](http://anti-code.com/devtools-cheatsheet)|þ|[Chrome 开发工具 Workspace 使用](http://www.iinterest.net/2014/05/09/chrome-dev-tool-workspace)|[Chrome神器Vimium快捷键学习记录](http://www.cppblog.com/deercoder/archive/2011/10/22/158886.html)|þ|[Sass调试-w3cplus](http://www.w3cplus.com/sassguide/debug.html)|[如何更专业的使用Chrome开发者工具-w3cplus](http://www.w3cplus.com/tools/how-to-use-chrome-devtools-like-a-pro.html)|þ|[Chrome调试canvas](http://sentsin.com/web/253.html)|[神器——Chrome开发者工具(一)](https://segmentfault.com/a/1190000000683599)|þ|[奇趣百科性能优化(Chrome DevTools 中的 Timeline Profils 等工具使用介绍](https://xinranliu.me/2015-05-22-qiqu-performance)|[Chrome 开发者工具的 15 个小技巧](http://frontenddev.org/link/15-tips-of-chrome-developer-tools.html)|þ|[Chrome开发者工具不完全指南](http://1ke.co/course/361)|[Chrome 开发者工具使用技巧](http://segmentfault.com/a/1190000003882567)|þþ## 性能优化þ| Reference | Reference |þ| --------- | --------- |þ|[Javascript高性能动画与页面渲染](http://www.infoq.com/cn/articles/javascript-high-performance-animation-and-page-rendering)|[移动H5前端性能优化指南](http://isux.tencent.com/h5-performance.html)|þ|[给网页设计师和前端开发者看的前端性能优化](http://www.uisdc.com/front-end-performance-for-web-designers-and-front-end-developers)|[张鑫旭——前端性能](http://www.zhangxinxu.com/wordpress/tag/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD/)|þ|[web前端性能优化进阶路](http://www.aliued.cn/2013/01/20/web%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E8%BF%9B%E9%98%B6%E8%B7%AF.html)|[Hey——前端性能](http://www.feelcss.com/tag/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD)|þ|[YSLOW中文介绍](http://www.cnblogs.com/yslow)|[Yahoo!团队实践分享：网站性能](http://www.360doc.com/content/10/0928/09/2588264_56971287.shtml)|þ|[加载，不只是少一点点](http://tgideas.qq.com/webplat/info/news_version3/804/808/811/m579/201109/41355.shtml)|[由12306谈谈网站前端性能和后端性能优化](http://coolshell.cn/articles/6470.html)|þ|[【高性能前端1】高性能HTML](http://www.alloyteam.com/2012/10/high-performance-html)|[【高性能前端2】高性能CSS](http://www.alloyteam.com/2012/10/high-performance-css)|þ|[前端工程与性能优化（上）：静态资源版本更新与缓存](http://www.infoq.com/cn/articles/front-end-engineering-and-performance-optimization-part1)|[前端工程与性能优化（下）：静态资源管理与模板框架](http://www.infoq.com/cn/articles/front-end-engineering-and-performance-optimization-part2)|þ|[HTTPS连接的前几毫秒发生了什么](http://blog.jobbole.com/48369)|[Yslow](http://uicss.cn/yslow/#more-12319)|þ|[阿里无线前端性能优化指南(Pt.1 加载期优化)](https://github.com/amfe/article/issues/1)|[毫秒必争，前端网页性能最佳实践](http://www.cnblogs.com/developersupport/p/3248695.html)|þþ## CDNþ| Reference | Reference |þ| --------- | --------- |þ|[Jquery&Bootstrap中文网开源项目免费 CDN 服务](http://www.bootcdn.cn/jquery)|[Bootstrap中文网开源项目免费 CDN 服务](http://www.bootcdn.cn)|þ|[新浪CDN](http://lib.sinaapp.com)|[百度静态资源公共库](http://cdn.code.baidu.com)|þ|[开放静态文件 CDN - 七牛](http://staticfile.org)|[CDN加速 - jq22](http://www.jq22.com/cdn)|þ|[微软CDN](http://www.asp.net/ajax/cdn)|[Angular CDN](https://code.angularjs.org/1.5.8/)|þ|[360网站卫士常用前端公共库CDN服务](http://libs.useso.com)||þþ## Gitþ| Article | Article |þ| --------- | --------- |þ|[Git操作](https://github.com/Wscats/Good-text-Share/issues/20)|[Git CSDN Blog](http://blog.csdn.net/qq_27080247/article/details/49942991)|þ| **Reference** | **Reference** |þ|[Git-scm](http://git-scm.com)|[Git-for-windows](https://git-for-windows.github.io)|þ|[廖雪峰-Git教程](http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000)|[Gogithub](http://www.worldhello.net/gotgithub/index.html)|þ|[Git常规命令练习](http://pcottle.github.io/learnGitBranching)|[Git的资料整理](https://github.com/xirong/my-git)|þ|[我所记录的git命令（非常实用）](http://www.cnblogs.com/fanfan259/p/4810517.html)|[GitHub 漫游指南](https://github.com/phodal/github-roam)|þ|[GitHub秘籍](https://github.com/tiimgreen/github-cheat-sheet/blob/master/README.zh-cn.md)|[动画方式练习git](http://onlywei.github.io/explain-git-with-d3)|þþ## Sass&Lessþ| Article | Article |þ| --------- | --------- |þ|[Less教程](https://github.com/Wscats/less-demo/issues/1)||þ| **Reference** | **Reference** |þ|[Sass](http://www.w3cplus.com/sassguide)|[Sass中文文档](http://sass.bootcss.com)|þ|[Less](http://less.bootcss.com)||þþ## Markdownþ| Reference | Reference |þ| --------- | --------- |þ|[Markdown 语法说明 (简体中文版)](http://wowubuntu.com/markdown)|[Markdown入门参考](https://github.com/LearnShare/Learning-Markdown/blob/master/README.md)|þ|[Mdeditor(一款国内的在线markdown编辑器)](https://www.zybuluo.com/mdeditor)|[Stackedit(国外的在线markdown编辑器，功能强大，同步云盘)](https://stackedit.io)|þ|[Mditor一款轻量级的markdown编辑器](http://bh-lay.github.io/mditor)|[lepture-editor](https://github.com/lepture/editor)|þ|[Markdown-editor](https://github.com/jbt/markdown-editor)||þþ## 前端文档þ| Reference | Reference |þ| --------- | --------- |þ|[前端知识结构](https://github.com/JacksonTian/fks)|[Web前端开发大系概览](https://github.com/unruledboy/WebFrontEndStack)|þ|[免费的编程中文书籍索](https://github.com/justjavac/free-programming-books-zh_CN)|[前端书籍](https://github.com/dypsilon/frontend-dev-bookmarks)|þ|[前端免费书籍大全](https://github.com/vhf/free-programming-books)|[重新介绍JavaScript（JS教程）](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/A_re-introduction_to_JavaScript)|þ|[Gitbook](https://www.gitbook.com 国外的在线markdown可编辑成书)|[Front-End-Develop-Guide 前端开发指南](https://github.com/Front-End-Developers-Hunan/Front-End-Develop-Guide)|þ|[前端开发笔记本](https://li-xinyang.gitbooks.io/frontend-notebook/content)|[大前端工具集](https://github.com/nieweidong/fetool)|þ|[前端开发者手册](https://dwqs.gitbooks.io/frontenddevhandbook/content)|[结合个人经历总结的前端入门方法](https://github.com/qiu-deqing/FE-learning)|þ|[2016最新前端学习计划](http://blog.csdn.net/qq_25827845/article/details/53079094)|þþ## 前端规范þ| Reference | Reference |þ| --------- | --------- |þ|[通过分析github代码库总结出来的工程师代码书写习惯](http://alloyteam.github.io/CodeGuide/)|[HTML&CSS编码规范 by @mdo](http://codeguide.bootcss.com)|þ|[前端编码规范之js - by yuwenhui](http://yuwenhui.github.io)|[前端编码规范之js - by 李靖](http://www.cnblogs.com/hustskyking/p/javascript-spec.html)|þ|[Airbnb JavaScript 编码规范（简体中文版）](https://github.com/yuche/javascript#table-of-contents)|[AMD与CMD规范的区别](http://www.zhihu.com/question/20351507)|þ|[AMD与CMD规范的区别](http://www.cnblogs.com/tugenhua0707/p/3507957.html)|[KISSY 源码规范](http://docs.kissyui.com/1.4/docs/html/tutorials/style-guide/kissy-source-style.html)|þ|[前端代码规范及最佳实践](http://blog.jobbole.com/79075)|[百度前端规范](http://coderlmn.github.io/code-standards)|þ|[JavaScript风格指南/编码规范（Airbnb公司版）](http://blog.jobbole.com/79484)|[网易前端开发规范](http://nec.netease.com/standard)|þ|[前端规范资源列表](https://github.com/ecomfe/spec)|[Web 前端开发规范文档](http://codecloud.net/5622.html)|þþ## 前端面试þ| Reference | Reference |þ| --------- | --------- |þ|[2016校招内推 -- 阿里巴巴前端 -- 四面面试经历](http://www.cnblogs.com/imwtr/p/4685546.html)|[那几个月在找工作（百度，网易游戏，华为）](https://www.nowcoder.com/discuss/3196)|þ|[前端开发面试题](https://segmentfault.com/a/1190000000465431)|[Front-end-Interview-questions](https://github.com/hawx1993/Front-end-Interview-questions)|þ|[5个经典的前端面试问题](http://ourjs.com/detail/5%E4%B8%AA%E7%BB%8F%E5%85%B8%E7%9A%84%E5%89%8D%E7%AB%AF%E)|[Front-end-Developer-Interview-Questions](https://github.com/h5bp/Front-end-Developer-Interview-Questions/tree/master/Translations/Chinese)|þ|[BAT及各大互联网公司2014前端笔试面试题：JavaScript篇](http://blog.jobbole.com/78738/)|[前端开发面试题大收集](https://github.com/paddingme/Front-end-Web-Development-Interview-Question)|þ|[收集的前端面试题和答案](https://github.com/qiu-deqing/FE-interview)|[前端开发面试题](https://github.com/markyun/My-blog/blob/master/Front-end-Developer-Questions/Questions-and-Answers/README.md)|þ|[前端面试大全](https://segmentfault.com/a/1190000005947094)|[关于前端面试](https://mdluo.github.io/blog/about-front-end-interview/)|þþ## 前端网站þ| Reference | Reference |þ| --------- | --------- |þ|[掘金](https://gold.xitu.io/)|[百度FEX](http://fex.baidu.com/)|þ|[阿里UED](http://www.aliued.com/)|[菜鸟教程](http://www.runoob.com/)|þ|[QDFuns](http://www.qdfuns.com/portal.php)|[幕课网](http://www.imooc.com/)|þ|[Codepen](http://codepen.io/)|[Sentsin](http://sentsin.com/daohang/)|þ|[CTOLib](http://www.ctolib.com/javascript/)|[CTOLib/Node](http://www.ctolib.com/nodejs/)|þþ## JS练习þ| Reference | Reference |þ| --------- | --------- |þ|[Codewars](https://www.codewars.com/)|[Javascript-puzzlers](http://javascript-puzzlers.herokuapp.com/)|þ|[Freecodecamp中文版](https://freecodecamp.cn/)|[ES6katas](http://es6katas.org/)|þ|[Now Coder牛客网](https://www.nowcoder.com/ta/js-assessment)|[Leetcode](https://leetcode.com/)|þ|[Nodeschool](https://nodeschool.io/)|[Hackerrank](https://www.hackerrank.com/)|þþ## 算法þ| Reference | Reference |þ| --------- | --------- |þ|[数据结构与算法 JavaScript 描述. 章节练习](https://github.com/Ralph-Wang/algorithm.in.js)|[常见排序算法（JS版）](https://github.com/twobin/twobinSort)|þ|[经典排序](https://github.com/luofei2011/jsAgm/blob/master/js/sort.js)|[常见排序算法-js版本](https://github.com/hechangmin/jssort)|þþ## ESþ| Reference | Reference |þ| --------- | --------- |þ|[Exploring-ES6翻译](http://es6-org.github.io/exploring-es6/)|[阮一峰 ES6](http://es6.ruanyifeng.com)|þ|[ECMA-262，第 5 版](http://yanhaijing.com/es5)|[ES5](http://es5.github.io)|",
winterbe/java8-tutorial,,False,False,False,157,82,13044,945,3173,0,0,0,0,"[655, 675, 676, 914, 1003, 1060, 1283, 1374, 1467, 1572]",User,Modern Java - A Guide to Java 8,"{'': 2, 'md': 1, 'js': 10, 'java': 68, 'txt': 1}",http://winterbe.com,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",Java,149,1,0,11,8,2309,False,,,,,1,35,0,1,6,0,0,0,,,2,"# Modern Java - A Guide to Java 8þ_This article was originally posted on [my blog](http://winterbe.com/posts/2014/03/16/java-8-tutorial/)._þþ> **You should also read my [Java 11 Tutorial](https://winterbe.com/posts/2018/09/24/java-11-tutorial/) (including new language and API features from Java 9, 10 and 11).**þþWelcome to my introduction to [Java 8](https://jdk8.java.net/). This tutorial guides you step by step through all new language features. Backed by short and simple code samples you'll learn how to use default interface methods, lambda expressions, method references and repeatable annotations. At the end of the article you'll be familiar with the most recent [API](http://download.java.net/jdk8/docs/api/) changes like streams, functional interfaces, map extensions and the new Date API. **No walls of text, just a bunch of commented code snippets. Enjoy!**þþ---þþ<p align=""center"">þ ★★★ Like this project? Leave a star, <a href=""https://twitter.com/winterbe_"">follow on Twitter</a> or <a href=""https://www.paypal.me/winterbe"">donate</a> to support my work. Thanks! ★★★þ</p>þþ---þþ## Table of Contentsþþ* [Default Methods for Interfaces](#default-methods-for-interfaces)þ* [Lambda expressions](#lambda-expressions)þ* [Functional Interfaces](#functional-interfaces)þ* [Method and Constructor References](#method-and-constructor-references)þ* [Lambda Scopes](#lambda-scopes)þ  * [Accessing local variables](#accessing-local-variables)þ  * [Accessing fields and static variables](#accessing-fields-and-static-variables)þ  * [Accessing Default Interface Methods](#accessing-default-interface-methods)þ* [Built-in Functional Interfaces](#built-in-functional-interfaces)þ  * [Predicates](#predicates)þ  * [Functions](#functions)þ  * [Suppliers](#suppliers)þ  * [Consumers](#consumers)þ  * [Comparators](#comparators)þ* [Optionals](#optionals)þ* [Streams](#streams)þ  * [Filter](#filter)þ  * [Sorted](#sorted)þ  * [Map](#map)þ  * [Match](#match)þ  * [Count](#count)þ  * [Reduce](#reduce)þ* [Parallel Streams](#parallel-streams)þ  * [Sequential Sort](#sequential-sort)þ  * [Parallel Sort](#parallel-sort)þ* [Maps](#maps)þ* [Date API](#date-api)þ  * [Clock](#clock)þ  * [Timezones](#timezones)þ  * [LocalTime](#localtime)þ  * [LocalDate](#localdate)þ  * [LocalDateTime](#localdatetime)þ* [Annotations](#annotations)þ* [Where to go from here?](#where-to-go-from-here)þþ## Default Methods for InterfacesþþJava 8 enables us to add non-abstract method implementations to interfaces by utilizing the `default` keyword. This feature is also known as [virtual extension methods](http://stackoverflow.com/a/24102730). þþHere is our first example:þþ```javaþinterface Formula {þ    double calculate(int a);þþ    default double sqrt(int a) {þ        return Math.sqrt(a);þ    }þ}þ```þþBesides the abstract method `calculate` the interface `Formula` also defines the default method `sqrt`. Concrete classes only have to implement the abstract method `calculate`. The default method `sqrt` can be used out of the box.þþ```javaþFormula formula = new Formula() {þ    @Overrideþ    public double calculate(int a) {þ        return sqrt(a * 100);þ    }þ};þþformula.calculate(100);     // 100.0þformula.sqrt(16);           // 4.0þ```þþThe formula is implemented as an anonymous object. The code is quite verbose: 6 lines of code for such a simple calculation of `sqrt(a * 100)`. As we'll see in the next section, there's a much nicer way of implementing single method objects in Java 8.þþþ## Lambda expressionsþþLet's start with a simple example of how to sort a list of strings in prior versions of Java:þþ```javaþList<String> names = Arrays.asList(""peter"", ""anna"", ""mike"", ""xenia"");þþCollections.sort(names, new Comparator<String>() {þ    @Overrideþ    public int compare(String a, String b) {þ        return b.compareTo(a);þ    }þ});þ```þþThe static utility method `Collections.sort` accepts a list and a comparator in order to sort the elements of the given list. You often find yourself creating anonymous comparators and pass them to the sort method.þþInstead of creating anonymous objects all day long, Java 8 comes with a much shorter syntax, **lambda expressions**:þþ```javaþCollections.sort(names, (String a, String b) -> {þ    return b.compareTo(a);þ});þ```þþAs you can see the code is much shorter and easier to read. But it gets even shorter:þþ```javaþCollections.sort(names, (String a, String b) -> b.compareTo(a));þ```þþFor one line method bodies you can skip both the braces `{}` and the `return` keyword. But it gets even shorter:þþ```javaþnames.sort((a, b) -> b.compareTo(a));þ```þþList now has a `sort` method. Also the java compiler is aware of the parameter types so you can skip them as well. Let's dive deeper into how lambda expressions can be used in the wild.þþþ## Functional InterfacesþþHow does lambda expressions fit into Java's type system? Each lambda corresponds to a given type, specified by an interface. A so called _functional interface_ must contain **exactly one abstract method** declaration. Each lambda expression of that type will be matched to this abstract method. Since default methods are not abstract you're free to add default methods to your functional interface.þþWe can use arbitrary interfaces as lambda expressions as long as the interface only contains one abstract method. To ensure that your interface meet the requirements, you should add the `@FunctionalInterface` annotation. The compiler is aware of this annotation and throws a compiler error as soon as you try to add a second abstract method declaration to the interface.þþExample:þþ```javaþ@FunctionalInterfaceþinterface Converter<F, T> {þ    T convert(F from);þ}þ```þþ```javaþConverter<String, Integer> converter = (from) -> Integer.valueOf(from);þInteger converted = converter.convert(""123"");þSystem.out.println(converted);    // 123þ```þþKeep in mind that the code is also valid if the `@FunctionalInterface` annotation would be omitted.þþþ## Method and Constructor ReferencesþþThe above example code can be further simplified by utilizing static method references:þþ```javaþConverter<String, Integer> converter = Integer::valueOf;þInteger converted = converter.convert(""123"");þSystem.out.println(converted);   // 123þ```þþJava 8 enables you to pass references of methods or constructors via the `::` keyword. The above example shows how to reference a static method. But we can also reference object methods:þþ```javaþclass Something {þ    String startsWith(String s) {þ        return String.valueOf(s.charAt(0));þ    }þ}þ```þþ```javaþSomething something = new Something();þConverter<String, String> converter = something::startsWith;þString converted = converter.convert(""Java"");þSystem.out.println(converted);    // ""J""þ```þþLet's see how the `::` keyword works for constructors. First we define an example class with different constructors:þþ```javaþclass Person {þ    String firstName;þ    String lastName;þþ    Person() {}þþ    Person(String firstName, String lastName) {þ        this.firstName = firstName;þ        this.lastName = lastName;þ    }þ}þ```þþNext we specify a person factory interface to be used for creating new persons:þþ```javaþinterface PersonFactory<P extends Person> {þ    P create(String firstName, String lastName);þ}þ```þþInstead of implementing the factory manually, we glue everything together via constructor references:þþ```javaþPersonFactory<Person> personFactory = Person::new;þPerson person = personFactory.create(""Peter"", ""Parker"");þ```þþWe create a reference to the Person constructor via `Person::new`. The Java compiler automatically chooses the right constructor by matching the signature of `PersonFactory.create`.þþ## Lambda ScopesþþAccessing outer scope variables from lambda expressions is very similar to anonymous objects. You can access final variables from the local outer scope as well as instance fields and static variables.þþ### Accessing local variablesþþWe can read final local variables from the outer scope of lambda expressions:þþ```javaþfinal int num = 1;þConverter<Integer, String> stringConverter =þ        (from) -> String.valueOf(from + num);þþstringConverter.convert(2);     // 3þ```þþBut different to anonymous objects the variable `num` does not have to be declared final. This code is also valid:þþ```javaþint num = 1;þConverter<Integer, String> stringConverter =þ        (from) -> String.valueOf(from + num);þþstringConverter.convert(2);     // 3þ```þþHowever `num` must be implicitly final for the code to compile. The following code does **not** compile:þþ```javaþint num = 1;þConverter<Integer, String> stringConverter =þ        (from) -> String.valueOf(from + num);þnum = 3;þ```þþWriting to `num` from within the lambda expression is also prohibited.þþ### Accessing fields and static variablesþþIn contrast to local variables, we have both read and write access to instance fields and static variables from within lambda expressions. This behaviour is well known from anonymous objects.þþ```javaþclass Lambda4 {þ    static int outerStaticNum;þ    int outerNum;þþ    void testScopes() {þ        Converter<Integer, String> stringConverter1 = (from) -> {þ            outerNum = 23;þ            return String.valueOf(from);þ        };þþ        Converter<Integer, String> stringConverter2 = (from) -> {þ            outerStaticNum = 72;þ            return String.valueOf(from);þ        };þ    }þ}þ```þþ### Accessing Default Interface MethodsþþRemember the formula example from the first section? Interface `Formula` defines a default method `sqrt` which can be accessed from each formula instance including anonymous objects. This does not work with lambda expressions.þþDefault methods **cannot** be accessed from within lambda expressions. The following code does not compile:þþ```javaþFormula formula = (a) -> sqrt(a * 100);þ```þþþ## Built-in Functional InterfacesþþThe JDK 1.8 API contains many built-in functional interfaces. Some of them are well known from older versions of Java like `Comparator` or `Runnable`. Those existing interfaces are extended to enable Lambda support via the `@FunctionalInterface` annotation.þþBut the Java 8 API is also full of new functional interfaces to make your life easier. Some of those new interfaces are well known from the [Google Guava](https://code.google.com/p/guava-libraries/) library. Even if you're familiar with this library you should keep a close eye on how those interfaces are extended by some useful method extensions.þþ### PredicatesþþPredicates are boolean-valued functions of one argument. The interface contains various default methods for composing predicates to complex logical terms (and, or, negate)þþ```javaþPredicate<String> predicate = (s) -> s.length() > 0;þþpredicate.test(""foo"");              // trueþpredicate.negate().test(""foo"");     // falseþþPredicate<Boolean> nonNull = Objects::nonNull;þPredicate<Boolean> isNull = Objects::isNull;þþPredicate<String> isEmpty = String::isEmpty;þPredicate<String> isNotEmpty = isEmpty.negate();þ```þþ### FunctionsþþFunctions accept one argument and produce a result. Default methods can be used to chain multiple functions together (compose, andThen).þþ```javaþFunction<String, Integer> toInteger = Integer::valueOf;þFunction<String, String> backToString = toInteger.andThen(String::valueOf);þþbackToString.apply(""123"");     // ""123""þ```þþ### SuppliersþþSuppliers produce a result of a given generic type. Unlike Functions, Suppliers don't accept arguments.þþ```javaþSupplier<Person> personSupplier = Person::new;þpersonSupplier.get();   // new Personþ```þþ### ConsumersþþConsumers represent operations to be performed on a single input argument.þþ```javaþConsumer<Person> greeter = (p) -> System.out.println(""Hello, "" + p.firstName);þgreeter.accept(new Person(""Luke"", ""Skywalker""));þ```þþ### ComparatorsþþComparators are well known from older versions of Java. Java 8 adds various default methods to the interface.þþ```javaþComparator<Person> comparator = (p1, p2) -> p1.firstName.compareTo(p2.firstName);þþPerson p1 = new Person(""John"", ""Doe"");þPerson p2 = new Person(""Alice"", ""Wonderland"");þþcomparator.compare(p1, p2);             // > 0þcomparator.reversed().compare(p1, p2);  // < 0þ```þþ## OptionalsþþOptionals are not functional interfaces, but nifty utilities to prevent `NullPointerException`. It's an important concept for the next section, so let's have a quick look at how Optionals work.þþOptional is a simple container for a value which may be null or non-null. Think of a method which may return a non-null result but sometimes return nothing. Instead of returning `null` you return an `Optional` in Java 8.þþ```javaþOptional<String> optional = Optional.of(""bam"");þþoptional.isPresent();           // trueþoptional.get();                 // ""bam""þoptional.orElse(""fallback"");    // ""bam""þþoptional.ifPresent((s) -> System.out.println(s.charAt(0)));     // ""b""þ```þþ## StreamsþþA `java.util.Stream` represents a sequence of elements on which one or more operations can be performed. Stream operations are either _intermediate_ or _terminal_. While terminal operations return a result of a certain type, intermediate operations return the stream itself so you can chain multiple method calls in a row. Streams are created on a source, e.g. a `java.util.Collection` like lists or sets (maps are not supported). Stream operations can either be executed sequentially or parallely.þþ> Streams are extremely powerful, so I wrote a separate [Java 8 Streams Tutorial](http://winterbe.com/posts/2014/07/31/java8-stream-tutorial-examples/). **You should also check out [Sequency](https://github.com/winterbe/sequency) as a similiar library for the web.**þþLet's first look how sequential streams work. First we create a sample source in form of a list of strings:þþ```javaþList<String> stringCollection = new ArrayList<>();þstringCollection.add(""ddd2"");þstringCollection.add(""aaa2"");þstringCollection.add(""bbb1"");þstringCollection.add(""aaa1"");þstringCollection.add(""bbb3"");þstringCollection.add(""ccc"");þstringCollection.add(""bbb2"");þstringCollection.add(""ddd1"");þ```þþCollections in Java 8 are extended so you can simply create streams either by calling `Collection.stream()` or `Collection.parallelStream()`. The following sections explain the most common stream operations.þþ### FilterþþFilter accepts a predicate to filter all elements of the stream. This operation is _intermediate_ which enables us to call another stream operation (`forEach`) on the result. ForEach accepts a consumer to be executed for each element in the filtered stream. ForEach is a terminal operation. It's `void`, so we cannot call another stream operation.þþ```javaþstringCollectionþ    .stream()þ    .filter((s) -> s.startsWith(""a""))þ    .forEach(System.out::println);þþ// ""aaa2"", ""aaa1""þ```þþ### SortedþþSorted is an _intermediate_ operation which returns a sorted view of the stream. The elements are sorted in natural order unless you pass a custom `Comparator`.þþ```javaþstringCollectionþ    .stream()þ    .sorted()þ    .filter((s) -> s.startsWith(""a""))þ    .forEach(System.out::println);þþ// ""aaa1"", ""aaa2""þ```þþKeep in mind that `sorted` does only create a sorted view of the stream without manipulating the ordering of the backed collection. The ordering of `stringCollection` is untouched:þþ```javaþSystem.out.println(stringCollection);þ// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1þ```þþ### MapþþThe _intermediate_ operation `map` converts each element into another object via the given function. The following example converts each string into an upper-cased string. But you can also use `map` to transform each object into another type. The generic type of the resulting stream depends on the generic type of the function you pass to `map`.þþ```javaþstringCollectionþ    .stream()þ    .map(String::toUpperCase)þ    .sorted((a, b) -> b.compareTo(a))þ    .forEach(System.out::println);þþ// ""DDD2"", ""DDD1"", ""CCC"", ""BBB3"", ""BBB2"", ""AAA2"", ""AAA1""þ```þþ### MatchþþVarious matching operations can be used to check whether a certain predicate matches the stream. All of those operations are _terminal_ and return a boolean result.þþ```javaþboolean anyStartsWithA =þ    stringCollectionþ        .stream()þ        .anyMatch((s) -> s.startsWith(""a""));þþSystem.out.println(anyStartsWithA);      // trueþþboolean allStartsWithA =þ    stringCollectionþ        .stream()þ        .allMatch((s) -> s.startsWith(""a""));þþSystem.out.println(allStartsWithA);      // falseþþboolean noneStartsWithZ =þ    stringCollectionþ        .stream()þ        .noneMatch((s) -> s.startsWith(""z""));þþSystem.out.println(noneStartsWithZ);      // trueþ```þþ#### CountþþCount is a _terminal_ operation returning the number of elements in the stream as a `long`.þþ```javaþlong startsWithB =þ    stringCollectionþ        .stream()þ        .filter((s) -> s.startsWith(""b""))þ        .count();þþSystem.out.println(startsWithB);    // 3þ```þþþ### ReduceþþThis _terminal_ operation performs a reduction on the elements of the stream with the given function. The result is an `Optional` holding the reduced value.þþ```javaþOptional<String> reduced =þ    stringCollectionþ        .stream()þ        .sorted()þ        .reduce((s1, s2) -> s1 + ""#"" + s2);þþreduced.ifPresent(System.out::println);þ// ""aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2""þ```þþ## Parallel StreamsþþAs mentioned above streams can be either sequential or parallel. Operations on sequential streams are performed on a single thread while operations on parallel streams are performed concurrently on multiple threads.þþThe following example demonstrates how easy it is to increase the performance by using parallel streams.þþFirst we create a large list of unique elements:þþ```javaþint max = 1000000;þList<String> values = new ArrayList<>(max);þfor (int i = 0; i < max; i++) {þ    UUID uuid = UUID.randomUUID();þ    values.add(uuid.toString());þ}þ```þþNow we measure the time it takes to sort a stream of this collection.þþ### Sequential Sortþþ```javaþlong t0 = System.nanoTime();þþlong count = values.stream().sorted().count();þSystem.out.println(count);þþlong t1 = System.nanoTime();þþlong millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);þSystem.out.println(String.format(""sequential sort took: %d ms"", millis));þþ// sequential sort took: 899 msþ```þþ### Parallel Sortþþ```javaþlong t0 = System.nanoTime();þþlong count = values.parallelStream().sorted().count();þSystem.out.println(count);þþlong t1 = System.nanoTime();þþlong millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0);þSystem.out.println(String.format(""parallel sort took: %d ms"", millis));þþ// parallel sort took: 472 msþ```þþAs you can see both code snippets are almost identical but the parallel sort is roughly 50% faster. All you have to do is change `stream()` to `parallelStream()`.þþ## MapsþþAs already mentioned maps do not directly support streams. There's no `stream()` method available on the `Map` interface itself, however you can create specialized streams upon the keys, values or entries of a map via `map.keySet().stream()`, `map.values().stream()` and `map.entrySet().stream()`. þþFurthermore maps support various new and useful methods for doing common tasks.þþ```javaþMap<Integer, String> map = new HashMap<>();þþfor (int i = 0; i < 10; i++) {þ    map.putIfAbsent(i, ""val"" + i);þ}þþmap.forEach((id, val) -> System.out.println(val));þ```þþThe above code should be self-explaining: `putIfAbsent` prevents us from writing additional if null checks; `forEach` accepts a consumer to perform operations for each value of the map.þþThis example shows how to compute code on the map by utilizing functions:þþ```javaþmap.computeIfPresent(3, (num, val) -> val + num);þmap.get(3);             // val33þþmap.computeIfPresent(9, (num, val) -> null);þmap.containsKey(9);     // falseþþmap.computeIfAbsent(23, num -> ""val"" + num);þmap.containsKey(23);    // trueþþmap.computeIfAbsent(3, num -> ""bam"");þmap.get(3);             // val33þ```þþNext, we learn how to remove entries for a given key, only if it's currently mapped to a given value:þþ```javaþmap.remove(3, ""val3"");þmap.get(3);             // val33þþmap.remove(3, ""val33"");þmap.get(3);             // nullþ```þþAnother helpful method:þþ```javaþmap.getOrDefault(42, ""not found"");  // not foundþ```þþMerging entries of a map is quite easy:þþ```javaþmap.merge(9, ""val9"", (value, newValue) -> value.concat(newValue));þmap.get(9);             // val9þþmap.merge(9, ""concat"", (value, newValue) -> value.concat(newValue));þmap.get(9);             // val9concatþ```þþMerge either put the key/value into the map if no entry for the key exists, or the merging function will be called to change the existing value.þþþ## Date APIþþJava 8 contains a brand new date and time API under the package `java.time`. The new Date API is comparable with the [Joda-Time](http://www.joda.org/joda-time/) library, however it's [not the same](http://blog.joda.org/2009/11/why-jsr-310-isn-joda-time_4941.html). The following examples cover the most important parts of this new API.þþ### ClockþþClock provides access to the current date and time. Clocks are aware of a timezone and may be used instead of `System.currentTimeMillis()` to retrieve the current time in milliseconds since Unix EPOCH. Such an instantaneous point on the time-line is also represented by the class `Instant`. Instants can be used to create legacy `java.util.Date` objects.þþ```javaþClock clock = Clock.systemDefaultZone();þlong millis = clock.millis();þþInstant instant = clock.instant();þDate legacyDate = Date.from(instant);   // legacy java.util.Dateþ```þþ### TimezonesþþTimezones are represented by a `ZoneId`. They can easily be accessed via static factory methods. Timezones define the offsets which are important to convert between instants and local dates and times.þþ```javaþSystem.out.println(ZoneId.getAvailableZoneIds());þ// prints all available timezone idsþþZoneId zone1 = ZoneId.of(""Europe/Berlin"");þZoneId zone2 = ZoneId.of(""Brazil/East"");þSystem.out.println(zone1.getRules());þSystem.out.println(zone2.getRules());þþ// ZoneRules[currentStandardOffset=+01:00]þ// ZoneRules[currentStandardOffset=-03:00]þ```þþ### LocalTimeþþLocalTime represents a time without a timezone, e.g. 10pm or 17:30:15. The following example creates two local times for the timezones defined above. Then we compare both times and calculate the difference in hours and minutes between both times.þþ```javaþLocalTime now1 = LocalTime.now(zone1);þLocalTime now2 = LocalTime.now(zone2);þþSystem.out.println(now1.isBefore(now2));  // falseþþlong hoursBetween = ChronoUnit.HOURS.between(now1, now2);þlong minutesBetween = ChronoUnit.MINUTES.between(now1, now2);þþSystem.out.println(hoursBetween);       // -3þSystem.out.println(minutesBetween);     // -239þ```þþLocalTime comes with various factory methods to simplify the creation of new instances, including parsing of time strings.þþ```javaþLocalTime late = LocalTime.of(23, 59, 59);þSystem.out.println(late);       // 23:59:59þþDateTimeFormatter germanFormatter =þ    DateTimeFormatterþ        .ofLocalizedTime(FormatStyle.SHORT)þ        .withLocale(Locale.GERMAN);þþLocalTime leetTime = LocalTime.parse(""13:37"", germanFormatter);þSystem.out.println(leetTime);   // 13:37þ```þþ### LocalDateþþLocalDate represents a distinct date, e.g. 2014-03-11. It's immutable and works exactly analog to LocalTime. The sample demonstrates how to calculate new dates by adding or subtracting days, months or years. Keep in mind that each manipulation returns a new instance.þþ```javaþLocalDate today = LocalDate.now();þLocalDate tomorrow = today.plus(1, ChronoUnit.DAYS);þLocalDate yesterday = tomorrow.minusDays(2);þþLocalDate independenceDay = LocalDate.of(2014, Month.JULY, 4);þDayOfWeek dayOfWeek = independenceDay.getDayOfWeek();þSystem.out.println(dayOfWeek);    // FRIDAYþ```þþParsing a LocalDate from a string is just as simple as parsing a LocalTime:þþ```javaþDateTimeFormatter germanFormatter =þ    DateTimeFormatterþ        .ofLocalizedDate(FormatStyle.MEDIUM)þ        .withLocale(Locale.GERMAN);þþLocalDate xmas = LocalDate.parse(""24.12.2014"", germanFormatter);þSystem.out.println(xmas);   // 2014-12-24þ```þþ### LocalDateTimeþþLocalDateTime represents a date-time. It combines date and time as seen in the above sections into one instance. `LocalDateTime` is immutable and works similar to LocalTime and LocalDate. We can utilize methods for retrieving certain fields from a date-time:þþ```javaþLocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59);þþDayOfWeek dayOfWeek = sylvester.getDayOfWeek();þSystem.out.println(dayOfWeek);      // WEDNESDAYþþMonth month = sylvester.getMonth();þSystem.out.println(month);          // DECEMBERþþlong minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY);þSystem.out.println(minuteOfDay);    // 1439þ```þþWith the additional information of a timezone it can be converted to an instant. Instants can easily be converted to legacy dates of type `java.util.Date`.þþ```javaþInstant instant = sylvesterþ        .atZone(ZoneId.systemDefault())þ        .toInstant();þþDate legacyDate = Date.from(instant);þSystem.out.println(legacyDate);     // Wed Dec 31 23:59:59 CET 2014þ```þþFormatting date-times works just like formatting dates or times. Instead of using pre-defined formats we can create formatters from custom patterns.þþ```javaþDateTimeFormatter formatter =þ    DateTimeFormatterþ        .ofPattern(""MMM dd, yyyy - HH:mm"");þþLocalDateTime parsed = LocalDateTime.parse(""Nov 03, 2014 - 07:13"", formatter);þString string = formatter.format(parsed);þSystem.out.println(string);     // Nov 03, 2014 - 07:13þ```þþUnlike `java.text.NumberFormat` the new `DateTimeFormatter` is immutable and **thread-safe**.þþFor details on the pattern syntax read [here](https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html).þþþ## AnnotationsþþAnnotations in Java 8 are repeatable. Let's dive directly into an example to figure that out.þþFirst, we define a wrapper annotation which holds an array of the actual annotations:þþ```javaþ@interface Hints {þ    Hint[] value();þ}þþ@Repeatable(Hints.class)þ@interface Hint {þ    String value();þ}þ```þJava 8 enables us to use multiple annotations of the same type by declaring the annotation `@Repeatable`.þþ### Variant 1: Using the container annotation (old school)þþ```javaþ@Hints({@Hint(""hint1""), @Hint(""hint2"")})þclass Person {}þ```þþ### Variant 2: Using repeatable annotations (new school)þþ```javaþ@Hint(""hint1"")þ@Hint(""hint2"")þclass Person {}þ```þþUsing variant 2 the java compiler implicitly sets up the `@Hints` annotation under the hood. That's important for reading annotation information via reflection.þþ```javaþHint hint = Person.class.getAnnotation(Hint.class);þSystem.out.println(hint);                   // nullþþHints hints1 = Person.class.getAnnotation(Hints.class);þSystem.out.println(hints1.value().length);  // 2þþHint[] hints2 = Person.class.getAnnotationsByType(Hint.class);þSystem.out.println(hints2.length);          // 2þ```þþAlthough we never declared the `@Hints` annotation on the `Person` class, it's still readable via `getAnnotation(Hints.class)`. However, the more convenient method is `getAnnotationsByType` which grants direct access to all annotated `@Hint` annotations.þþþFurthermore the usage of annotations in Java 8 is expanded to two new targets:þþ```javaþ@Target({ElementType.TYPE_PARAMETER, ElementType.TYPE_USE})þ@interface MyAnnotation {}þ```þþ## Where to go from here?þþMy programming guide to Java 8 ends here. If you want to learn more about all the new classes and features of the JDK 8 API, check out my [JDK8 API Explorer](http://winterbe.com/projects/java8-explorer/). It helps you figuring out all the new classes and hidden gems of JDK 8, like `Arrays.parallelSort`, `StampedLock` and `CompletableFuture` - just to name a few.þþI've also published a bunch of follow-up articles on my [blog](http://winterbe.com) that might be interesting to you:þþ- [Java 8 Stream Tutorial](http://winterbe.com/posts/2014/07/31/java8-stream-tutorial-examples/)þ- [Java 8 Nashorn Tutorial](http://winterbe.com/posts/2014/04/05/java8-nashorn-tutorial/)þ- [Java 8 Concurrency Tutorial: Threads and Executors](http://winterbe.com/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/)þ- [Java 8 Concurrency Tutorial: Synchronization and Locks](http://winterbe.com/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/)þ- [Java 8 Concurrency Tutorial: Atomic Variables and ConcurrentMap](http://winterbe.com/posts/2015/05/22/java8-concurrency-tutorial-atomic-concurrent-map-examples/)þ- [Java 8 API by Example: Strings, Numbers, Math and Files](http://winterbe.com/posts/2015/03/25/java8-examples-string-number-math-files/)þ- [Avoid Null Checks in Java 8](http://winterbe.com/posts/2015/03/15/avoid-null-checks-in-java/)þ- [Fixing Java 8 Stream Gotchas with IntelliJ IDEA](http://winterbe.com/posts/2015/03/05/fixing-java-8-stream-gotchas-with-intellij-idea/)þ- [Using Backbone.js with Java 8 Nashorn](http://winterbe.com/posts/2014/04/07/using-backbonejs-with-nashorn/)þþYou should [follow me on Twitter](https://twitter.com/winterbe_). Thanks for reading!",
changwookjun/StudyBook,,False,False,False,1104199,227,1223,158,764,3,6,2,1,"[14, 126, 149, 150, 230, 281, 389, 402, 415, 442]",User,Study E-Book(ComputerVision DeepLearning MachineLearning Math NLP Python ReinforcementLearning),"{'': 7, 'pdf': 218, 'txt': 1, 'md': 1}",,,,362,1,0,2,18,788,True,0,2,0,2,0,1,0,0,8,0,0,0,,,236,"# Study E-Book(ComputerVision DeepLearning MachineLearning Math NLP Python ReinforcementLearning)þþContents  þ* [Computer Vision Books](https://github.com/changwookjun/StudyBook/tree/master/ComputerVisionBooks)   þ  + [Machine Learning for OpenCV.pdf](https://github.com/changwookjun/StudyBook/blob/master/ComputerVisionBooks/Machine%20Learning%20for%20OpenCV.pdf)   þ  + [Mastering_opencv.pdf](https://github.com/changwookjun/StudyBook/blob/master/ComputerVisionBooks/Mastering_opencv.pdf)   þ  + [OpenCV Computer Vision Projects.pdf](https://github.com/changwookjun/StudyBook/blob/master/ComputerVisionBooks/OpenCV%20Computer%20Vision%20Projects.pdf)   þ  + [opencv-3-computer-vision-application-robert-laganiere7734.pdf](https://github.com/changwookjun/StudyBook/blob/master/ComputerVisionBooks/opencv-3-computer-vision-application-robert-laganiere7734.pdf)   þ  þ* [Deep Learning Books](https://github.com/changwookjun/StudyBook/tree/master/DeepLearningBooks)   þ  + [Deep Learning - Josh Patterson & Adam Gibson.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Deep%20Learning%20-%20Josh%20Patterson%20%26%20Adam%20Gibson.pdf)   þ  + [Deep Learning with Keras by Antonio Gulli.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Deep%20Learning%20with%20Keras%20by%20Antonio%20Gulli.pdf)   þ  + [Deep Learning with Python A Hands-on Introduction.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Deep%20Learning%20with%20Python%20A%20Hands-on%20Introduction.pdf)   þ  + [Deep Learning with TensorFlow.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Deep%20Learning%20with%20TensorFlow.pdf)   þ  + [Deep Learning with Theano.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Deep%20Learning%20with%20Theano.pdf)   þ  + [Fundamentals of Deep Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Fundamentals%20of%20Deep%20Learning.pdf)   þ  + [Introduction to Deep Learning Using R.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Introduction%20to%20Deep%20Learning%20Using%20R.pdf)   þ  + [Learning TensorFlow.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Learning%20TensorFlow.pdf)   þ  + [Python Deep Learning Cookbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Python%20Deep%20Learning%20Cookbook.pdf)   þ  + [Python Deep Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Python%20Deep%20Learning.pdf)   þ  + [R Deep Learning Cookbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/R%20Deep%20Learning%20Cookbook.pdf)   þ  + [deeplearning.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/deeplearning.pdf)   þ  + [deeplearningbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/deeplearningbook.pdf)   þ  + [deeplearningbook_bookmarked.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/deeplearningbook_bookmarked.pdf)   þ  + [oreilly-hands-on-machine-learning-with-scikit-learn-and-tensorflow-1491962291.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/oreilly-hands-on-machine-learning-with-scikit-learn-and-tensorflow-1491962291.pdf)   þ  + [CS 20_Tensorflow for Deep Learning Research](https://github.com/changwookjun/StudyBook/tree/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research)     þ      - [01 _ Lecture slide _ Overview of Tensorflow.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/01%20_%20Lecture%20slide%20_%20Overview%20of%20Tensorflow.pdf)     þ      - [02_Lecture slide_TensorFlow Operations.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/02_Lecture%20slide_TensorFlow%20Operations.pdf)     þ      - [03 _ Lecture slide _ Basic Models in TensorFlow.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/03%20_%20Lecture%20slide%20_%20Basic%20Models%20in%20TensorFlow.pdf)     þ      - [04 Eager Execution + word2vec.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/04%20Eager%20Execution%20%2B%20word2vec.pdf)     þ      - [05_Slide_Managing your experiment.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/05_Slide_Managing%20your%20experiment.pdf)     þ      - [06_Introduction to Computer Vision and convolutional network.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/06_Introduction%20to%20Computer%20Vision%20and%20convolutional%20network.pdf)     þ      - [07 _ Covnets in TensorFlow.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/07%20_%20Covnets%20in%20TensorFlow.pdf)     þ      - [08_Style transfer.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/08_Style%20transfer.pdf)     þ      - [10_Lecture_Slides_VAE in TensorFlow.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/10_Lecture_Slides_VAE%20in%20TensorFlow.pdf)     þ      - [11 _ Slides _ Introduction to RNNs.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/11%20_%20Slides%20_%20Introduction%20to%20RNNs.pdf)     þ      - [12_Slides_Machine Translation.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/12_Slides_Machine%20Translation.pdf)    þ      - [14_Slides_A TensorFlow Chatbot.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/14_Slides_A%20TensorFlow%20Chatbot.pdf)    þ      - [16_Slides_Tensor2Tensor.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/16_Slides_Tensor2Tensor.pdf)    þ      - [CS20_intro_to_RL.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/CS20_intro_to_RL.pdf)   þ      - [march9guestlecture.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/CS%2020_Tensorflow%20for%20Deep%20Learning%20Research/march9guestlecture.pdf)    þ  + [DeepLearning_chapter-wise-pdf](https://github.com/changwookjun/StudyBook/tree/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf)     þ      - [table-of-contents.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B1%5Dtable-of-contents.pdf)  þ      - [acknowledgements.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B2%5Dacknowledgements.pdf)  þ      - [notation.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B3%5Dnotation.pdf)  þ      - [chapter-1-introduction.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B4%5Dchapter-1-introduction.pdf)  þ      - [part-1-basics.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B5%5Dpart-1-basics.pdf)  þ      - [part-1-chapter-2.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B6%5Dpart-1-chapter-2.pdf)  þ      - [part-1-chapter-3.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B7%5Dpart-1-chapter-3.pdf)  þ      - [part-1-chapter-4.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B8%5Dpart-1-chapter-4.pdf)  þ      - [part-1-chapter-5.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B9%5Dpart-1-chapter-5.pdf)  þ      - [part-2-deep-network-modern-practices.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B10%5Dpart-2-deep-network-modern-practices.pdf)  þ      - [part-2-chapter-6.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B11%5Dpart-2-chapter-6.pdf)  þ      - [part-2-chapter-7.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B12%5Dpart-2-chapter-7.pdf)  þ      - [part-2-chapter-8.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B13%5Dpart-2-chapter-8.pdf)  þ      - [part-2-chapter-9.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B14%5Dpart-2-chapter-9.pdf)        þ      - [part-2-chapter-10.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B15%5Dpart-2-chapter-10.pdf)        þ      - [part-2-chapter-11.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B16%5Dpart-2-chapter-11.pdf)        þ      - [part-2-chapter-12.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B17%5Dpart-2-chapter-12.pdf)  þ      - [part-3-deep-learning-research.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B18%5Dpart-3-deep-learning-research.pdf) þ      - [part-3-chapter-13.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B19%5Dpart-3-chapter-13.pdf) þ      - [part-3-chapter-14.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B20%5Dpart-3-chapter-14.pdf) þ      - [part-3-chapter-15.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B21%5Dpart-3-chapter-15.pdf) þ      - [part-3-chapter-16.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B22%5Dpart-3-chapter-16.pdf) þ      - [part-3-chapter-17.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B23%5Dpart-3-chapter-17.pdf) þ      - [part-3-chapter-18.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B24%5Dpart-3-chapter-18.pdf) þ      - [part-3-chapter-19.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B25%5Dpart-3-chapter-19.pdf) þ      - [part-3-chapter-20.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B26%5Dpart-3-chapter-20.pdf) þ      - [bibliography.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B27%5Dbibliography.pdf) þ      - [index.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/DeepLearning_chapter-wise-pdf/%5B28%5Dindex.pdf) þ  + [d2l-en.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/d2l-en.pdf) þ  + [Hands On Transfer Learning with Python_eBook.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Hands%20On%20Transfer%20Learning%20with%20Python_eBook.pdf) þ  + [ADVANCED_DEEP_LEARNING_WITH_KERAS.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/ADVANCED_DEEP_LEARNING_WITH_KERAS.pdf) þ  + [Dive into DeepLearning.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Dive_into_Deep_Learning.pdf)   þ  + [ee559 Deep learning](https://github.com/changwookjun/StudyBook/tree/master/DeepLearningBooks/ee559-Deeplearning)     þ  + [Hands-on-Machine-Learning-with-Scikit-2E.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Hands-on-Machine-Learning-with-Scikit-2E.pdf)  þ  + [deeplearning_2019_spring.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/deeplearning_2019_spring.pdf)    þ  + [Deep-Learning-with-PyTorch.pdf](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Deep-Learning-with-PyTorch.pdf)  þþ* [Machine Learning Books](https://github.com/changwookjun/StudyBook/tree/master/MachineLearningBooks)      þ  + [30_03_atelierdatamining.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/30_03_atelierdatamining.pdf)  þ  + [Advanced-Machine-Learning-with-Python.azw3.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Advanced-Machine-Learning-with-Python.azw3.pdf) þ  + [Bishop - Pattern Recognition And Machine Learning - Springer 2006.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)  þ  + [Building Machine Learning Projects with TensorFlow.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Building%20Machine%20Learning%20Projects%20with%20TensorFlow.pdf)  þ  + [Building Machine Learning Systems with Python, 2nd Edition.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Building%20Machine%20Learning%20Systems%20with%20Python%2C%202nd%20Edition.pdf)  þ  + [Designing Machine Learning Systems with Python 2016 {PRG}.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Designing%20Machine%20Learning%20Systems%20with%20Python%20%202016%20%7BPRG%7D.pdf)  þ  + [Hands-On Data Science and Python Machine Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Hands-On%20Data%20Science%20and%20Python%20Machine%20Learning.pdf þ)  þ  + [Introduction to Machine Learning with Python.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Large%20Scale%20Machine%20Learning%20with%20Spark.pdf)  þ  + [Large Scale Machine Learning with Spark.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Large%20Scale%20Machine%20Learning%20with%20Spark.pdf)  þ  + [Learning Predictive Analytics with Python By Ashish Kumar Feb 2016 PACKT.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Learning%20Predictive%20Analytics%20with%20Python%20By%20Ashish%20Kumar%20Feb%202016%20PACKT.pdf)  þ  + [MATLAB Machine Learning by Michael Paluszek.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/MATLAB%20Machine%20Learning%20by%20Michael%20Paluszek.pdf)  þ  + [Machine Learning Algorithms.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Machine%20Learning%20Algorithms.pdf)  þ  + [Machine Learning in Python.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Machine%20Learning%20in%20Python.pdf)  þ  + [Machine_Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Machine_Learning.pdf)  þ  + [Mastering Feature Engineering.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Mastering%20Feature%20Engineering.pdf)  þ  + [Mastering Machine Learning with scikit-learn, 2nd Edition.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Mastering%20Machine%20Learning%20with%20scikit-learn%2C%202nd%20Edition.pdf)  þ  + [Mastering Machine Learning with scikit-learn.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Mastering%20Machine%20Learning%20with%20scikit-learn.pdf)  þ  + [NG_MLY.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Ng_MLY.pdf) þ  + [Practical Machine Learning A New Look at Anomaly Detection.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Practical%20Machine%20Learning%20A%20New%20Look%20at%20Anomaly%20Detection.pdf) þ  + [Practical Machine Learning with H2O.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Python%20Data%20Analytics.pdf) þ  + [Python Data Analytics.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Mastering%20Machine%20Learning%20with%20scikit-learn.pdf) þ  + [Python Machine Learning By Example.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Python%20Machine%20Learning%20By%20Example.pdf) þ  + [Python Machine Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Python%20Machine%20Learning.pdf) þ  + [Python Real World Machine Learning - Prateek Joshi.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Python%20Real%20World%20Machine%20Learning%20-%20Prateek%20Joshi.pdf) þ  + [TensorFlow Machine Learning Cookbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/TensorFlow%20Machine%20Learning%20Cookbook.pdf) þ  + [python-machine-learning-2nd.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/python-machine-learning-2nd.pdf) þ  + [scikit-learn Cookbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/scikit-learn%20Cookbook.pdf) þ  + [Gaussian Processes for Machine Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/RW.pdf) þ  + [The Elements of Statistical Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/ESLII_print12.pdf) þ  + [Hands-On Machine Learning for Algorithmic Trading [eBook].pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Hands-On%20Machine%20Learning%20for%20Algorithmic%20Trading%20%5BeBook%5D.pdf) þ  + [Foundations of Data Science.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Foundations%20of%20Data%20Science.pdf) þ  + [cs229-cheatsheet](https://github.com/changwookjun/StudyBook/tree/master/MachineLearningBooks/cs229-cheatsheet) þ  + [Automatic_Machine_Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Automatic_Machine_Learning.pdf) þ  + [DataScienceHandbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/DataScienceHandbook.pdf) þ  + [Python Data Science Handbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/pythondatasciencehandbook.pdf) þ  + [Foundations of Data Science(Microsoft).pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/Foundations%20of%20Data%20Science(Microsoft).pdf) þþ* [Math Books](https://github.com/changwookjun/StudyBook/tree/master/MathBooks)     þ  + [MIT18_657F15_LecNote.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/MIT18_657F15_LecNote.pdf) þ  + [Mathematics for Machine Learnin.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/Mathematics%20for%20Machine%20Learnin.pdf) þ  + [mathandcomp.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/mathandcomp.pdf) þ  + [Mathematics for machine learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/Mathematics%20for%20machine%20learning.pdf) þ  + [Introduction to Applied Linear Algebra.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/Introduction%20to%20Applied%20Linear%20Algebra.pdf) þ  + [matrixcookbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/matrixcookbook.pdf) þ  + [mml-book](https://github.com/changwookjun/StudyBook/tree/master/MathBooks/mml-book)   þ  + [Mathematics for machine Learning.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/Mathematics%20for%20Machine%20Learning.pdf)  þ  + [MATHEMATICS FOR MACHINE LEARNING.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/mml-book.pdf)  þ  + [LINEAR ALGEBRA.pdf](https://github.com/changwookjun/StudyBook/blob/master/MathBooks/LINEAR%20ALGEBRA.pdf)  þþ* [NLP Books](https://github.com/changwookjun/StudyBook/tree/master/NLPBooks)     þ  + [Applied Text Analysis with Python.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/Applied%20Text%20Analysis%20with%20Python.pdf) þ  + [Jacob Perkins-Python 3 Text Processing with NLTK 3.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/Jacob%20Perkins-Python%203%20Text%20Processing%20with%20NLTK%203.pdf) þ  + [NLTK Essentials.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/NLTK%20Essentials.pdf) þ  + [Natural Language Processing with Python.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/Natural%20Language%20Processing%20with%20Python.pdf) þ  + [Python 3 Text Processing with NLTK 3 Cookbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/Python%203%20Text%20Processing%20with%20NLTK%203%20Cookbook.pdf) þ  + [Python Text Processing with NLTK 2.0 Cookbook.pdf](https://github.com/changwookjun/StudyBook/blob/master/MachineLearningBooks/scikit-learn%20Cookbook.pdf) þ  + [Text Analytics with Python A Practical Real-World Approach to Gaining Actionable Insights from your Data.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/Text%20Analytics%20with%20Python%20A%20Practical%20Real-World%20Approach%20to%20Gaining%20Actionable%20Insights%20from%20your%20Data.pdf) þ  + [The Text Mining HandBook.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/The%20Text%20Mining%20HandBook.pdf) þ  + [eisenstein-nlp-notes.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/eisenstein-nlp-notes.pdf)þ  + [oxford-cs-deepnlp-2017](https://github.com/changwookjun/StudyBook/tree/master/NLPBooks/oxford-cs-deepnlp-2017)þ    - [Lecture 1a - Introduction.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%201a%20-%20Introduction.pdf)    þ    - [Lecture 1b - Deep Neural Networks Are Our Friends.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%201b%20-%20Deep%20Neural%20Networks%20Are%20Our%20Friends.pdf)   þ    - [Lecture 2a- Word Level Semantics.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%202a-%20Word%20Level%20Semantics.pdf) þ    - [Lecture 2b - Overview of the Practicals.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%202b%20-%20Overview%20of%20the%20Practicals.pdf) þ    - [Lecture 3 - Language Modelling and RNNs Part 1.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%203%20-%20Language%20Modelling%20and%20RNNs%20Part%201.pdf) þ    - [Lecture 4 - Language Modelling and RNNs Part 2.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%204%20-%20Language%20Modelling%20and%20RNNs%20Part%202.pdf)   þ    - [Lecture 5 - Text Classification.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%205%20-%20Text%20Classification.pdf)   þ    - [Lecture 6 - Nvidia RNNs and GPUs.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%206%20-%20Nvidia%20RNNs%20and%20GPUs.pdf)   þ    - [Lecture 7 - Conditional Language Modeling.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%207%20-%20Conditional%20Language%20Modeling.pdf)   þ    - [Lecture 8 - Conditional Language Modeling with Attention.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%208%20-%20Conditional%20Language%20Modeling%20with%20Attention.pdf)   þ    - [Lecture 9 - Speech Recognition.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%209%20-%20Speech%20Recognition.pdf)   þ    - [Lecture 10 - Text to Speech.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%2010%20-%20Text%20to%20Speech.pdf)   þ    - [Lecture 11 - Question Answering.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%2011%20-%20Question%20Answering.pdf)   þ    - [Lecture 12- Memory Lecture.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%2012-%20Memory%20Lecture.pdf)    þ    - [Lecture 13 - Linguistics.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/oxford-cs-deepnlp-2017/Lecture%2013%20-%20Linguistics.pdf)      þ  + [Speech and Language Processing.pdf](https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/Speech_and_Language_Processing.pdf) þþþ* [Python Books](https://github.com/changwookjun/StudyBook/tree/master/PythonBooks)   þ  + [IPython Interactive Computing and Visualization Cookbook.pdfþ](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/IPython%20Interactive%20Computing%20and%20Visualization%20Cookbook.pdf)þ  + [Learn Python The Hard Way 3rd Edition free pdf download.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Learn%20Python%20The%20Hard%20Way%203rd%20Edition%20free%20pdf%20download.pdf)þ  + [Learning NumPy Array.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Learning%20NumPy%20Array.pdf)þ  + [Learning Pandas.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Learning%20Pandas.pdf)þ  + [Mastering Pandas for Finance.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Mastering%20Pandas%20for%20Finance.pdf)þ  + [Mastering Pandas.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Mastering%20Pandas.pdf)þ  + [Mastering-Python.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Mastering-Python.pdf)þ  + [NumPy Beginner's Guide, 2nd Edition.pdf](https://github.com/tchangwookjun/StudyBook/blob/master/PythonBooks/NumPy%20Beginner's%20Guide%2C%202nd%20Edition.pdf)þ  + [NumPy, 3rd Edition.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/NumPy%2C%203rd%20Edition.pdf)þ  + [SciPy and NumPy.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/SciPy%20and%20NumPy.pdf)þ  + [ScipyLectures-simple.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/ScipyLectures-simple.pdf)þ  + [Shaw Z.A. - Learn Python the Hard Way, 2nd Edition [2011, PDF, ENG].pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Shaw%20Z.A.%20-%20Learn%20Python%20the%20Hard%20Way%2C%202nd%20Edition%20%5B2011%2C%20PDF%2C%20ENG%5D.pdf)þ  + [Understanding GIL.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/Understanding%20GIL.pdf)þ  + [scipy-ref-0.17.0.pdf](https://github.com/changwookjun/StudyBook/blob/master/PythonBooks/scipy-ref-0.17.0.pdf)þ  þ* [Reinforcement Learning Books](https://github.com/changwookjun/StudyBook/tree/master/ReinforcementLearningBooks)  þ  + [RLAlgsInMDPs.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/RLAlgsInMDPs.pdf)þ  + [RLbook2018.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/RLbook2018.pdf)þ  + [Dissecting Reinforcement Learning](https://github.com/changwookjun/StudyBook/tree/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning)    þ    - [Dissecting Reinforcement Learning-Part1.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning/Dissecting%20Reinforcement%20Learning-Part1.pdf)   þ    - [Dissecting Reinforcement Learning-Part2.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning/Dissecting%20Reinforcement%20Learning-Part2.pdf) þ    - [Dissecting Reinforcement Learning-Part3.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning/Dissecting%20Reinforcement%20Learning-Part3.pdf) þ    - [Dissecting Reinforcement Learning-Part4.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning/Dissecting%20Reinforcement%20Learning-Part4.pdf) þ    - [Dissecting Reinforcement Learning-Part5.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning/Dissecting%20Reinforcement%20Learning-Part5.pdf)   þ    - [Dissecting Reinforcement Learning-Part6.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning/Dissecting%20Reinforcement%20Learning-Part6.pdf)   þ    - [Dissecting Reinforcement Learning-Part7.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/Dissecting%20Reinforcement%20Learning/Dissecting%20Reinforcement%20Learning-Part7.pdf)  þ  + [AI_CRASH_COURSE.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/AI_CRASH_COURSE.pdf)   þ  þ  + [UCL Course on RL d.silver](https://github.com/changwookjun/StudyBook/tree/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver)þ    - [Lecture 1: Introduction to Reinforcement Learning](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/intro_RL.pdf)  þ    - [Lecture 2: Markov Decision Processes](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/MDP.pdf)      þ    - [Lecture 3: Planning by Dynamic Programming](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/DP.pdf)  þ    - [Lecture 4: Model-Free Prediction](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/MC-TD.pdf)      þ    - [Lecture 5: Model-Free Control](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/control.pdf)      þ    - [Lecture 6: Value Function Approximation](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/FA.pdf)      þ    - [Lecture 7: Policy Gradient Methods](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/pg.pdf)      þ    - [Lecture 8: Integrating Learning and Planning](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/dyna.pdf)      þ    - [Lecture 9: Exploration and Exploitation](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/XX.pdf)      þ    - [Lecture 10: Case Study: RL in Classic Games](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/games.pdf)  þ    - [Lecture 11: Case Study: Deep RL](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/UCL%20Course%20on%20RL%20d.silver/deep_rl_tutorial.pdf)      þ    - [Video-lectures available here](https://www.youtube.com/watch?v=2pWv7GOvuf0)          þ  + [AnIntroductiontoDeepReinforcementLearning.pdf](https://github.com/changwookjun/StudyBook/blob/master/ReinforcementLearningBooks/AnIntroductiontoDeepReinforcementLearning.pdf)  þþ# AuthorþChangWookJun / @changwookjun (changwookjun@gmail.com)",
ming1016/study,,False,False,False,14091,680,3341,227,642,1,2,0,1,"[68, 217, 392, 393, 398, 729, 732, 736, 745, 753]",User,学习记录,"{'pbxproj': 1, 'xcworkspacedata': 2, 'xcuserstate': 2, 'plist': 2, 'xcbkptlist': 1, 'h': 32, 'm': 28, 'json': 34, 'storyboard': 2, '': 5, 'swift': 39, 'md': 5, 'pdf': 2, 'png': 26, 'html': 1, 'py': 100, 'java': 330, 'css': 2, 'js': 4, 'xml': 8, 'cpp': 1, 'txt': 1, 'pyc': 1, 'iml': 1, 'rb': 35, 'el': 3, 'rkt': 2, 'yin': 9, 'elt': 1}",,,Java,104,1,0,2,0,1962,True,7,5,1,0,1,1,0,0,7,0,0,0,,,3,"# 笔记þ所有笔记可以通过wiki查看：<https://github.com/ming1016/study/wiki>þþ# 更新þ* 增加了我为什么写了《跟戴铭学iOS编程》这本书<https://github.com/ming1016/study/wiki/我为什么写了《跟戴铭学iOS编程》这本书>þ* 增加了Apple 操作系统可执行文件 Mach-O <https://github.com/ming1016/study/wiki/Apple-操作系统可执行文件-Mach-O>þ* 增加如何对 iOS 启动阶段耗时进行分析：<https://github.com/ming1016/study/wiki/如何对-iOS-启动阶段耗时进行分析>þ* 增加iOS 开发舆图：<https://github.com/ming1016/study/wiki/iOS-开发舆图>þ* 增加深入剖析 JavaScriptCore：<https://github.com/ming1016/study/wiki/深入剖析-JavaScriptCore>þ* 增加读 SnapKit 和 Masonry 自动布局框架源码：<https://github.com/ming1016/study/wiki/读-SnapKit-和-Masonry-自动布局框架源码>þ* 增加Swift 项目中涉及到 JSONDecoder，网络请求，泛型协议式编程的一些记录和想法：<https://github.com/ming1016/study/wiki/Swift-项目中涉及到-JSONDecoder，网络请求，泛型协议式编程的一些记录和想法>þ* 增加Why Swift? Generics(泛型), Collection(集合类型), POP(协议式编程), Memory Management(内存管理)：<https://github.com/ming1016/study/wiki/Why-Swift%3F-Generics(泛型),-Collection(集合类型),-POP(协议式编程),-Memory-Management(内存管理)>þ* 增加HTML 转原生 HTN 项目开发记录：<https://github.com/ming1016/study/wiki/HTML-转原生-HTN-项目开发记录>þ* 增加深入剖析 WebKit ：<https://github.com/ming1016/study/wiki/深入剖析-WebKit>þ* 增加深入剖析 iOS 性能优化：<https://github.com/ming1016/study/wiki/深入剖析-iOS-性能优化>þ* 增加了用 Swift 编写的工程代码静态分析命令行工具 smck：<https://github.com/ming1016/study/wiki/用-Swift-编写的工程代码静态分析命令行工具-smck>þ* 增加深入剖析 iOS 编译 Clang / LLVM：<https://github.com/ming1016/study/wiki/深入剖析-iOS-编译-Clang---LLVM>þ* 增加感叹在开发中冥思苦想后灵光一现的那些思路：<https://github.com/ming1016/study/wiki/感叹在开发中冥思苦想后灵光一现的那些思路>þ* 增加iOS预加载Web页面方案：<https://github.com/ming1016/study/wiki/iOS预加载Web页面方案>þ* 增加使用Swift3开发了个macOS的程序可以检测出objc项目中无用方法，然后一键全部清理：<https://github.com/ming1016/study/wiki/使用Swift3开发了个macOS的程序可以检测出objc项目中无用方法，然后一键全部清理>þ* 增加使用ReactiveCocoa开发RSS阅读器：<https://github.com/ming1016/study/wiki/使用ReactiveCocoa开发RSS阅读器>þ* 增加iOS多线程操作时一些要注意的安全问题：<https://github.com/ming1016/study/wiki/iOS多线程操作时一些要注意的安全问题>þ* 增加iOS函数响应式编程以及ReactiveCocoa的使用：<https://github.com/ming1016/study/wiki/iOS函数响应式编程以及ReactiveCocoa的使用>þ* 增加制作一个类似苹果VFL(Visual Format Language)的格式化语言来描述类似UIStackView那种布局思路，并解析生成页面：<https://github.com/ming1016/study/wiki/制作一个类似苹果VFL%28Visual-Format-Language%29的格式化语言来描述类似UIStackView那种布局思路，并解析生成页面>þ* 增加从ReactiveCocoa中能学到什么？不用此库也能学以致用文章：<https://github.com/ming1016/study/wiki/从ReactiveCocoa中能学到什么？不用此库也能学以致用>þ* 增加iOS页面响应电量流量监测文章：<https://github.com/ming1016/study/wiki/iOS页面响应、电量、流量分析>þ* 增加iOS性能监测文章：<https://github.com/ming1016/study/wiki/检测iOS的APP性能的一些方法>þ* 增加一篇关于解耦实践的文章：<https://github.com/ming1016/study/wiki/竭尽全力的去解耦的一次实践，封装一个TableView和一些功能组合的控件>þ* 增加iOS新人指引：<https://github.com/ming1016/study/wiki/给未接触iOS开发的同学推荐的入门资料，不多，但都是精华>þ* 增加WWDC Session的page：<https://github.com/ming1016/study/wiki/WWDC-Session>þ* 增加深入剖析Auto Layout，分析iOS各版本新增特性：<https://github.com/ming1016/study/wiki/深入剖析Auto-Layout，分析iOS各版本新增特性>þ* 增加构建iOS稳定应用架构时方案选择的思考：<https://github.com/ming1016/study/wiki/构建iOS稳定应用架构时方案选择的思考>þ* 增加校招iOS面试题：<https://github.com/ming1016/study/wiki/校招iOS面试题>þ* 增加Masonry的page：<https://github.com/ming1016/study/wiki/Masonry>þ* 增加如何将自己的库或控件通过制作podspec提交到Cocoapods官方git上供所有人用或者设置为私有库给自己团队来使用的page：<https://github.com/ming1016/study/wiki/如何将自己的库或控件通过制作podspec提交到Cocoapods官方git上供所有人用或者设置为私有库给自己团队来使用>þ* 增加iOS书籍推荐的page：<https://github.com/ming1016/study/wiki/iOS书籍推荐>þ* 增加iOS性能优化的page：<https://github.com/ming1016/study/wiki/iOS性能优化>þ* 增加iOS设计模式的page：<https://github.com/ming1016/study/wiki/iOS设计模式>þ* 增加iOS视频的page：<https://github.com/ming1016/study/wiki/iOS视频>þ* 增加OpenCV的page：<https://github.com/ming1016/study/wiki/OpenCV>þ* 增加GPU处理图像的page：<https://github.com/ming1016/study/wiki/GPU%E5%A4%84%E7%90%86%E5%9B%BE%E5%83%8F>þ* 增加Core Image的page：<https://github.com/ming1016/study/wiki/Core-Image>þ* 增加PhotoKit的page：<https://github.com/ming1016/study/wiki/PhotoKit>þ* 增加Camera的page：<https://github.com/ming1016/study/wiki/Camera>þ* 更新了Block的page，添加了block的创建，不带参数的block，block闭包，修改非局部变量，block作为函数参数，定义block类型的内容：<https://github.com/ming1016/study/wiki/Block>þ* 更新了iOS并发编程，GDC队列，使用Barrier避免写死锁，dispatch_sync解决读死锁。两种GCD中Dispatch_groups发送通知的方法以及dispatch_block_cancel的使用示例：<https://github.com/ming1016/study/wiki/iOS%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B>þ* 增加了算法的page：<https://github.com/ming1016/study/wiki/%E7%AE%97%E6%B3%95>þ* 增加了Objc Runtime的page: <https://github.com/ming1016/study/wiki/Objc-Runtime>þ* 增加了RSS分类整理的page：<https://github.com/ming1016/study/wiki/RSS%E5%88%86%E7%B1%BB%E6%95%B4%E7%90%86>þ* 增加了CFRunLoop的page：<https://github.com/ming1016/study/wiki/CFRunLoop>þ* 增加了iOS并发编程的page：<https://github.com/ming1016/study/wiki/iOS%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B>þ* 增加了Auto Layout的page：<https://github.com/ming1016/study/wiki/Auto-Layout>þ* 增加了UIView的page：<https://github.com/ming1016/study/wiki/UIView>þ* 增加了UICollectionView的page：<https://github.com/ming1016/study/wiki/UICollectionView>þ* 增加了Core Data的page：<https://github.com/ming1016/study/wiki/Core-Data>þ* 增加了iOS Background Tasks的page：<https://github.com/ming1016/study/wiki/iOS-Background-Tasks>þ* 增加了NSURLSession的page：<https://github.com/ming1016/study/wiki/NSURLSession>þ* 增加了NSURLConnection的page：<https://github.com/ming1016/study/wiki/NSURLConnection>þ* 增加了View Controller转场page：<https://github.com/ming1016/study/wiki/View-Controller%E8%BD%AC%E5%9C%BA>þ* 增加了TextKit的page：<https://github.com/ming1016/study/wiki/TextKit>þ* 增加了Block的page：<https://github.com/ming1016/study/wiki/Block>þ* 增加iOS基础集合类page：<https://github.com/ming1016/study/wiki/iOS%E5%9F%BA%E7%A1%80%E9%9B%86%E5%90%88%E7%B1%BB>þ* 增加iOS字符串的笔记page：<https://github.com/ming1016/study/wiki/iOS%E5%AD%97%E7%AC%A6%E4%B8%B2>þ* 增加Core Animation的笔记page<https://github.com/ming1016/study/wiki/Core-Animation>þ* 增加swift简明带例子的手册page<https://github.com/ming1016/study/wiki/swift>þ* 增加Xcode调试之LLDB的page<https://github.com/ming1016/study/wiki/Xcode%E8%B0%83%E8%AF%95%E4%B9%8BLLDB>þ* 增加Markdown实用的page<https://github.com/ming1016/study/wiki/MarkDown>þ* 添加wiki首页<https://github.com/ming1016/study/wiki>",
Yixiaohan/show-me-the-code,,False,False,False,24,2,11251,1298,4732,0,0,0,0,"[243, 941, 950, 1114, 1425, 1797, 1912, 2034, 2047, 2068]",User,Python 练习册，每天一个小程序,"{'': 1, 'md': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",,33,1,0,1,3,2137,True,2,7,0,0,3,35,0,0,7,0,0,0,,,1,"## Python 练习册，每天一个小程序 ##þþþ#### 说明： ####þþ- Python 练习册，每天一个小程序。注：将 Python 换成其他语言，大多数题目也适用þ- 不会出现诸如「打印九九乘法表」、「打印水仙花」之类的题目þ- [点此链接，会看到部分题目的代码，仅供参考](https://github.com/Show-Me-the-Code/python)þ- 本文本文由@史江歌（shijiangge@gmail.com  QQ:499065469）根据互联网资料收集整理而成，感谢互联网，感谢各位的分享。鸣谢！本文会不断更新。þþ> Talk is cheap. Show me the code.--Linus Torvaldsþþ----------þ þ**第 0000 题：** 将你的 QQ 头像（或者微博头像）右上角加上红色的数字，类似于微信未读信息数量那种提示效果。þ类似于图中效果þþ![头像](http://i.imgur.com/sg2dkuY.png?1)þþ**第 0001 题：** 做为 Apple Store App 独立开发者，你要搞限时促销，为你的应用**生成激活码**（或者优惠券），使用 Python 如何生成 200 个激活码（或者优惠券）？þþ**第 0002 题:** 将 0001 题生成的 200 个激活码（或者优惠券）保存到 **MySQL** 关系型数据库中。 þþ**第 0003 题：** 将 0001 题生成的 200 个激活码（或者优惠券）保存到 **Redis** 非关系型数据库中。 þþ**第 0004 题：** 任一个英文的纯文本文件，统计其中的单词出现的个数。þþ**第 0005 题：** 你有一个目录，装了很多照片，把它们的尺寸变成都不大于 iPhone5 分辨率的大小。þþ**第 0006 题：** 你有一个目录，放了你一个月的日记，都是 txt，为了避免分词的问题，假设内容都是英文，请统计出你认为每篇日记最重要的词。þþ**第 0007 题：** 有个目录，里面是你自己写过的程序，统计一下你写过多少行代码。包括空行和注释，但是要分别列出来。þþ**第 0008 题：** 一个HTML文件，找出里面的**正文**。þþ**第 0009 题：** 一个HTML文件，找出里面的**链接**。þþ**第 0010 题：** 使用 Python 生成类似于下图中的**字母验证码图片**þþ![字母验证码](http://i.imgur.com/aVhbegV.jpg)þþ- [阅读资料](http://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python) þþ**第 0011 题：** 敏感词文本文件 filtered_words.txt，里面的内容为以下内容，当用户输入敏感词语时，则打印出 Freedom，否则打印出 Human Rights。þþ    北京þ    程序员þ    公务员þ    领导þ    牛比þ    牛逼þ    你娘þ    你妈þ    loveþ    sexþ jianggeþ þ**第 0012 题：** 敏感词文本文件 filtered_words.txt，里面的内容 和 0011题一样，当用户输入敏感词语，则用 星号 * 替换，例如当用户输入「北京是个好城市」，则变成「**是个好城市」。þþ**第 0013 题：** 用 Python 写一个爬图片的程序，爬 [这个链接里的日本妹子图片 :-)](http://tieba.baidu.com/p/2166231880)þþ- [参考代码](http://www.v2ex.com/t/61686 ""参考代码"")þþ**第 0014 题：** 纯文本文件 student.txt为学生信息, 里面的内容（包括花括号）如下所示：þþ    {þ     ""1"":[""张三"",150,120,100],þ     ""2"":[""李四"",90,99,95],þ     ""3"":[""王五"",60,66,68]þ    }þþ请将上述内容写到 student.xls 文件中，如下图所示：þþ![student.xls](http://i.imgur.com/nPDlpme.jpg)þþ- [阅读资料](http://www.cnblogs.com/skynet/archive/2013/05/06/3063245.html) 腾讯游戏开发 XML 和 Excel 内容相互转换þþ**第 0015 题：** 纯文本文件 city.txt为城市信息, 里面的内容（包括花括号）如下所示：þþ    {þ        ""1"" : ""上海"",þ        ""2"" : ""北京"",þ        ""3"" : ""成都""þ    }þþ请将上述内容写到 city.xls 文件中，如下图所示：þþ![city.xls](http://i.imgur.com/rOHbUzg.png)þþþ**第 0016 题：** 纯文本文件 numbers.txt, 里面的内容（包括方括号）如下所示：þþ    [þ     [1, 82, 65535], þ     [20, 90, 13],þ     [26, 809, 1024]þ    ]þþ请将上述内容写到 numbers.xls 文件中，如下图所示：þþ![numbers.xls](http://i.imgur.com/iuz0Pbv.png)þþ**第 0017 题：** 将 第 0014 题中的 student.xls 文件中的内容写到 student.xml 文件中，如þþ下所示：þþ    <?xml version=""1.0"" encoding=""UTF-8""?>þ    <root>þ    <students>þ    <!-- þ     学生信息表þ     ""id"" : [名字, 数学, 语文, 英文]þ    -->þ    {þ     ""1"" : [""张三"", 150, 120, 100],þ     ""2"" : [""李四"", 90, 99, 95],þ     ""3"" : [""王五"", 60, 66, 68]þ    }þ    </students>þ    </root>þþþ**第 0018 题：** 将 第 0015 题中的 city.xls 文件中的内容写到 city.xml 文件中，如下þ所示：þþ```þ    <?xmlversion=""1.0"" encoding=""UTF-8""?>þ    <root>þ    <cities>þ    <!-- þ     城市信息þ    -->þ    {þ     ""1"" : ""上海"",þ     ""2"" : ""北京"",þ     ""3"" : ""成都""þ    }þ    </cities>þ    </root>þ```þþ**第 0019 题：** 将 第 0016 题中的 numbers.xls 文件中的内容写到 numbers.xml 文件中，如下þþ所示：þþ    <?xml version=""1.0"" encoding=""UTF-8""?>þ    <root>þ    <numbers>þ    <!-- þ     数字信息þ    -->þ    þ    [þ     [1, 82, 65535],þ     [20, 90, 13],þ     [26, 809, 1024]þ    ]þ    þ    </numbers>þ    </root>þþ**第 0020 题：** [登陆中国联通网上营业厅](http://iservice.10010.com/index_.html) 后选择「自助服务」 --> 「详单查询」，然后选择你要查询的时间段，点击「查询」按钮，查询结果页面的最下方，点击「导出」，就会生成类似于 2014年10月01日～2014年10月31日通话详单.xls 文件。写代码，对每月通话时间做个统计。þþ**第 0021 题：** 通常，登陆某个网站或者 APP，需要使用用户名和密码。密码是如何加密后存储起来的呢？请使用 Python 对密码加密。þþ- 阅读资料 [用户密码的存储与 Python 示例](http://zhuoqiang.me/password-storage-and-python-example.html)þþ- 阅读资料 [Hashing Strings with Python](http://www.pythoncentral.io/hashing-strings-with-python/)þþ- 阅读资料 [Python's safest method to store and retrieve passwords from a database](http://stackoverflow.com/questions/2572099/pythons-safest-method-to-store-and-retrieve-passwords-from-a-database)þþ**第 0022 题：** iPhone 6、iPhone 6 Plus 早已上市开卖。请查看你写得 第 0005 题的代码是否可以复用。þþ**第 0023 题：** 使用 Python 的 Web 框架，做一个 Web 版本 留言簿 应用。þþ[阅读资料：Python 有哪些 Web 框架](http://v2ex.com/t/151643#reply53)þþ- ![留言簿参考](http://i.imgur.com/VIyCZ0i.jpg)þþþ**第 0024 题：** 使用 Python 的 Web 框架，做一个 Web 版本 TodoList 应用。þþ- ![SpringSide 版TodoList](http://i.imgur.com/NEf7zHp.jpg)þþ**第 0025 题：** 使用 Python 实现：对着电脑吼一声,自动打开浏览器中的默认网站。þþþ    例如，对着笔记本电脑吼一声“百度”，浏览器自动打开百度首页。þ    þ    关键字：Speech to Textþ    þ参考思路：    þ1：获取电脑录音-->WAV文件þ    python record wavþþ2：录音文件-->文本þþ    STT: Speech to Textþ    þ    STT API Google APIþþ3:文本-->电脑命令",
keesun/study,,False,False,False,7422,270,372,62,170,1,86,131,1,"[112, 463, 464, 478, 487, 530, 540, 548, 578, 590]",User,"Learn, Share and Grow","{'md': 20, 'pdf': 1, '': 25, 'java': 146, 'jar': 11, 'properties': 25, 'cmd': 11, 'xml': 11, 'reg': 3, 'jks': 1, 'html': 6, 'p12': 2, 'yml': 1, 'adoc': 2, 'txt': 2, 'ssl': 1, 'pem': 2}",,,Java,118,3,0,5,0,829,True,0,3,0,0,2,7,2,0,9,0,0,0,,,751,"# WelcomeþHi, This is Keesun (AKA, Whiteship) and this repository would contain the things that I am interested in.þ**ALL THE CONTENTS ARE OWNED AND MADE BY Keesun.**þþ# Online Coursesþ## [:computer: Spring Framework Introduction](https://www.inflearn.com/course/spring/)þ## [:computer: Spring Framework Core Technology](https://www.inflearn.com/course/spring-framework_core/)þ## [:computer: Spring Boot](https://www.inflearn.com/course/%EC%8A%A4%ED%94%84%EB%A7%81%EB%B6%80%ED%8A%B8/)þ## [:computer: Spring Data JPA](https://www.inflearn.com/course/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%8D%B0%EC%9D%B4%ED%84%B0-jpa/)þ## [:computer: REST API Development with Spring](https://www.inflearn.com/course/spring_rest-api/)þþ# Youtubeþ## [:tv: InfoQ articles](infoq.md)þ## [:tv: Spring Data JPA](spring-data-jpa-reference-coding.md)þ## [:tv: Hibernate ORM Reference Coding](hibernate-orm-reference-coding.md)þ## [:tv: :book: Effective Java](https://github.com/keesun/study/tree/master/effective-java)þ## [:tv: Spring Boot Reference Coding 1-39 (完)](spring-boot-reference-coding.md)þ## [:tv: Getting Started Docker 1-3 (完)](doker-getting-started.md)þ## [:tv: Getting Started Kubernetes 1-3(完)](kubernetes-getting-started.md)þþ# Repositoryþ## [REST API Development WIth Spring](https://github.com/keesun/study/tree/master/rest-api-with-spring)þþ# Cheet Sheetþ## [Docker cheetsheet](docker-cmds.md)",
hoanhan101/ultimate-go,,False,False,False,1153,84,11387,367,865,11,81,88,6,"[18, 57, 68, 69, 71, 94, 96, 103, 130, 164]",User,Ultimate Go study guide,"{'': 3, 'md': 3, 'mod': 1, 'sum': 1, 'go': 75, 'png': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",Go,215,1,0,20,2,805,True,2,7,2,1,1,27,1,6,8,0,0,0,,,344,"# Ultimate Go study guideþþ[![Go Report Card](https://goreportcard.com/badge/github.com/hoanhan101/ultimate-go)þ](https://goreportcard.com/report/github.com/hoanhan101/ultimate-go)þ![](https://img.shields.io/github/stars/hoanhan101/ultimate-go)þ![](https://img.shields.io/github/forks/hoanhan101/ultimate-go)þ[![hackernews](https://img.shields.io/badge/hackernews-450%2B-orange)](https://news.ycombinator.com/item?id=20701671)þ[![r/golang](https://img.shields.io/badge/r/golang-255%2B-orange)](https://www.reddit.com/r/golang/comments/cqqi9h/ultimate_go_study_guides_with_heavily_documented/)þ[![r/compsci](https://img.shields.io/badge/r/compsci-60%2B-orange)](https://www.reddit.com/r/compsci/comments/cr3jzh/ultimate_go_study_guides_with_heavily_documented/)þ[![r/programming](https://img.shields.io/badge/r/programming-40%2B-orange)](https://www.reddit.com/r/programming/comments/cr3gqu/ultimate_go_study_guides_with_heavily_documented/)þþ> [101+ coding interview problems with detailed solutions, test cases, and program analysis →](https://github.com/hoanhan101/algo)þþ> [Join my mailing list to get the latest updates here →](https://tinyletter.com/hoanhan)þþ<p align=""center"">þ  <img src=""gopher.png"" alt=""gopher"" width=""300""/>þ</p>þþ## MotivationþþThis repo contains my notes on learning Go and computer systems. Different people have differentþlearning style. For me, I learn best by doing and walking through examples. Hence, I am trying toþtake notes carefully and comment directly on the source code, rather than writing up Markdownþfiles. That way, I can understand every single line of code as I am reading and also be mindful ofþthe theories behind the scene.þþIn the mix, I also include links to other articles that I find helpful.þþIf you’re interested in getting updates for this, feel free to join my [mailing þlist here →](https://tinyletter.com/hoanhan)þþ## Table of Contents þþ- **Design Philosophy**:þ  [Guideline](https://github.com/ardanlabs/gotraining/blob/master/topics/go/README.md)þ- **Language Mechanics**þ  - **Syntax**þ    - Variable: [Built-in types | Zero value concept | Initialization | Conversion vs Casting](go/language/variable.go)þ    - Struct: [Initialization | Name type vs Anonymous type](go/language/struct.go)þ    - Pointer: þ      - [Passing by value | Escape analysis | Stack space | Garbage Collection](go/language/pointer.go)þ      - [Golang's Code Review Receiver Type](https://github.com/golang/go/wiki/CodeReviewComments#receiver-type)þ    - Constant: [Initialization | iota](go/language/constant.go)þ    - Function: [Initialization](go/language/function.go)þ  - **Data Structures**þ    - Array: [CPU Cache | TLB | Initialization | Iteration | Type array | Contiguous memory allocation](go/language/array.go)þ    - Slice: [Initialization | Length vs Capacity | Reference Type | Appending | Slice of Slice | Copy of Slice | UTF-8](go/language/slice.go)þ    - Map: [Initialization | Iteration | Deleting | Finding | Restriction ](go/language/map.go)þ  - **Decoupling**þ    - Method: þ      - [Value and Pointer Receiver Call](go/language/method_1.go)þ      - [Value and Pointer Semantics](go/language/method_2.go)þ      - [Methods are just functions | Function variable](go/language/method_3.go)þ    - Interface: þ      - [Valueless type | Concrete type vs Interface type | Relationship | Polymorphic function](go/language/interface_1.go)þ      - [Interface via Pointer Receiver | Method set | Slice of Interface](go/language/interface_2.go)þ    - Embedding: þ      - [Declaring fields, NOT Embedding](go/language/embedding_1.go)þ      - [Embedding type | Inner type promotion](go/language/embedding_2.go)þ      - [Embedded type and Interface](go/language/embedding_3.go)þ      - [Outer and inner type implementing the same Interface](go/language/embedding_4.go)þ    - Exporting:þ      - [Guideline](go/language/exporting/README.md)þ      - [Exported identifier](go/language/exporting/exporting_1)þ      - [Accessing a value of an unexported identifier](go/language/exporting/exporting_2)þ      - [Unexported fields from an exported struct](go/language/exporting/exporting_3)þ      - [Exported types with embedded unexported types](go/language/exporting/exporting_4)þ- **Software Design**þ  - Composition:þ    [Guideline](https://github.com/ardanlabs/gotraining/tree/master/topics/go#interface-and-composition-design)þ    - Grouping types: þ      - [Grouping By State](go/design/grouping_types_1.go)þ      - [Grouping By Behavior](go/design/grouping_types_2.go)þ    - Decoupling: þ      - [Struct Composition](go/design/decoupling_1.go)þ      - [Decoupling With Interface](go/design/decoupling_2.go)þ      - [Interface Composition](go/design/decoupling_3.go)þ      - [Decoupling With Interface Composition](go/design/decoupling_4.go)þ    - Conversion: þ      - [Interface Conversions | Type Assertion](go/design/conversion_1.go)þ      - [Runtime Type Assertion](go/design/conversion_2.go)þ    - Interface Pollution: þ      - [Interface Pollution](go/design/pollution_1.go)þ      - [Remove Interface Pollution](go/design/pollution_2.go)þ    - Mocking: þ      - [Package To Mock](go/design/mocking_1.go)þ      - [Sample Client](go/design/mocking_2.go)þ  - Error Handling: þ    - [Default error values](go/design/error_1.go)þ    - [Error variables](go/design/error_2.go)þ    - [Type as context](go/design/error_3.go)þ    - [Behavior as context](go/design/error_4.go)þ    - [Finding the bug/pitfall of nil value of error interface](go/design/error_5.go)þ    - [Wrapping Errors](go/design/error_6.go)þ  - Packaging: [Guideline](https://github.com/ardanlabs/gotraining/blob/master/topics/go/design/packaging/README.md)þ  - Dependency management: [Go Modules](https://blog.golang.org/using-go-modules)þ- **Concurrency**þ  - **Mechanics**þ    - Goroutine: þ      - [Go Scheduler Internals](go/concurrency/goroutine_1.go)þ      - [Language Mechanics](go/concurrency/goroutine_2.go)þ      - [Goroutine time slicing](go/concurrency/goroutine_3.go)þ      - [Goroutines and parallelism](go/concurrency/goroutine_4.go)þ    - Data race: þ      - [Race Detection](go/concurrency/data_race_1.go)þ      - [Atomic Functions](go/concurrency/data_race_2.go)þ      - [Mutexes](go/concurrency/data_race_3.go)þ      - [Read/Write Mutex](go/concurrency/data_race_4.go)þ    - Channel: þ      - [Guideline](https://github.com/ardanlabs/gotraining/tree/master/topics/go#concurrent-software-design)þ      - [Language Mechanics | Unbuffered channel: Signaling with(out) data](go/concurrency/channel_1.go)þ      - [Unbuffered channel: Double signal | Buffered channel: Close and range | Unbuffered channel: select and receive | Unbuffered channel: select and send | Buffered channel: Select and drop](go/concurrency/channel_2.go)þ      - [Unbuffered channel (Tennis match)](go/concurrency/channel_3.go)þ      - [Unbuffered channel (Replay race)](go/concurrency/channel_4.go)þ      - [Buffered channel: Fan Out](go/concurrency/channel_5.go)þ      - [Select](go/concurrency/channel_6.go)þ  - **Patterns**þ    - Context: þ      - [Store and retrieve values from a context](go/concurrency/context_1.go)þ      - [WithCancel](go/concurrency/context_2.go)þ      - [WithDeadline](go/concurrency/context_3.go)þ      - [WithTimeout](go/concurrency/context_4.go)þ      - [Request/Response](go/concurrency/context_5.go)þ    - Patternþ      - Taskþ      - Loggerþ- **Testing and Profiling**þ  - Testing: þ    - [Basic Unit Test](go/testing/basic_test.go)þ    - [Table Test](go/testing/table_test.go)þ    - [Sub Test](go/testing/sub_test.go)þ    - [Web Server](go/testing/web_server)þ    - [Mock Server](go/testing/web_test.go)þ    - [Test Coverage](go/testing/README.md)þ  - Benchmarkingþ    - [Basic Benchmark](go/benchmark/basic_test.go)þ    - [Sub Benchmark](go/benchmark/sub_test.go)þ  - Fuzzingþ    - [Guideline](https://github.com/ardanlabs/gotraining/blob/master/topics/go/testing/fuzzing/README.md)þ  - Profilingþ    - Stack Trace: [Review](go/profiling/stack_trace_1.go) | [Packing](go/profiling/stack_trace_2.go)þ    - GODEBUG: [Memory Tracing](go/profiling/memory_tracing.go)þþ## For more resources:þþ- [Ultimate Go Programming](https://www.safaribooksonline.com/library/view/ultimate-go-programming/9780134757476/)þ- [ardanlabs/gotraining/topics/courses/go](https://github.com/ardanlabs/gotraining/blob/master/topics/courses/go/README.md)þ- [Computer Systems: A Programmer's Perspective](https://www.amazon.com/Computer-Systems-Programmers-Perspective-3rd/dp/013409266X)þ- [Free Gophers Pack](https://github.com/MariaLetta/free-gophers-pack)þ- [Thoughts on Go performance optimization](https://github.com/dgryski/go-perfbook)þþ## Stargazers over timeþþ[![Stargazers over time](https://starchart.cc/hoanhan101/ultimate-go.svg)](https://starchart.cc/hoanhan101/ultimate-go)",
cokecoffe/ios-demo,,False,False,False,28211,2700,261,49,316,0,0,0,0,"[812, 1858, 2523, 2557, 2589, 2614, 2621, 2634, 2641, 2643]",User,demos for ios study.,"{'': 285, 'pbxproj': 82, 'xcworkspacedata': 52, 'xcuserstate': 62, 'xcsettings': 7, 'xcbkptlist': 26, 'xcscheme': 63, 'plist': 159, 'pch': 84, 'h': 571, 'm': 549, 'strings': 61, 'xib': 145, 'png': 282, 'rtf': 4, 'md': 14, 'jpg': 11, 'storyboard': 7, 'a': 2, '1': 4, 'txt': 11, 'xml': 1, 'c': 2, 'glsl': 2, 'mdown': 2, 'markdown': 3, 'jpeg': 1, 'm4v': 1, 'mode1v3': 7, 'pbxuser': 7, 'nib': 11, 'hmap': 15, 'dep': 9, 'o': 16, 'linkfilelist': 3, 'dat': 9, 'pbxbtree': 24, 'header': 3, 'pbxsymbols': 3, 'wav': 4, 'mobileprovision': 1, 'xcent': 1, 'db': 1, 'caf': 1, 'json': 37, 'svn-base': 44, 'rb': 3, 'icns': 1, 'textile': 1, 'p12': 1, 'xcconfig': 1, 'sh': 1, 'html': 1, 'gz': 1, 'pdf': 1}",,,Objective-C,163,1,0,0,0,3008,True,2,2,0,0,3,0,0,0,6,0,0,0,,,45,"## 数据库相关：þþ1. SQLite的基本使用：þ一个联系人的Demo，可以存储用户名，地址，电话号码，并提供了查询功能。þ2. SQLiteSample：þ一个完整封装了的SQLite的使用例子,来源于 [易飞扬][yifiyang]的博客，我做了一些改动。 þþ## 视图方面þþ1. UITableview的异步加载:þTableview:实现上提更新数据þ2. NavigationController的使用：þ包括设置导航栏标题、左右按钮、返回按钮标题þ3. animation þUIView过场动画:[博客][uiviewAnimal]þ4. ProgressHUD:þ状态指示器þ5. RadioButtonWithUIKit:þ单选框的实现þ5.1 CheckBox 单选框的实现þ6. LazyTableImages:þApple官方的列表中图片异步加载þ7. TPKeyboardAvoidingþ防止键盘遮挡UITextFieldþ8. iPad_popoverViewþ适用于iPad的弹出框例子þ9. RadioTableþ单选列表的实现，支持异步请求数据，支持联动选择þ10. CoreAnimationBeginþCoreAnimation的简单入门,CABasicAnimation\CAKeyframeAnimation\CAAnimationGroup基本使用þ11. Pop_TableViewDemoþ二级联动选择列表þ12. Quartz2DþQuartz2Dþ13. AutoScrollLabelþLabel跑马灯效果þ14. UIScrollViewsþ滚动视图的使用þ15. CorePlotDemoþ绘制图表的Demo，包括饼图，柱状图，折线图þ16. SwipeBarþ抽屉效果þ17. Pickersþ滚轮的基本使用þ18. dynamicSearchViewþ一个搜索筛选的例子，可以动态添加或者删除筛选条件，需要筛选的控制器需要实现协议。þ19. UIView_Animation、UIView_Animation2þUIView基本动画使用\UIView动画的 一些技巧þ20. tableviewHeadViewþ滑动表格可以隐藏或消失表格上面的一个视图，比如搜索框。þþ## Web方面þ1. HTTP:þ演示IOS5的JSON解析支持与HTTP的POST、GETþ2. UeNetWork:þ测试网络链接，获取IP，同步异步下载，身份验证，XML、JSON解析 总结þ3. SOAP:þ使用SOAP协议向服务器请求，返回XML，并解析þ4. WebServiceLocalTimeSoapþ使用WSDL2ObjC转换为oc后soap方式访问webservice。þ5. WebServiceDemo:þ访问WebService的一个例子,使用了MBProgressHUD ASIHTTPRequest JSON三个库þ6. XMPP_Demo：þ一个使用XMPP的简单的例子，能显示好友列表，发送接受消息。[我的博客][xmpp]þ7. WSDL2ObjC_exampleþwebservice访问的例子，使用wsdl2objec解析wsdlþþ## 外设þ1. CustomCameraþ定制相机视图þ2. CameraWithAVFoudationþ使用AVFoundation库实现的相机þ3. GPSDemoþGPS定位解析地址,兼容IOS456þþþ## Otherþ1. KVO_TestDemoþkvo基本使用þ2. copyþ深拷贝，浅拷贝的理解，[我的博客][deepcopy]这里有说明þ3. excel-plistþexcel转plistþ4. CaseToolþ大小写转换þ5. CrashLogþ崩溃日志记录þ6. appLifeCycleþapp生命周期的应用þ7. Dispatch_queueþ分发队列的练习，包括并行、串行队列。分组队列等。from <<ios5 cook book>>þ8. TheElementsþ苹果的元素周期表的demo，很好的展示了mvc的使用þþ[deepcopy](http://www.cnblogs.com/cokecoffe/archive/2012/07/25/2607477.html)þ[yifiyang](http://www.yifeiyang.net/iphone-developer-advanced-9-management-database-using-sqlite/)þ[uiviewAnimal](http://www.cnblogs.com/v2m_/archive/2011/10/28/2227979.html)þ[xmpp](http://www.cnblogs.com/cokecoffe/archive/2012/08/22/2651645.html?updated=1)",
BombinS/yandex_frontend_first,,False,False,False,204,7,0,1,0,0,0,0,0,[546],User,,"{'pdf': 1, 'js': 6}",,,JavaScript,4,1,0,0,1,546,True,0,0,0,0,0,0,0,0,8,0,0,0,,,1,,
ggj2010/javabase,,False,False,False,2313,555,77,18,88,0,0,0,0,"[585, 586, 589, 591, 592, 593, 662, 663, 678, 696]",User,study~,"{'': 2, 'md': 7, 'xml': 42, 'iml': 6, 'java': 427, 'sql': 4, 'yml': 7, 'properties': 5, 'html': 17, 'js': 20, 'map': 1, 'json': 1, 'jsp': 1, 'vue': 1, 'txt': 3, 'xsd': 1, 'docx': 1, 'log': 1, 'ftl': 8}",,"{'key': 'apache-2.0', 'name': 'Apache License 2.0', 'spdx_id': 'Apache-2.0', 'url': 'https://api.github.com/licenses/apache-2.0', 'node_id': 'MDc6TGljZW5zZTI='}",Java,139,1,0,0,0,1648,True,0,2,0,0,0,0,0,0,7,0,0,0,,,48,# java学习记录一些东西和teamstudy类似þ    整个项目比较乱，模块分的也比较随意，这些只是自己在空闲的时候用来review 代码的。þ## 模块þ      ```þ            <module>thread</module>þ            <module>socket</module>þ            <module>lambada</module>þ            <module>kafka</module>þ            <module>zookeeper</module>þ            <module>redis</module>þ            <module>js</module>þ            <module>httpclient</module>þ            <module>mobiletechnology</module>þ             <module>webmagic</module>þ      ```þ     目前有这几个模块，以后可能会有新的模块添加进去的þ### thread模块þþ    这个模块主要用来记录一些多线程基础。具体干什么的代码里面都有注释þ### httpclient模块þ      这个模块是用来记录怎么使用httpclient这个工具，以及新老版本的切换和api调用，同时也写了一个demo，用来爬取邮乐网的用户地址信息，þ      模拟用户登陆，然后抓取用户收货地址，保存到redis.当时是有那么一个漏洞，可以访问任意用户的收货地址þ### mobiletechnology模块þ        因为目前在手机组，刚好公司的某个手机后台api项目需要重构，于是自己也搭建了一套。þ      api后台模块设计可以参考这个人的博客：http://blog.csdn.net/newjueqi/article/details/19003775þ      目前完成的功能是利用springboot+redis 搭建的一套restful风格的apiþ      总结下几个核心的功能：springboot的自定义拦截和全局异常处理 包括返回值code设计，和一些简单的参数加密和签名校验。þ      以后准备引入dubbo+kafka。dubbo的源码看了一段时间又放下了，下个星期来了继续研读。þ###webmagic模块þ    有意思的爬虫,
dongdeshaui-cn/super-dong,,False,False,False,49,1,0,0,0,0,0,0,0,[1108],User,study study study study study study,{'md': 1},,,,1,1,0,0,0,1108,True,0,0,0,0,0,0,0,0,7,0,0,0,,,0,# super-dongþstudy study study study study study,
CJ-bot/study,,False,False,False,7,14,0,1,0,0,0,0,0,"[287, 293, 300]",User,study study study study study,"{'html': 6, 'js': 6, 'md': 2}",,,HTML,3,1,0,0,0,300,True,0,0,0,0,0,0,0,0,9,0,0,0,,,0,,
aiandrox/qanda,,False,False,False,39,109,0,0,0,1,0,0,1,"[53, 575, 576, 577, 578]",User,Udemy: はじめての Ruby on Rails入門,"{'': 30, 'json': 2, 'lock': 1, 'md': 1, 'js': 3, 'coffee': 2, 'scss': 3, 'rb': 43, 'erb': 9, 'ru': 1, 'yml': 6, 'enc': 1, 'html': 3, 'png': 2, 'ico': 1, 'txt': 1}",https://www.udemy.com/course/the-ultimate-ruby-on-rails-bootcamp/,,Ruby,7,7,0,0,1,578,True,0,0,0,0,6,1,6,1,9,0,0,0,,,4,"# READMEþþThis README would normally document whatever steps are necessary to get theþapplication up and running.þþThings you may want to cover:þþ* Ruby versionþþ* System dependenciesþþ* Configurationþþ* Database creationþþ* Database initializationþþ* How to run the test suiteþþ* Services (job queues, cache servers, search engines, etc.)þþ* Deployment instructionsþþ* ...",
bakery-blueprint/whitebreadman-spring,,False,False,False,3,1,0,1,0,4,81,9,1,"[145, 146, 148]",Organization,,{'md': 1},,,,4,1,0,0,1,148,True,0,0,0,0,0,0,0,0,9,0,0,0,5,0,,"# Springþþþþ<img src=""https://k.kakaocdn.net/dn/XDsfI/btqBZg0hYXm/J3kg9jDhNnGHCfrAEqpB91/img.png"" width=""200"" height=""100"" />þþ## Books þþ### 토비의 스프링þþhttp://book.interpark.com/product/BookDisplay.do?_method=detail&sc.prdNo=211110244&gclid=Cj0KCQiA7aPyBRChARIsAJfWCgLWWwJCzT0vKRpFd6Us6-fMZxrBzl8sP-GA2qdxotgfZmlWhMVd6aIaAijtEALw_wcBþþþþþþ### How to Studyþþ5명의 인원이 돌아가면서 해당  맡은 Chapter에 대한 내용을 발표한다.þþ발표 대상이 아닌 인원도 자신의 github 혹은 블로그에 정리하여 수요일 자정까지 제출 완료한다.þþþþ* 1장. 오브젝트와 의존관계þ  * 1.1 초난감 DAO þ    * 1.2 DAO의 분리 þ    * 1.3 DAO의 확장. [최준우]  (1 Week)þ  * 1.4 제어의 역전 þ    * 1.5 스프링 Ioc þ    * 1.6 싱글톤 레지스트리와 오젝트와 오브젝트 스코프 [이상훈]  (2 Week)þ  * 1.7 의존관계 주입 þ    * 1.8 XML을 이용한 설정 [채유진]  (3 Week)þþþþ* 2장. 템플릿þ  * 3.1 다시 보는 초난감 DAOþ    * 3.2 변하는 것과 변하지 않는 것 þ    * 3.3 JDBC 전략 패턴의 최적화 [임혜성]  (4 Week)þ  * 3.4 컨텍스트와 DIþ    * 3.5 템플릿과 콜백 þ    * 3.6 스프링의 JDBCTEMPLATE [최준우]  (5 Week)þþþþ* 5장. AOPþ  * 6.1 트랜젝션 코드의 분리þ    * 6.2 고립된 단위 테스트þ    * 6.3 다이내믹 프로시와 팩토리빈 [이상훈]  (~6.3.3 다이내믹 프록시를 이용한 트랜잭션 부가기능) (6 Week)þ  * 6.3 다이내믹 프로시와 팩토리빈 (6.3.3 다이내믹 프록시를 이용한 트랜잭션 부가기능 ~ )þ    * 6.4 스프링의 프록시 팩토리 빈 [채유진]  (7 Week)þ  * 6.5 스프링 AOP (8 Week)þ  * 6.6 트랜잭션 속성þ    * 6.7 애노테이션 트랜젝션 속성과 포인트컷 [임혜성]  (9 Week)þþþþ* 8장 스프링이란 무엇인가?þþþþ### 벌금þþ과제 미제출 시 : 3000원þþ<u>불참 시 에도 제출은 필수이다.</u>",
konglx90/knote,,False,False,False,109,109,0,1,0,0,0,0,0,"[213, 258, 712, 742, 748, 749, 752, 753, 760, 766]",User,note for programming,"{'': 1, 'md': 45, 'tsx': 3, 'js': 50, 'json': 3, 'py': 1, 'html': 4, 'css': 2}",,,JavaScript,59,1,0,0,1,926,True,1,0,0,0,0,0,0,0,8,0,0,0,,,7,## knote docsþþ### #1 文件名和文件夹名推荐使用中划线的形式þþ`2017-front-end.md`þþ### 推荐þþ[ES6-babel](https://babeljs.io/learn-es2015/) 新特性的快速了解þþ[understandinges6](https://leanpub.com/understandinges6/read)þþ[JavaScript Promise迷你书](http://liubin.org/promises-book/),
nickchen120235/notes,,False,False,False,30,7,0,1,0,39,356,90,1,"[65, 70, 84, 86, 88, 90, 91, 93]",User,Random notes,{'md': 7},,,,41,2,0,0,1,94,True,0,0,0,0,0,0,0,0,9,0,0,0,,,0,# Random Notesþþþ### Internetþ- <a href=https://github.com/nickchen120235/notes/blob/master/internet/v2ray.md>v2ray</a>þ- <a href=https://github.com/nickchen120235/notes/blob/master/internet/update%20npm%20nodejs.md>Update npm &amp; nodejs</a>þþ### Miscellaneousþ- <a href=https://github.com/nickchen120235/notes/blob/master/miscellaneous/LaTeX.md>LaTeX</a>þ- <a href=https://github.com/nickchen120235/mongo-example>mongo-example (mongoDB + JavaScript)</a>þ- <a href=https://github.com/nickchen120235/notes/blob/master/miscellaneous/ffmpeg.md>FFmpeg</a>þ- <a href=https://github.com/nickchen120235/notes/blob/master/miscellaneous/MongoDB%20Shell.md>MongoDB Shell</a>þ- <a href=https://github.com/nickchen120235/notes/blob/master/miscellaneous/python.md>Python</a>,
iamaustin316/note,,False,False,False,1,2,0,1,0,0,0,0,0,"[1643, 1804]",User,some note,"{'md': 1, 'html': 1}",,,HTML,5,1,0,0,0,1804,True,0,0,0,0,0,0,0,0,7,0,0,0,,,0,# noteþsome note,
Waynesway/note,,False,False,False,7,1,0,1,0,0,0,0,0,[2010],User,,{'md': 1},,,,1,1,0,0,0,2010,True,0,0,0,0,0,0,0,0,7,0,0,0,,,1,# note,
iwag/underscore_cpp,,False,False,False,132,6,0,1,0,0,0,0,0,"[2330, 2331]",User,,"{'': 3, 'md': 1, 'hpp': 1, 'cpp': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",C++,3,1,0,0,0,2331,True,0,0,0,0,0,0,0,0,6,0,0,0,,,17,underscore_cppþ==============,
enurod/InstaGraph,,False,False,False,3,1,1,1,1,0,0,0,0,"[1618, 2327]",User,Basic python script that takes an instagram username from the command line and creates a simple network map,{'py': 1},,,Python,3,1,0,0,0,2327,True,0,0,0,0,0,0,0,0,6,0,0,0,,,2,,
emonkak/lambdabot-skype-plugins,,False,False,False,128,5,0,1,0,0,0,0,0,"[2293, 2334, 2335]",User,A lambdabot plugin to connect to skype.,"{'': 2, 'hs': 2, 'cabal': 1}",,"{'key': 'mit', 'name': 'MIT License', 'spdx_id': 'MIT', 'url': 'https://api.github.com/licenses/mit', 'node_id': 'MDc6TGljZW5zZTEz'}",Haskell,3,1,0,0,0,2335,True,0,0,0,0,0,0,0,0,6,0,0,0,,,22,,
RIbragimov-NYc/CodeAcademy,,False,False,False,116,3,0,1,0,0,0,0,0,[2333],User,2nd test,"{'': 1, 'md': 2}",,"{'key': 'other', 'name': 'Other', 'spdx_id': 'NOASSERTION', 'url': None, 'node_id': 'MDc6TGljZW5zZTA='}",,3,1,0,0,0,2333,True,0,0,0,0,0,0,0,0,6,0,0,0,,,0,CodeAcademyþ===========þþ2nd test,
